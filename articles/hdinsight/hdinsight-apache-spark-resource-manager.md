---
title: cluster di risorse aaaManage per Apache Spark in HDInsight di Azure | Documenti Microsoft
description: Informazioni su come toouse gestire risorse per i cluster Spark in HDInsight di Azure per ottenere prestazioni migliori.
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="a38d7-103">Gestire le risorse del cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a38d7-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="a38d7-104">In questo articolo si apprenderà come interfacce hello tooaccess come Ambari UI e dell'interfaccia utente YARN hello Spark cronologia Server associata con il cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="a38d7-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="a38d7-105">Verrà inoltre Scopri come tootune hello configurazione del cluster per ottenere prestazioni ottimali.</span><span class="sxs-lookup"><span data-stu-id="a38d7-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="a38d7-106">**Prerequisiti:**</span><span class="sxs-lookup"><span data-stu-id="a38d7-106">**Prerequisites:**</span></span>

<span data-ttu-id="a38d7-107">È necessario disporre delle seguenti hello:</span><span class="sxs-lookup"><span data-stu-id="a38d7-107">You must have hello following:</span></span>

* <span data-ttu-id="a38d7-108">Una sottoscrizione di Azure.</span><span class="sxs-lookup"><span data-stu-id="a38d7-108">An Azure subscription.</span></span> <span data-ttu-id="a38d7-109">Vedere [Ottenere una versione di valutazione gratuita di Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="a38d7-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="a38d7-110">Un cluster Apache Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="a38d7-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="a38d7-111">Per istruzioni, vedere l'articolo relativo alla [creazione di cluster Apache Spark in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="a38d7-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="a38d7-112">La modalità di avvio dell'interfaccia utente Web Ambari hello?</span><span class="sxs-lookup"><span data-stu-id="a38d7-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="a38d7-113">Da hello [portale Azure](https://portal.azure.com/), dalla schermata iniziale di hello, fare clic sul riquadro hello per il cluster Spark (se è stato aggiunto, schermata iniziale di toohello).</span><span class="sxs-lookup"><span data-stu-id="a38d7-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="a38d7-114">È inoltre possibile navigare cluster tooyour **Esplora tutto** > **cluster HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="a38d7-115">Dal Pannello di cluster Spark hello, fare clic su **Dashboard**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="a38d7-116">Quando richiesto, immettere le credenziali di amministratore hello per cluster Spark hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="a38d7-117">![Avviare Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Avviare Resource Manager")</span><span class="sxs-lookup"><span data-stu-id="a38d7-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="a38d7-118">Questo deve essere avviato hello Ambari dell'interfaccia utente Web, come illustrato di seguito.</span><span class="sxs-lookup"><span data-stu-id="a38d7-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="a38d7-119">![Interfaccia utente Web Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Interfaccia utente Web Ambari")</span><span class="sxs-lookup"><span data-stu-id="a38d7-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="a38d7-120">Modalità avvio hello Spark cronologia Server?</span><span class="sxs-lookup"><span data-stu-id="a38d7-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="a38d7-121">Da hello [portale Azure](https://portal.azure.com/), dalla schermata iniziale di hello, fare clic sul riquadro hello per il cluster Spark (se è stato aggiunto, schermata iniziale di toohello).</span><span class="sxs-lookup"><span data-stu-id="a38d7-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="a38d7-122">Da hello in cluster pannello **collegamenti rapidi**, fare clic su **Dashboard Cluster**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="a38d7-123">In hello **Dashboard Cluster** pannello, fare clic su **Spark cronologia Server**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="a38d7-124">![Server cronologia Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Server cronologia Spark")</span><span class="sxs-lookup"><span data-stu-id="a38d7-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="a38d7-125">Quando richiesto, immettere le credenziali di amministratore hello per cluster Spark hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="a38d7-126">Modalità di avvio dell'interfaccia utente Yarn hello?</span><span class="sxs-lookup"><span data-stu-id="a38d7-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="a38d7-127">È possibile utilizzare hello dell'interfaccia utente YARN toomonitor le applicazioni che sono in esecuzione nel cluster Spark hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="a38d7-128">Dal Pannello di hello cluster, fare clic su **Dashboard Cluster**, quindi fare clic su **YARN**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Avviare l'interfaccia utente di YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="a38d7-130">In alternativa, è possibile avviare hello dell'interfaccia utente YARN da hello Ambari UI.</span><span class="sxs-lookup"><span data-stu-id="a38d7-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="a38d7-131">Fare clic su toolaunch hello Ambari UI, dal pannello cluster hello **Dashboard del Cluster**e quindi fare clic su **Dashboard del Cluster HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="a38d7-132">Hello Ambari UI, fare clic su **YARN**, fare clic su **collegamenti rapidi**, fare clic su Gestione risorse attivo hello e quindi fare clic su **ResourceManager UI**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="a38d7-133">Che cos'è la applicazioni Spark hello cluster ottimale configurazione toorun?</span><span class="sxs-lookup"><span data-stu-id="a38d7-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="a38d7-134">Hello e tre i parametri chiave che possono essere utilizzati per la configurazione di Spark a seconda dei requisiti dell'applicazione sono `spark.executor.instances`, `spark.executor.cores`, e `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="a38d7-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="a38d7-135">Un Executor è un processo avviato per un'applicazione Spark.</span><span class="sxs-lookup"><span data-stu-id="a38d7-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="a38d7-136">Viene eseguito sul nodo lavoro hello ed è responsabile toocarry attività hello per un'applicazione hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="a38d7-137">numero predefinito di Hello di executor hello executor dimensioni e per ogni cluster è calcolato in base a numero hello di nodi di lavoro e le dimensioni di hello lavoro nodo.</span><span class="sxs-lookup"><span data-stu-id="a38d7-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="a38d7-138">Questi elementi sono archiviati `spark-defaults.conf` nei nodi head del cluster hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="a38d7-139">tre parametri di configurazione Hello possono essere configurati a livello di cluster hello (per tutte le applicazioni in esecuzione nel cluster hello) o possono essere specificati per ogni singola applicazione.</span><span class="sxs-lookup"><span data-stu-id="a38d7-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="a38d7-140">Modificare i parametri di hello utilizzando Ambari UI</span><span class="sxs-lookup"><span data-stu-id="a38d7-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="a38d7-141">Scegliere hello UI Ambari **Spark**, fare clic su **configurazioni**e quindi espandere **spark-impostazioni predefinite personalizzate**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Impostare parametri con Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="a38d7-143">i valori predefiniti di Hello sono applicazioni di Spark buona toohave 4 eseguite simultaneamente nel cluster di hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="a38d7-144">È possibile, le modifiche questi valori dall'interfaccia utente di hello, come illustrato di seguito.</span><span class="sxs-lookup"><span data-stu-id="a38d7-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Impostare parametri con Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="a38d7-146">Fare clic su **salvare** toosave modifiche alla configurazione di hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="a38d7-147">Nella parte superiore di hello della pagina hello, verrà richiesto toorestart hello tutti i servizi interessati.</span><span class="sxs-lookup"><span data-stu-id="a38d7-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="a38d7-148">Fare clic su **Restart**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-148">Click **Restart**.</span></span>

    ![Riavviare i servizi](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="a38d7-150">Modificare i parametri in un'applicazione in esecuzione nel server Jupyter notebook hello</span><span class="sxs-lookup"><span data-stu-id="a38d7-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="a38d7-151">Per le applicazioni in esecuzione in server Jupyter notebook di hello, è possibile utilizzare hello `%%configure` modifiche alla configurazione di hello toomake di particolare.</span><span class="sxs-lookup"><span data-stu-id="a38d7-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="a38d7-152">Idealmente, è necessario apportare tali modifiche all'inizio di hello di un'applicazione hello, prima di eseguire la prima cella di codice.</span><span class="sxs-lookup"><span data-stu-id="a38d7-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="a38d7-153">In questo modo si garantisce che la configurazione hello è applicato toohello inserire il sessione, quando viene creato.</span><span class="sxs-lookup"><span data-stu-id="a38d7-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="a38d7-154">Se si desidera toochange hello configurazione in una fase successiva in un'applicazione hello, è necessario utilizzare hello `-f` parametro.</span><span class="sxs-lookup"><span data-stu-id="a38d7-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="a38d7-155">Tuttavia, in questo modo tutti sullo stato di avanzamento in hello applicazione andranno persi.</span><span class="sxs-lookup"><span data-stu-id="a38d7-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="a38d7-156">frammento di Hello seguente viene illustrato come toochange hello configurazione per un'applicazione in esecuzione nel server Jupyter.</span><span class="sxs-lookup"><span data-stu-id="a38d7-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="a38d7-157">I parametri di configurazione devono essere passati come una stringa JSON e devono essere nella riga successiva hello dopo magic hello, come illustrato nell'esempio la colonna hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="a38d7-158">Lo script spark-submit hello modificare i parametri per un'applicazione inviato tramite</span><span class="sxs-lookup"><span data-stu-id="a38d7-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="a38d7-159">Comando seguente è riportato un esempio di come toochange hello parametri di configurazione per un'applicazione di batch che viene inviato tramite `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="a38d7-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="a38d7-160">Modificare i parametri hello in un'applicazione inviato tramite cURL</span><span class="sxs-lookup"><span data-stu-id="a38d7-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="a38d7-161">Comando seguente è riportato un esempio di come toochange hello parametri di configurazione per un'applicazione di batch in cui viene inviato utilizzando cURL.</span><span class="sxs-lookup"><span data-stu-id="a38d7-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="a38d7-162">Come è possibile modificare questi parametri nel server Spark Thrift?</span><span class="sxs-lookup"><span data-stu-id="a38d7-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="a38d7-163">Spark Thrift Server fornisce cluster Spark JDBC/ODBC accesso tooa e viene utilizzato tooservice query Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="a38d7-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="a38d7-164">Strumenti come Power BI, Tableau e così via</span><span class="sxs-lookup"><span data-stu-id="a38d7-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="a38d7-165">utilizzare ODBC protocollo toocommunicate con le query di Spark SQL tooexecute Spark Thrift Server come applicazione Spark.</span><span class="sxs-lookup"><span data-stu-id="a38d7-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="a38d7-166">Quando si crea un cluster Spark, due istanze di hello Spark Thrift Server vengono avviati, uno per ogni nodo head.</span><span class="sxs-lookup"><span data-stu-id="a38d7-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="a38d7-167">Ogni Server di Spark Thrift sia visibile come un'applicazione di Spark in hello dell'interfaccia utente YARN.</span><span class="sxs-lookup"><span data-stu-id="a38d7-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="a38d7-168">Spark Thrift Server Usa allocazione dinamica dell'executor di nascita e pertanto hello `spark.executor.instances` non viene utilizzato.</span><span class="sxs-lookup"><span data-stu-id="a38d7-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="a38d7-169">Utilizza invece Spark Thrift Server `spark.dynamicAllocation.minExecutors` e `spark.dynamicAllocation.maxExecutors` conteggio executor di hello toospecify.</span><span class="sxs-lookup"><span data-stu-id="a38d7-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="a38d7-170">i parametri di configurazione di Hello `spark.executor.cores` e `spark.executor.memory` è toomodify hello executor spazio utilizzato.</span><span class="sxs-lookup"><span data-stu-id="a38d7-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="a38d7-171">È possibile modificare questi parametri, come illustrato di seguito.</span><span class="sxs-lookup"><span data-stu-id="a38d7-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="a38d7-172">Espandere hello **avanzate spark-thrift-sparkconf** i parametri di categoria tooupdate hello `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, e `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="a38d7-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurare il server Spark Thrift](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="a38d7-174">Espandere hello **personalizzato spark-thrift-sparkconf** parametro hello di categoria tooupdate `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="a38d7-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Configurare il server Spark Thrift](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="a38d7-176">Come è possibile modificare memoria hello di hello Spark Thrift Server?</span><span class="sxs-lookup"><span data-stu-id="a38d7-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="a38d7-177">Memoria Spark Thrift Server viene configurato too25% delle dimensioni del nodo head RAM hello, fornito dimensione RAM totale hello del nodo head hello è maggiore di 14GB.</span><span class="sxs-lookup"><span data-stu-id="a38d7-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="a38d7-178">È possibile utilizzare hello configurazione della memoria driver hello toochange Ambari UI, come illustrato di seguito.</span><span class="sxs-lookup"><span data-stu-id="a38d7-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="a38d7-179">Scegliere hello UI Ambari **Spark**, fare clic su **configurazioni**, espandere **avanzate spark env**e quindi specificare il valore di hello per **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurare la RAM del server Spark Thrift](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="a38d7-181">La funzionalità di Business Intelligence non è in uso con il cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="a38d7-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="a38d7-182">Come riprendere il risorse hello?</span><span class="sxs-lookup"><span data-stu-id="a38d7-182">How do I take hello resources back?</span></span>
<span data-ttu-id="a38d7-183">Perché si usa l'allocazione dinamica di Spark, hello solo le risorse utilizzate dal server thrift sono risorse hello per due schemi di applicazione hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="a38d7-184">tooreclaim queste risorse che è necessario arrestare hello servizi Thrift Server eseguiti nel cluster hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="a38d7-185">Hello Ambari UI, dal riquadro di sinistra hello, fare clic su **Spark**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="a38d7-186">Nella pagina successiva di hello, fare clic su **Spark Thrift server**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Riavviare il server Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="a38d7-188">Dovrebbe essere headnodes di hello due in cui hello Spark Thrift Server è in esecuzione.</span><span class="sxs-lookup"><span data-stu-id="a38d7-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="a38d7-189">Fare clic su uno dei headnodes hello.</span><span class="sxs-lookup"><span data-stu-id="a38d7-189">Click one of hello headnodes.</span></span>

    ![Riavviare il server Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="a38d7-191">la pagina successiva di Hello Elenca tutti i servizi di hello in esecuzione su tale nodo head.</span><span class="sxs-lookup"><span data-stu-id="a38d7-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="a38d7-192">Dall'elenco hello hello clic sul pulsante Avanti tooSpark Thrift Server e quindi fare clic su **arrestare**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Riavviare il server Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="a38d7-194">Ripetere questi passaggi in hello altri nodo head anche.</span><span class="sxs-lookup"><span data-stu-id="a38d7-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="a38d7-195">I notebook Jupyter non vengono eseguiti come previsto.</span><span class="sxs-lookup"><span data-stu-id="a38d7-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="a38d7-196">Come è possibile riavviare servizio hello?</span><span class="sxs-lookup"><span data-stu-id="a38d7-196">How can I restart hello service?</span></span>
<span data-ttu-id="a38d7-197">Avvio dell'interfaccia utente Web Ambari hello come illustrato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="a38d7-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="a38d7-198">Dal riquadro di spostamento a sinistra di hello, fare clic su **Jupyter**, fare clic su **azioni servizio**e quindi fare clic su **riavviare tutti**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="a38d7-199">Verrà avviato servizio Jupyter hello in headnodes hello tutti.</span><span class="sxs-lookup"><span data-stu-id="a38d7-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="a38d7-200">Rilevare l'esaurimento delle risorse</span><span class="sxs-lookup"><span data-stu-id="a38d7-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="a38d7-201">Avvio dell'interfaccia utente Yarn hello come illustrato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="a38d7-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="a38d7-202">Nella tabella le metriche del Cluster nella parte superiore dello schermo hello, controllare i valori di **di memoria utilizzata** e **memoria totale** colonne.</span><span class="sxs-lookup"><span data-stu-id="a38d7-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="a38d7-203">Se i valori hello 2 sono molto simili, potrebbe non essere disponibile sufficiente risorse toostart hello successiva applicazione.</span><span class="sxs-lookup"><span data-stu-id="a38d7-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="a38d7-204">Hello vale toohello **VCores utilizzato** e **VCores totale** colonne.</span><span class="sxs-lookup"><span data-stu-id="a38d7-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="a38d7-205">Inoltre, nella visualizzazione principale hello, se è presente un'applicazione è rimasto **accettato** lo stato e non in fase di transizione in **esecuzione** né **non riuscito** stato, potrebbe anche trattarsi di un'indicazione che non stanno toostart sufficienti risorse.</span><span class="sxs-lookup"><span data-stu-id="a38d7-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="a38d7-206">Come terminare un'esecuzione applicazione toofree risorsa?</span><span class="sxs-lookup"><span data-stu-id="a38d7-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="a38d7-207">In hello dell'interfaccia utente Yarn, dal pannello sinistro hello, fare clic su **esecuzione**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="a38d7-208">Elenco delle applicazioni in esecuzione hello determinare toobe applicazione hello terminato, fare clic su hello **ID**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="a38d7-209">![Terminare App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Terminare App1")</span><span class="sxs-lookup"><span data-stu-id="a38d7-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="a38d7-210">Fare clic su **Kill applicazione** hello angolo superiore destro, quindi scegliere **OK**.</span><span class="sxs-lookup"><span data-stu-id="a38d7-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="a38d7-211">![Terminare App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Terminare App2")</span><span class="sxs-lookup"><span data-stu-id="a38d7-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="a38d7-212">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="a38d7-212">See also</span></span>
* [<span data-ttu-id="a38d7-213">Tenere traccia ed eseguire il debug di processi in esecuzione nel cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a38d7-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="a38d7-214">Per gli analisti dei dati</span><span class="sxs-lookup"><span data-stu-id="a38d7-214">For data analysts</span></span>

* [<span data-ttu-id="a38d7-215">Spark con Machine Learning: utilizzare Spark in HDInsight per l'analisi della temperatura di compilazione utilizzando dati HVAC</span><span class="sxs-lookup"><span data-stu-id="a38d7-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="a38d7-216">Spark con Machine Learning: usare Spark in HDInsight risultati dell'ispezione alimentare toopredict</span><span class="sxs-lookup"><span data-stu-id="a38d7-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="a38d7-217">Analisi dei log del sito Web mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a38d7-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="a38d7-218">Application Insight telemetry data analysis using Spark in HDInsight (Analisi dei dati di telemetria di Application Insights con Spark in HDInsight)</span><span class="sxs-lookup"><span data-stu-id="a38d7-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="a38d7-219">Usare Caffe in Azure HDInsight Spark per l'apprendimento avanzato distribuito</span><span class="sxs-lookup"><span data-stu-id="a38d7-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="a38d7-220">Per gli sviluppatori di Spark</span><span class="sxs-lookup"><span data-stu-id="a38d7-220">For Spark developers</span></span>

* [<span data-ttu-id="a38d7-221">Creare un'applicazione autonoma con Scala</span><span class="sxs-lookup"><span data-stu-id="a38d7-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="a38d7-222">Eseguire processi in modalità remota in un cluster Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="a38d7-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="a38d7-223">Utilizzare i plug-in strumenti di HDInsight per toocreate IntelliJ IDEA e inviare applicazioni Spark Scala</span><span class="sxs-lookup"><span data-stu-id="a38d7-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="a38d7-224">Streaming Spark: usare Spark in HDInsight per la creazione di applicazioni di streaming in tempo reale</span><span class="sxs-lookup"><span data-stu-id="a38d7-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="a38d7-225">Utilizzare i plug-in strumenti di HDInsight per le applicazioni di Spark toodebug IntelliJ IDEA in modalità remota</span><span class="sxs-lookup"><span data-stu-id="a38d7-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="a38d7-226">Usare i notebook di Zeppelin con un cluster Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="a38d7-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="a38d7-227">Kernel disponibili per notebook di Jupyter nel cluster Spark per HDInsight</span><span class="sxs-lookup"><span data-stu-id="a38d7-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="a38d7-228">Usare pacchetti esterni con i notebook Jupyter</span><span class="sxs-lookup"><span data-stu-id="a38d7-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="a38d7-229">Installare Jupyter nel computer e connettere il cluster HDInsight Spark tooan</span><span class="sxs-lookup"><span data-stu-id="a38d7-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
