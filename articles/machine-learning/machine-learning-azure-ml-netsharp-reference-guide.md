---
title: 'aaaGuide toohello neurale reti linguaggio specifica Net # | Documenti Microsoft'
description: 'Sintassi per hello Net # neural networks lingua specifica, con relativi esempi di come toocreate una rete neurale personalizzata del modello in Microsoft Azure Machine Learning tramite Net #'
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 3493247ecc39ca3a1382510ad520d7017159ff62
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="guide-toonet-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="fc2b1-103">Guida di linguaggio di specifica di rete neurale tooNet # per Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="fc2b1-103">Guide tooNet# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="fc2b1-104">Panoramica</span><span class="sxs-lookup"><span data-stu-id="fc2b1-104">Overview</span></span>
<span data-ttu-id="fc2b1-105">NET # è un linguaggio sviluppato da Microsoft che viene utilizzato toodefine architetture di rete neurale.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-105">Net# is a language developed by Microsoft that is used toodefine neural network architectures.</span></span> <span data-ttu-id="fc2b1-106">È possibile usare Net# in moduli di reti neurali in Microsoft Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in hello MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in hello `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="fc2b1-107">In questo articolo si apprenderà concetti di base necessarie toodevelop una rete neurale personalizzata:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-107">In this article, you will learn basic concepts needed toodevelop a custom neural network:</span></span> 

* <span data-ttu-id="fc2b1-108">Requisiti di rete neurale e come toodefine hello componenti primari</span><span class="sxs-lookup"><span data-stu-id="fc2b1-108">Neural network requirements and how toodefine hello primary components</span></span>
* <span data-ttu-id="fc2b1-109">sintassi di Hello e parole chiave del linguaggio di specifica Net # hello</span><span class="sxs-lookup"><span data-stu-id="fc2b1-109">hello syntax and keywords of hello Net# specification language</span></span>
* <span data-ttu-id="fc2b1-110">Esempi di reti neurali personalizzate create usando Net#</span><span class="sxs-lookup"><span data-stu-id="fc2b1-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="fc2b1-111">Nozioni di base sulla rete neurale</span><span class="sxs-lookup"><span data-stu-id="fc2b1-111">Neural network basics</span></span>
<span data-ttu-id="fc2b1-112">Costituito da una struttura di rete neurale ***nodi*** organizzati in ***livelli***e ponderata ***connessioni*** (o ***bordi***) tra nodi Hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between hello nodes.</span></span> <span data-ttu-id="fc2b1-113">connessioni Hello sono direzionali e ogni connessione dispone di un ***origine*** nodo e un ***destinazione*** nodo.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-113">hello connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="fc2b1-114">Ogni ***livello di cui è possibile eseguire il training*** (livello nascosto o di output) ha una o più ***aggregazioni di connessioni***.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="fc2b1-115">Un bundle di connessione è costituito da un livello di origine e una specifica di connessioni hello di tale livello di origine.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-115">A connection bundle consists of a source layer and a specification of hello connections from that source layer.</span></span> <span data-ttu-id="fc2b1-116">Tutte le connessioni di hello in una condivisione di bundle specificato hello stesso ***livello origine*** e hello stesso ***livello destinazione***.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-116">All hello connections in a given bundle share hello same ***source layer*** and hello same ***destination layer***.</span></span> <span data-ttu-id="fc2b1-117">In Net #, un bundle di connessione viene considerato come livello di destinazione del bundle toohello appartiene.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-117">In Net#, a connection bundle is considered as belonging toohello bundle's destination layer.</span></span>  

<span data-ttu-id="fc2b1-118">NET # supporta vari tipi di pacchetti di connessione, che consente di personalizzare la modalità di hello gli input sono mappate toohidden livelli e output toohello mappato.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-118">Net# supports various kinds of connection bundles, which lets you customize hello way inputs are mapped toohidden layers and mapped toohello outputs.</span></span>   

<span data-ttu-id="fc2b1-119">predefinito Hello o bundle standard è un **bundle completo**, in cui ogni nodo in hello del livello di origine è nodo tooevery connessi nel livello di destinazione hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-119">hello default or standard bundle is a **full bundle**, in which each node in hello source layer is connected tooevery node in hello destination layer.</span></span>  

<span data-ttu-id="fc2b1-120">Net # supporta inoltre hello seguenti quattro tipi di pacchetti di connessione avanzate:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-120">Additionally, Net# supports hello following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="fc2b1-121">**Aggregazioni filtrate**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-121">**Filtered bundles**.</span></span> <span data-ttu-id="fc2b1-122">utente di Hello può definire un predicato utilizzando percorsi hello del nodo di livello di origine hello e hello destinazione livello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-122">hello user can define a predicate by using hello locations of hello source layer node and hello destination layer node.</span></span> <span data-ttu-id="fc2b1-123">I nodi connessi ogni volta che il predicato hello è True.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-123">Nodes are connected whenever hello predicate is True.</span></span>
* <span data-ttu-id="fc2b1-124">**Aggregazioni convoluzionali**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-124">**Convolutional bundles**.</span></span> <span data-ttu-id="fc2b1-125">utente di Hello può definire Villaggi piccoli di nodi nel livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-125">hello user can define small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="fc2b1-126">Ogni nodo nel livello di destinazione hello è connesso tooone risorse di nodi nel livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-126">Each node in hello destination layer is connected tooone neighborhood of nodes in hello source layer.</span></span>
* <span data-ttu-id="fc2b1-127">**Aggregazioni di pooling** e **aggregazioni di normalizzazione delle risposte**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="fc2b1-128">Questi sono raggruppamenti di tooconvolutional simili in tale hello utente definisce Villaggi piccoli di nodi nel livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-128">These are similar tooconvolutional bundles in that hello user defines small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="fc2b1-129">differenza Hello è che non si è trainable pesi hello dei bordi hello in questi pacchetti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-129">hello difference is that hello weights of hello edges in these bundles are not trainable.</span></span> <span data-ttu-id="fc2b1-130">In alternativa, in cui viene applicata una funzione predefinita nodo di origine toohello valori toodetermine hello destinazione nodo valore.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-130">Instead, a predefined function is applied toohello source node values toodetermine hello destination node value.</span></span>  

<span data-ttu-id="fc2b1-131">Tramite Net # toodefine hello struttura di una rete neurale rende possibili toodefine strutture complesse, ad esempio le reti neurali o convoluzioni di dimensioni arbitrarie, che sono note learning tooimprove sui dati, ad esempio immagini, audio o video.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-131">Using Net# toodefine hello structure of a neural network makes it possible toodefine complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known tooimprove learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="fc2b1-132">Personalizzazioni supportate</span><span class="sxs-lookup"><span data-stu-id="fc2b1-132">Supported customizations</span></span>
<span data-ttu-id="fc2b1-133">architettura Hello dei modelli di rete neurale creati in Azure Machine Learning può essere ampiamente personalizzato tramite Net #.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-133">hello architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="fc2b1-134">È possibile:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-134">You can:</span></span>  

* <span data-ttu-id="fc2b1-135">Creare livelli nascosti e controllo hello numero di nodi in ogni livello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-135">Create hidden layers and control hello number of nodes in each layer.</span></span>
* <span data-ttu-id="fc2b1-136">Specificare la modalità livelli tooeach toobe connessi altri.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-136">Specify how layers are toobe connected tooeach other.</span></span>
* <span data-ttu-id="fc2b1-137">Definire strutture di connettività speciali, ad esempio aggregazioni di convoluzioni e per la condivisione dei pesi.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="fc2b1-138">Specificare diverse funzioni di attivazione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-138">Specify different activation functions.</span></span>  

<span data-ttu-id="fc2b1-139">Per informazioni dettagliate della sintassi del linguaggio di specifica hello, vedere [struttura specifica](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-139">For details of hello specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="fc2b1-140">Per esempi di definizione di reti neurali per alcune attività, dalla toocomplex simplex, di apprendimento automatico comune vedere [esempi](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-140">For examples of defining neural networks for some common machine learning tasks, from simplex toocomplex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="fc2b1-141">Requisiti generali</span><span class="sxs-lookup"><span data-stu-id="fc2b1-141">General requirements</span></span>
* <span data-ttu-id="fc2b1-142">Devono essere esattamente disponibili un livello di output, almeno un livello di input e zero o più livelli nascosti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="fc2b1-143">Ogni livello ha un numero fisso di nodi, disposti concettualmente in una matrice rettangolare di dimensioni arbitrarie.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="fc2b1-144">Input livelli privi di parametri con training associato e rappresentano hello punto dati di istanza in cui vengono immessi rete hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-144">Input layers have no associated trained parameters and represent hello point where instance data enters hello network.</span></span> 
* <span data-ttu-id="fc2b1-145">Livelli trainable (livelli nascosti e di output di hello) sono associati parametri con training, noto come pesi e i pregiudizi.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-145">Trainable layers (hello hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="fc2b1-146">nodi di origine e destinazione Hello devono trovarsi in livelli separati.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-146">hello source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="fc2b1-147">Le connessioni devono essere acicliche; in altre parole, non può essere una catena di connessioni iniziali toohello back-nodo di origine iniziale.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back toohello initial source node.</span></span>
* <span data-ttu-id="fc2b1-148">il livello di output di Hello non può essere un livello di origine di un pacchetto di connessione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-148">hello output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="fc2b1-149">Specifiche di struttura</span><span class="sxs-lookup"><span data-stu-id="fc2b1-149">Structure specifications</span></span>
<span data-ttu-id="fc2b1-150">Una specifica struttura di rete neurale è composto da tre sezioni: hello **dichiarazione di costante**, hello **livello dichiarazione**, hello **dichiarazione connessione**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-150">A neural network structure specification is composed of three sections: hello **constant declaration**, hello **layer declaration**, hello **connection declaration**.</span></span> <span data-ttu-id="fc2b1-151">È anche disponibile una sezione facoltativa denominata **dichiarazione delle condivisioni**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="fc2b1-152">sezioni Hello possono essere specificate in qualsiasi ordine.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-152">hello sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="fc2b1-153">Dichiarazione della costante</span><span class="sxs-lookup"><span data-stu-id="fc2b1-153">Constant declaration</span></span>
<span data-ttu-id="fc2b1-154">Una dichiarazione della costante è facoltativa.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-154">A constant declaration is optional.</span></span> <span data-ttu-id="fc2b1-155">Fornisce un toodefine indica i valori utilizzati in un' posizione nella definizione di rete neurale hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-155">It provides a means toodefine values used elsewhere in hello neural network definition.</span></span> <span data-ttu-id="fc2b1-156">istruzione di dichiarazione Hello è costituito da un identificatore seguito da un segno di uguale e un'espressione di valore.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-156">hello declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="fc2b1-157">Ad esempio, hello istruzione definisce una costante **x**:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-157">For example, hello following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="fc2b1-158">toodefine due o più costanti contemporaneamente, racchiudere i nomi di identificatore hello e i valori tra parentesi graffe ed è necessario separarli con punti e virgola.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-158">toodefine two or more constants simultaneously, enclose hello identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="fc2b1-159">ad esempio:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="fc2b1-160">Hello destra di ogni espressione di assegnazione può essere un numero intero, un numero reale, un valore booleano (True o False) o un'espressione matematica.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-160">hello right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="fc2b1-161">ad esempio:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="fc2b1-162">Dichiarazione dei livelli</span><span class="sxs-lookup"><span data-stu-id="fc2b1-162">Layer declaration</span></span>
<span data-ttu-id="fc2b1-163">dichiarazione di livello Hello è obbligatorio.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-163">hello layer declaration is required.</span></span> <span data-ttu-id="fc2b1-164">Definisce dimensioni hello e l'origine del livello di hello, inclusi i bundle di connessione e relativi attributi.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-164">It defines hello size and source of hello layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="fc2b1-165">salve inizia di istruzione di dichiarazione con il nome di hello del livello di hello (di input, nascosto o di output), seguito dalle dimensioni di hello del livello di hello (una tupla di numeri interi positivi).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-165">hello declaration statement starts with hello name of hello layer (input, hidden, or output), followed by hello dimensions of hello layer (a tuple of positive integers).</span></span> <span data-ttu-id="fc2b1-166">ad esempio:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="fc2b1-167">prodotto Hello di dimensioni hello è il numero di hello di nodi nel livello hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-167">hello product of hello dimensions is hello number of nodes in hello layer.</span></span> <span data-ttu-id="fc2b1-168">In questo esempio, sono presenti due dimensioni [5,20], che non vi sono 100 nodi nel livello hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in hello layer.</span></span>
* <span data-ttu-id="fc2b1-169">livelli di Hello possono essere dichiarati in qualsiasi ordine, con una sola eccezione: se è definito più di un livello di input, hello ordine in cui sono dichiarati deve corrispondere hello di funzioni nei dati di input hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-169">hello layers can be declared in any order, with one exception: If more than one input layer is defined, hello order in which they are declared must match hello order of features in hello input data.</span></span>  

<span data-ttu-id="fc2b1-170">toospecify che hello numero di nodi in un livello determinato automaticamente, utilizzare hello **auto** (parola chiave).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-170">toospecify that hello number of nodes in a layer be determined automatically, use hello **auto** keyword.</span></span> <span data-ttu-id="fc2b1-171">Hello **auto** parola chiave ha effetti diversi, a seconda di livello hello:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-171">hello **auto** keyword has different effects, depending on hello layer:</span></span>  

* <span data-ttu-id="fc2b1-172">In una dichiarazione a livello di input, il numero di hello di nodi è il numero di hello di funzioni nei dati di input hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-172">In an input layer declaration, hello number of nodes is hello number of features in hello input data.</span></span>
* <span data-ttu-id="fc2b1-173">In una dichiarazione di livello nascosto, il numero di hello di nodi è il numero hello specificato dal valore del parametro hello per **numero di nodi nascosti**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-173">In a hidden layer declaration, hello number of nodes is hello number that is specified by hello parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="fc2b1-174">In una dichiarazione di livello di output, il numero di hello di nodi è 2 per classificazione a due classi, 1 per la regressione e uguale toohello numero di nodi di output per la classificazione multiclasse.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-174">In an output layer declaration, hello number of nodes is 2 for two-class classification, 1 for regression, and equal toohello number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="fc2b1-175">Ad esempio, hello seguente definizione di rete consente dimensioni hello di tutti i livelli toobe determinato automaticamente:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-175">For example, hello following network definition allows hello size of all layers toobe automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="fc2b1-176">Una dichiarazione di livello per un livello trainable (livelli nascosti o di output di hello) può includere facoltativamente funzione output hello (denominata anche una funzione di attivazione), che per impostazione predefinita troppo**sigmoidale** per i modelli di classificazione e **lineare** per i modelli di regressione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-176">A layer declaration for a trainable layer (hello hidden or output layers) can optionally include hello output function (also called an activation function), which defaults too**sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="fc2b1-177">(Anche se si utilizza l'impostazione predefinita di hello, è possibile dichiarare in modo esplicito funzione di attivazione hello, se lo si desidera per maggiore chiarezza.)</span><span class="sxs-lookup"><span data-stu-id="fc2b1-177">(Even if you use hello default, you can explicitly state hello activation function, if desired for clarity.)</span></span>

<span data-ttu-id="fc2b1-178">Hello output funzioni seguenti sono supportate:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-178">hello following output functions are supported:</span></span>  

* <span data-ttu-id="fc2b1-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="fc2b1-179">sigmoid</span></span>
* <span data-ttu-id="fc2b1-180">linear</span><span class="sxs-lookup"><span data-stu-id="fc2b1-180">linear</span></span>
* <span data-ttu-id="fc2b1-181">softmax</span><span class="sxs-lookup"><span data-stu-id="fc2b1-181">softmax</span></span>
* <span data-ttu-id="fc2b1-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="fc2b1-182">rlinear</span></span>
* <span data-ttu-id="fc2b1-183">square</span><span class="sxs-lookup"><span data-stu-id="fc2b1-183">square</span></span>
* <span data-ttu-id="fc2b1-184">sqrt</span><span class="sxs-lookup"><span data-stu-id="fc2b1-184">sqrt</span></span>
* <span data-ttu-id="fc2b1-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="fc2b1-185">srlinear</span></span>
* <span data-ttu-id="fc2b1-186">abs</span><span class="sxs-lookup"><span data-stu-id="fc2b1-186">abs</span></span>
* <span data-ttu-id="fc2b1-187">tanh</span><span class="sxs-lookup"><span data-stu-id="fc2b1-187">tanh</span></span> 
* <span data-ttu-id="fc2b1-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="fc2b1-188">brlinear</span></span>  

<span data-ttu-id="fc2b1-189">Ad esempio che segue la dichiarazione di hello utilizza hello **softmax** funzione:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-189">For example, hello following declaration uses hello **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="fc2b1-190">Dichiarazione della connessione</span><span class="sxs-lookup"><span data-stu-id="fc2b1-190">Connection declaration</span></span>
<span data-ttu-id="fc2b1-191">Immediatamente dopo aver definito livello trainable hello, è necessario dichiarare le connessioni tra i livelli di hello che è definito.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-191">Immediately after defining hello trainable layer, you must declare connections among hello layers you have defined.</span></span> <span data-ttu-id="fc2b1-192">dichiarazione di bundle connessione Hello inizia con la parola chiave hello **da**, seguiti dal nome hello di tipo del bundle hello origine hello e di livello di connessione bundle toocreate.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-192">hello connection bundle declaration starts with hello keyword **from**, followed by hello name of hello bundle's source layer and hello kind of connection bundle toocreate.</span></span>   

<span data-ttu-id="fc2b1-193">Sono attualmente supportati cinque tipi di aggregazioni di connessioni:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="fc2b1-194">**Completa** bundle, indicati dalla parola chiave hello **tutti**</span><span class="sxs-lookup"><span data-stu-id="fc2b1-194">**Full** bundles, indicated by hello keyword **all**</span></span>
* <span data-ttu-id="fc2b1-195">**Filtrati** bundle, indicati dalla parola chiave hello **in**, seguito da un'espressione del predicato</span><span class="sxs-lookup"><span data-stu-id="fc2b1-195">**Filtered** bundles, indicated by hello keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="fc2b1-196">**Convolutional** bundle, indicati dalla parola chiave hello **convolve**, seguito da attributi convoluzione hello</span><span class="sxs-lookup"><span data-stu-id="fc2b1-196">**Convolutional** bundles, indicated by hello keyword **convolve**, followed by hello convolution attributes</span></span>
* <span data-ttu-id="fc2b1-197">**Il pool** bundle, indicati dalle parole chiave hello **max pool** o **significa pool**</span><span class="sxs-lookup"><span data-stu-id="fc2b1-197">**Pooling** bundles, indicated by hello keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="fc2b1-198">**Normalizzazione di risposta** bundle, indicati dalla parola chiave hello **norm risposta**</span><span class="sxs-lookup"><span data-stu-id="fc2b1-198">**Response normalization** bundles, indicated by hello keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="fc2b1-199">Aggregazioni complete</span><span class="sxs-lookup"><span data-stu-id="fc2b1-199">Full bundles</span></span>
<span data-ttu-id="fc2b1-200">Un bundle di connessione completa include una connessione da ogni nodo nel nodo di hello origine livello tooeach nel livello di destinazione hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-200">A full connection bundle includes a connection from each node in hello source layer tooeach node in hello destination layer.</span></span> <span data-ttu-id="fc2b1-201">Si tratta di tipo di connessione di rete predefinito hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-201">This is hello default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="fc2b1-202">Aggregazioni filtrate</span><span class="sxs-lookup"><span data-stu-id="fc2b1-202">Filtered bundles</span></span>
<span data-ttu-id="fc2b1-203">Una specifica di aggregazione di connessioni filtrata include un predicato, espresso sintatticamente in modo analogo a un'espressione lambda in C#.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="fc2b1-204">Hello seguente definisce due pacchetti filtrati:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-204">hello following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="fc2b1-205">Nel predicato hello per *ByRow*, **s** è un parametro che rappresenta un indice nella matrice rettangolare di hello dei nodi del livello di input hello, *pixel*, e **d**  è un parametro che rappresenta un indice nella matrice hello dei nodi del livello nascosto hello, *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-205">In hello predicate for *ByRow*, **s** is a parameter representing an index into hello rectangular array of nodes of hello input layer, *Pixels*, and **d** is a parameter representing an index into hello array of nodes of hello hidden layer, *ByRow*.</span></span> <span data-ttu-id="fc2b1-206">tipo di entrambi Hello **s** e **d** è una tupla di interi di lunghezza due.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-206">hello type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="fc2b1-207">Concettualmente, **s** include tutte le coppie di valori interi con *0 <= s[0] < 10* e *0 <= s[1] < 20* e **d** include tutte le coppie di valori interi con *0 <= d[0] < 10* e *0 <= d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="fc2b1-208">Sul lato destro di hello dell'espressione predicato hello, vi è una condizione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-208">On hello right-hand side of hello predicate expression, there is a condition.</span></span> <span data-ttu-id="fc2b1-209">In questo esempio, per ogni valore di **s** e **d** tale condizione hello è True, è un bordo dal nodo di livello di hello origine livello nodo toohello destinazione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-209">In this example, for every value of **s** and **d** such that hello condition is True, there is an edge from hello source layer node toohello destination layer node.</span></span> <span data-ttu-id="fc2b1-210">Di conseguenza, questa espressione di filtro indica il file di bundle hello include una connessione dal nodo hello definito da **s** toohello nodo definito da **d** in tutti i casi in cui s [0] è uguale tood [0].</span><span class="sxs-lookup"><span data-stu-id="fc2b1-210">Thus, this filter expression indicates that hello bundle includes a connection from hello node defined by **s** toohello node defined by **d** in all cases where s[0] is equal tood[0].</span></span>  

<span data-ttu-id="fc2b1-211">È facoltativamente possibile specificare un insieme di pesi per un'aggregazione filtrata.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="fc2b1-212">valore per hello Hello **pesi** attributo deve essere una tupla di valori a virgola mobile con una lunghezza corrispondente hello numero di connessioni definito dal bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-212">hello value for hello **Weights** attribute must be a tuple of floating point values with a length that matches hello number of connections defined by hello bundle.</span></span> <span data-ttu-id="fc2b1-213">Per impostazione predefinita, i pesi sono generati in modo casuale.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="fc2b1-214">I valori di peso sono raggruppati in base all'indice di nodo di destinazione hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-214">Weight values are grouped by hello destination node index.</span></span> <span data-ttu-id="fc2b1-215">Vale a dire, se è connesso il nodo di destinazione prima hello ha impiegato i nodi di origine, hello innanzitutto *K* gli elementi di hello **pesi** tupla sono pesi hello per hello primo nodo di destinazione, in ordine di indice di origine.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-215">That is, if hello first destination node is connected tooK source nodes, hello first *K* elements of hello **Weights** tuple are hello weights for hello first destination node, in source index order.</span></span> <span data-ttu-id="fc2b1-216">Hello che stesso vale per hello rimanenti nodi di destinazione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-216">hello same applies for hello remaining destination nodes.</span></span>  

<span data-ttu-id="fc2b1-217">È possibile toospecify pesi direttamente come valori costanti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-217">It's possible toospecify weights directly as constant values.</span></span> <span data-ttu-id="fc2b1-218">Ad esempio, se si è appreso pesi hello in precedenza, è possibile specificarli come costanti utilizzando questa sintassi:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-218">For example, if you learned hello weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="fc2b1-219">Aggregazioni convoluzionali</span><span class="sxs-lookup"><span data-stu-id="fc2b1-219">Convolutional bundles</span></span>
<span data-ttu-id="fc2b1-220">Se i dati di training hello presenta una struttura omogenea, le connessioni convolutional sono funzionalità di alto livello dei dati hello toolearn comunemente utilizzati.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-220">When hello training data has a homogeneous structure, convolutional connections are commonly used toolearn high-level features of hello data.</span></span> <span data-ttu-id="fc2b1-221">Ad esempio, nei dati di tipo immagine, audio o video è possibile che la dimensionalità spaziale o temporale sia abbastanza uniforme.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="fc2b1-222">Bundle convolutional impiegano rettangolare **directcompute** che vengono portati sopra tramite dimensioni hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-222">Convolutional bundles employ rectangular **kernels** that are slid through hello dimensions.</span></span> <span data-ttu-id="fc2b1-223">In pratica, ogni kernel definisce un set di pesi applicato in locali Villaggi, cui viene fatto riferimento tooas **applicazioni kernel**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred tooas **kernel applications**.</span></span> <span data-ttu-id="fc2b1-224">Ogni applicazione kernel corrisponde tooa nodo nel livello di origine hello, ovvero tooas cui hello **nodo centrale**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-224">Each kernel application corresponds tooa node in hello source layer, which is referred tooas hello **central node**.</span></span> <span data-ttu-id="fc2b1-225">numero di connessioni sono condivise con pesi Hello di un kernel.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-225">hello weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="fc2b1-226">In un bundle convolutional, ogni kernel rettangolare e tutte le applicazioni kernel hello stessa dimensione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are hello same size.</span></span>  

<span data-ttu-id="fc2b1-227">Bundle convolutional supportano hello gli attributi seguenti:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-227">Convolutional bundles support hello following attributes:</span></span>

<span data-ttu-id="fc2b1-228">**InputShape** definisce dimensionalità hello del livello di origine hello per scopi di hello per il raggruppamento convolutional.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-228">**InputShape** defines hello dimensionality of hello source layer for hello purposes of this convolutional bundle.</span></span> <span data-ttu-id="fc2b1-229">il valore di Hello deve essere una tupla di numeri interi positivi.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-229">hello value must be a tuple of positive integers.</span></span> <span data-ttu-id="fc2b1-230">prodotto di Hello di numeri interi hello deve essere uguale hello numero di nodi nel livello di origine hello, ma in caso contrario, è necessario dimensionalità hello toomatch dichiarata per il livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-230">hello product of hello integers must equal hello number of nodes in hello source layer, but otherwise, it does not need toomatch hello dimensionality declared for hello source layer.</span></span> <span data-ttu-id="fc2b1-231">lunghezza Hello di questo tipo di tupla diventa hello **grado** valore per bundle convolutional hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-231">hello length of this tuple becomes hello **arity** value for hello convolutional bundle.</span></span> <span data-ttu-id="fc2b1-232">(In genere grado fa riferimento toohello numero di argomenti o una funzione può accettare gli operandi).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-232">(Typically arity refers toohello number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="fc2b1-233">forma hello toodefine e le posizioni dei kernel hello, utilizzare gli attributi di hello **KernelShape**, **Stride**, **Padding**, **LowerPad**, e **UpperPad**:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-233">toodefine hello shape and locations of hello kernels, use hello attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="fc2b1-234">**KernelShape**: dimensionalità di hello definisce (obbligatoria) di ogni kernel per bundle convolutional hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-234">**KernelShape**: (required) Defines hello dimensionality of each kernel for hello convolutional bundle.</span></span> <span data-ttu-id="fc2b1-235">il valore di Hello deve essere una tupla di numeri interi positivi con una lunghezza pari al grado hello del bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-235">hello value must be a tuple of positive integers with a length that equals hello arity of hello bundle.</span></span> <span data-ttu-id="fc2b1-236">Ogni componente di questo tipo di tupla deve essere maggiore di componente corrispondente di hello del **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-236">Each component of this tuple must be no greater than hello corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="fc2b1-237">**Stride**: (facoltativo) hello definisce la variabile di dimensioni di passaggio di convoluzione hello (dimensioni di un passaggio per ogni dimensione), che corrisponde alla distanza hello tra i nodi centrale hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-237">**Stride**: (optional) Defines hello sliding step sizes of hello convolution (one step size for each dimension), that is hello distance between hello central nodes.</span></span> <span data-ttu-id="fc2b1-238">il valore di Hello deve essere una tupla di numeri interi positivi con una lunghezza di grado hello del bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-238">hello value must be a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="fc2b1-239">Ogni componente di questo tipo di tupla deve essere maggiore di componente corrispondente di hello del **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-239">Each component of this tuple must be no greater than hello corresponding component of **KernelShape**.</span></span> <span data-ttu-id="fc2b1-240">valore predefinito di Hello è una tupla con tooone uguale di tutti i componenti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-240">hello default value is a tuple with all components equal tooone.</span></span> 
* <span data-ttu-id="fc2b1-241">**Condivisione**: condivisione per ogni dimensione di convoluzione hello un peso di hello definisce (facoltativo).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-241">**Sharing**: (optional) Defines hello weight sharing for each dimension of hello convolution.</span></span> <span data-ttu-id="fc2b1-242">il valore di Hello può essere un singolo valore booleano o una tupla di valori booleani con una lunghezza di grado hello del bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-242">hello value can be a single Boolean value or a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="fc2b1-243">Un singolo valore booleano è estesa toobe una tupla di lunghezza corretta di hello con tutti i componenti toohello uguale valore specificato.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-243">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="fc2b1-244">valore predefinito di Hello è una tupla costituita da tutti i valori True.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-244">hello default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="fc2b1-245">**MapCount**: (facoltativo) definisce hello numerose funzionalità esegue il mapping per bundle convolutional hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-245">**MapCount**: (optional) Defines hello number of feature maps for hello convolutional bundle.</span></span> <span data-ttu-id="fc2b1-246">il valore di Hello può essere un numero intero positivo o una tupla di numeri interi positivi con una lunghezza di grado hello del bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-246">hello value can be a single positive integer or a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="fc2b1-247">Un singolo valore integer viene esteso toobe una tupla di lunghezza corretta di hello con hello prima componenti uguale toohello specificato valore e tutti i hello tooone uguale a componenti rimanenti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-247">A single integer value is extended toobe a tuple of hello correct length with hello first components equal toohello specified value and all hello remaining components equal tooone.</span></span> <span data-ttu-id="fc2b1-248">valore predefinito di Hello è uno.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-248">hello default value is one.</span></span> <span data-ttu-id="fc2b1-249">numero totale di Hello delle mappe di funzionalità è prodotto hello dei componenti di hello di hello tupla.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-249">hello total number of feature maps is hello product of hello components of hello tuple.</span></span> <span data-ttu-id="fc2b1-250">Hello factoring del numero totale di vari componenti hello determina la modalità di raggruppamento hello funzionalità mappare i valori nei nodi di destinazione hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-250">hello factoring of this total number across hello components determines how hello feature map values are grouped in hello destination nodes.</span></span> 
* <span data-ttu-id="fc2b1-251">**Pesi**: (facoltativo) definisce hello iniziale i pesi per il bundle di hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-251">**Weights**: (optional) Defines hello initial weights for hello bundle.</span></span> <span data-ttu-id="fc2b1-252">il valore di Hello deve essere una tupla di valori a virgola mobile con una lunghezza hello numero kernel volte hello del pesi per kernel, come definito più avanti in questo articolo.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-252">hello value must be a tuple of floating point values with a length that is hello number of kernels times hello number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="fc2b1-253">pesi predefiniti Hello, vengono generati in modo casuale.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-253">hello default weights are randomly generated.</span></span>  

<span data-ttu-id="fc2b1-254">Esistono due set di proprietà che controllano la spaziatura interna ovvero la proprietà come hello si escludono a vicenda:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-254">There are two sets of properties that control padding, hello properties being mutually exclusive:</span></span>

* <span data-ttu-id="fc2b1-255">**Spaziatura interna**: (facoltativo) consente di determinare se un input hello deve essere completato utilizzando un **schema di riempimento predefinito**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-255">**Padding**: (optional) Determines whether hello input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="fc2b1-256">il valore di Hello può essere un singolo valore booleano o può essere una tupla di valori booleani con una lunghezza di grado hello del bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-256">hello value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="fc2b1-257">Un singolo valore booleano è estesa toobe una tupla di lunghezza corretta di hello con tutti i componenti toohello uguale valore specificato.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-257">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="fc2b1-258">Se il valore di hello per una dimensione è True, origine hello viene riempita logicamente in tale dimensione con le applicazioni aggiuntive kernel toosupport di celle con valori zero, in modo che i nodi di centrale hello del kernel e il cognome di hello in tale dimensione siano hello prima e l'ultimo nodo in tale dimensione nel livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-258">If hello value for a dimension is True, hello source is logically padded in that dimension with zero-valued cells toosupport additional kernel applications, such that hello central nodes of hello first and last kernels in that dimension are hello first and last nodes in that dimension in hello source layer.</span></span> <span data-ttu-id="fc2b1-259">Pertanto, il numero di hello dei nodi "fittizi" in ogni dimensione è determinata automaticamente in toofit esattamente *(InputShape [d] - 1) / Stride [d] + 1* kernel nel livello di origine hello applicato un riempimento.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-259">Thus, hello number of "dummy" nodes in each dimension is determined automatically, toofit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into hello padded source layer.</span></span> <span data-ttu-id="fc2b1-260">Se il valore di hello per una dimensione è False, hello kernel sono definiti in modo che sia il numero di hello di nodi su ciascun lato che sono stati esclusi hello stesso (backup differenza tooa 1).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-260">If hello value for a dimension is False, hello kernels are defined so that hello number of nodes on each side that are left out is hello same (up tooa difference of 1).</span></span> <span data-ttu-id="fc2b1-261">il valore predefinito Hello di questo attributo è una tupla con tooFalse uguale di tutti i componenti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-261">hello default value of this attribute is a tuple with all components equal tooFalse.</span></span>
* <span data-ttu-id="fc2b1-262">**UpperPad** e **LowerPad**: (facoltativo) specificare un controllo maggiore sulla quantità di hello di spaziatura interna toouse.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over hello amount of padding toouse.</span></span> <span data-ttu-id="fc2b1-263">**Importante:** questi attributi possono essere definiti se e solo se hello **Padding** proprietà precedente è ***non*** definito.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-263">**Important:** These attributes can be defined if and only if hello **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="fc2b1-264">i valori Hello devono essere tuple con valori integer con lunghezze di grado hello del bundle hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-264">hello values should be integer-valued tuples with lengths that are hello arity of hello bundle.</span></span> <span data-ttu-id="fc2b1-265">Quando vengono specificati questi attributi, nodi "fittizi" vengono aggiunti toohello inferiore ed estremità superiore di ogni dimensione di hello livello di input.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-265">When these attributes are specified, "dummy" nodes are added toohello lower and upper ends of each dimension of hello input layer.</span></span> <span data-ttu-id="fc2b1-266">numero di nodi Hello aggiunto toohello inferiore e superiore termina in ogni dimensione è determinata da **LowerPad**[i] e **UpperPad**[i] rispettivamente.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-266">hello number of nodes added toohello lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="fc2b1-267">è necessario soddisfare tooensure che kernel corrispondenti nodi solo troppo "reali" e non troppo "fittizio" hello seguenti condizioni:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-267">tooensure that kernels correspond only too"real" nodes and not too"dummy" nodes, hello following conditions must be met:</span></span>
  * <span data-ttu-id="fc2b1-268">Ogni componente di**LowerPad** deve essere rigorosamente minore di KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="fc2b1-269">Ogni componente di **UpperPad** non deve essere maggiore di KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="fc2b1-270">il valore predefinito Hello di questi attributi è una tupla con too0 uguale di tutti i componenti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-270">hello default value of these attributes is a tuple with all components equal too0.</span></span> 

<span data-ttu-id="fc2b1-271">impostazione di Hello **Padding** = true consente in base alle esigenze di spaziatura come tookeep hello "center" del kernel hello all'interno di hello "real" di input.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-271">hello setting **Padding** = true allows as much padding as is needed tookeep hello "center" of hello kernel inside hello "real" input.</span></span> <span data-ttu-id="fc2b1-272">In questo caso matematiche hello un bit per il calcolo delle dimensioni di output di hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-272">This changes hello math a bit for computing hello output size.</span></span> <span data-ttu-id="fc2b1-273">In genere, l'output di hello dimensioni *D* viene calcolata come *D = (I - K) / S + 1*, dove *si* dimensioni input hello, *K* dimensioni kernel hello, *S* è stride hello, e  */*  è la divisione di interi (arrotondare per difetto).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-273">Generally, hello output size *D* is computed as *D = (I - K) / S + 1*, where *I* is hello input size, *K* is hello kernel size, *S* is hello stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="fc2b1-274">Se si imposta UpperPad = [1, 1], hello input dimensioni *si* in modo efficace è 29 e pertanto *D = (29-5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-274">If you set UpperPad = [1, 1], hello input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="fc2b1-275">Se **Padding** è true, *I* viene essenzialmente incrementato di *K - 1*, ovvero *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="fc2b1-276">Specificando i valori per **UpperPad** e **LowerPad** ottenere un maggiore controllo riguardo hello padding rispetto ai casi si appena **Padding** = true.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over hello padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="fc2b1-277">Per altre informazioni sulle reti convoluzionali e le relative applicazioni, vedere gli articoli seguenti:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="fc2b1-278">http://deeplearning.net/tutorial/lenet.html </span><span class="sxs-lookup"><span data-stu-id="fc2b1-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="fc2b1-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span><span class="sxs-lookup"><span data-stu-id="fc2b1-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="fc2b1-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span><span class="sxs-lookup"><span data-stu-id="fc2b1-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="fc2b1-281">Aggregazioni di pooling</span><span class="sxs-lookup"><span data-stu-id="fc2b1-281">Pooling bundles</span></span>
<span data-ttu-id="fc2b1-282">Oggetto **pool bundle** applica connettività tooconvolutional simile di geometry, ma usa le funzioni predefinite toosource nodo valori tooderive hello nodo valore di destinazione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-282">A **pooling bundle** applies geometry similar tooconvolutional connectivity, but it uses predefined functions toosource node values tooderive hello destination node value.</span></span> <span data-ttu-id="fc2b1-283">Le aggregazioni di pooling non hanno quindi stati sottoponibili a training (pesi o distorsioni).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="fc2b1-284">Supporto di bundle tutti hello convolutional attributi ad eccezione di pool **condivisione**, **MapCount**, e **pesi**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-284">Pooling bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="fc2b1-285">In genere, non si sovrappongano kernel hello riepilogati per unità del pool di connessioni adiacenti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-285">Typically, hello kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="fc2b1-286">Se Stride [d] è uguale tooKernelShape [d] in ogni dimensione, il livello di hello ottenuto è hello tradizionale locale pooling livello, che è comunemente usato in reti neurali convolutional.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-286">If Stride[d] is equal tooKernelShape[d] in each dimension, hello layer obtained is hello traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="fc2b1-287">Ogni nodo di destinazione calcola hello massima o Media hello delle attività di hello del relativo kernel nel livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-287">Each destination node computes hello maximum or hello mean of hello activities of its kernel in hello source layer.</span></span>  

<span data-ttu-id="fc2b1-288">Hello di esempio seguente viene illustrato un bundle del pool di connessioni:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-288">hello following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="fc2b1-289">grado di Hello del bundle hello è 3 (lunghezza di tuple hello hello **InputShape**, **KernelShape**, e **Stride**).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-289">hello arity of hello bundle is 3 (hello length of hello tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="fc2b1-290">Hello numero di nodi nel livello di origine hello è *5 * 24 * 24 = 2880*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-290">hello number of nodes in hello source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="fc2b1-291">Questo è un livello di pooling locale tradizionale, perché **KernelShape** e **Stride** sono uguali.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="fc2b1-292">Hello numero di nodi nel livello di destinazione hello è *5 * 12 * 12 = 1440*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-292">hello number of nodes in hello destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="fc2b1-293">Per altre informazioni sui livelli di pooling, vedere gli articoli seguenti:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="fc2b1-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Sezione 3.4)</span><span class="sxs-lookup"><span data-stu-id="fc2b1-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="fc2b1-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span><span class="sxs-lookup"><span data-stu-id="fc2b1-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="fc2b1-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span><span class="sxs-lookup"><span data-stu-id="fc2b1-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="fc2b1-297">Aggregazioni di normalizzazione delle risposte</span><span class="sxs-lookup"><span data-stu-id="fc2b1-297">Response normalization bundles</span></span>
<span data-ttu-id="fc2b1-298">**Normalizzazione di risposta** è uno schema di normalizzazione locale che è stato introdotto da Geoffrey Hinton, et al., nel documento hello [ImageNet Classiﬁcation con complete reti neurali Convolutional](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in hello paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="fc2b1-299">Normalizzazione di risposta è una generalizzazione tooaid utilizzato nelle reti neurali.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-299">Response normalization is used tooaid generalization in neural nets.</span></span> <span data-ttu-id="fc2b1-300">Quando un neurone la generazione di un livello molto elevato di attivazione, un livello di normalizzazione risposta locale elimina il livello di attivazione hello di hello circostanti neuroni.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses hello activation level of hello surrounding neurons.</span></span> <span data-ttu-id="fc2b1-301">Ciò avviene tramite tre parametri (***α***, ***β***, e ***k***) e una struttura convoluzionale (o forma di vicinato).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="fc2b1-302">Ogni neurone nel livello di destinazione hello ***y*** corrisponde tooa neurone ***x*** nel livello di origine hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-302">Every neuron in hello destination layer ***y*** corresponds tooa neuron ***x*** in hello source layer.</span></span> <span data-ttu-id="fc2b1-303">livello di attivazione di Hello ***y*** viene fornito dalla seguente formula, hello in cui ***f*** hello livello di attivazione di un neurone, e ***Nx*** è kernel hello (o set di hello contenente hello neuroni di circa hello ***x***), come definito da hello convolutional struttura seguente:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-303">hello activation level of ***y*** is given by hello following formula, where ***f*** is hello activation level of a neuron, and ***Nx*** is hello kernel (or hello set that contains hello neurons in hello neighborhood of ***x***), as defined by hello following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="fc2b1-304">Bundle di normalizzazione risposta supportano tutti gli attributi convolutional hello, tranne **condivisione**, **MapCount**, e **pesi**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-304">Response normalization bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="fc2b1-305">Se kernel hello contiene neuroni hello stessa mappa come ***x***, lo schema di normalizzazione hello è tooas cui **stessa mappa normalizzazione**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-305">If hello kernel contains neurons in hello same map as ***x***, hello normalization scheme is referred tooas **same map normalization**.</span></span> <span data-ttu-id="fc2b1-306">toodefine stesso eseguire il mapping di normalizzazione, hello prima coordinata **InputShape** deve avere valore hello 1.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-306">toodefine same map normalization, hello first coordinate in **InputShape** must have hello value 1.</span></span>
* <span data-ttu-id="fc2b1-307">Se il kernel hello contiene neuroni hello stessa posizione spaziale ***x***, senza neuroni hello in altri mapping, viene chiamato lo schema di normalizzazione hello **attraverso esegue il mapping di normalizzazione**.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-307">If hello kernel contains neurons in hello same spatial position as ***x***, but hello neurons are in other maps, hello normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="fc2b1-308">Questo tipo di normalizzazione risposta implementa una forma di inibizione laterale ispirata hello trovato tipo nel neuroni reali, la creazione di concorrenza per i livelli di attivazione big tra output neurone calcolato in mappe diverse.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-308">This type of response normalization implements a form of lateral inhibition inspired by hello type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="fc2b1-309">toodefine tra esegue il mapping di normalizzazione, coordinate prima hello deve essere un numero intero maggiore di uno e non è maggiore del numero di hello delle mappe e rest hello di coordinate hello deve avere il valore di hello 1.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-309">toodefine across maps normalization, hello first coordinate must be an integer greater than one and no greater than hello number of maps, and hello rest of hello coordinates must have hello value 1.</span></span>  

<span data-ttu-id="fc2b1-310">Poiché il bundle di normalizzazione risposta applicano un funzione predefinita toosource nodo valori toodetermine hello nodo valore di destinazione, non presentano alcun stato trainable (pesi o pregiudizi).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-310">Because response normalization bundles apply a predefined function toosource node values toodetermine hello destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="fc2b1-311">**Avviso**: i nodi nel livello di destinazione hello hello corrispondono tooneurons che sono nodi centrale hello kernel hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-311">**Alert**: hello nodes in hello destination layer correspond tooneurons that are hello central nodes of hello kernels.</span></span> <span data-ttu-id="fc2b1-312">Ad esempio, se KernelShape [d] è dispari, verrà restituito *KernelShape [d] / 2* corrispondente nodo centrale kernel toohello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds toohello central kernel node.</span></span> <span data-ttu-id="fc2b1-313">Se *KernelShape [d]* è pari, Trova nodo centrale hello *KernelShape [d] / 2-1*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-313">If *KernelShape[d]* is even, hello central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="fc2b1-314">Pertanto, se **Padding**[d] è False, hello prima e ultima hello *KernelShape [d] / 2* nodi non dispongono di nodi corrispondenti nel livello di destinazione hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-314">Therefore, if **Padding**[d] is False, hello first and hello last *KernelShape[d]/2* nodes do not have corresponding nodes in hello destination layer.</span></span> <span data-ttu-id="fc2b1-315">tooavoid questa situazione, definire **Padding** come [true, true,..., true].</span><span class="sxs-lookup"><span data-stu-id="fc2b1-315">tooavoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="fc2b1-316">Inoltre toohello quattro attributi descritti in precedenza, il bundle di normalizzazione risposta anche supporto hello gli attributi seguenti:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-316">In addition toohello four attributes described earlier, response normalization bundles also support hello following attributes:</span></span>  

* <span data-ttu-id="fc2b1-317">**Alpha**: (obbligatorio) specifica un valore a virgola mobile che corrisponde a troppo***α*** nella formula precedente hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-317">**Alpha**: (required) Specifies a floating-point value that corresponds too***α*** in hello previous formula.</span></span> 
* <span data-ttu-id="fc2b1-318">**Beta**: (obbligatorio) specifica un valore a virgola mobile che corrisponde a troppo***β*** nella formula precedente hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-318">**Beta**: (required) Specifies a floating-point value that corresponds too***β*** in hello previous formula.</span></span> 
* <span data-ttu-id="fc2b1-319">**Offset**: (facoltativo) specifica un valore a virgola mobile che corrisponde a troppo***k*** nella formula precedente hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-319">**Offset**: (optional) Specifies a floating-point value that corresponds too***k*** in hello previous formula.</span></span> <span data-ttu-id="fc2b1-320">Per impostazione predefinita too1.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-320">It defaults too1.</span></span>  

<span data-ttu-id="fc2b1-321">Hello seguente definisce un raggruppamento di normalizzazione risposta mediante tali attributi:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-321">hello following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="fc2b1-322">livello di origine Hello include cinque mappe, ognuna con dimensione aof 12 x 12, per un totale di nodi 1440.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-322">hello source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="fc2b1-323">valore di Hello **KernelShape** indica che si tratta di un livello di normalizzazione mappa stessa, in cui le risorse di hello sono un 3x3 rettangolo.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-323">hello value of **KernelShape** indicates that this is a same map normalization layer, where hello neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="fc2b1-324">il valore predefinito di Hello **Padding** è False, pertanto il livello di destinazione hello è solo 10 nodi in ogni dimensione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-324">hello default value of **Padding** is False, thus hello destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="fc2b1-325">tooinclude un nodo nel livello di destinazione hello corrispondente nodo tooevery nel livello di origine di hello, aggiungere spaziatura interna = [true, true, true]; e modificare anche le dimensioni di hello di RN1 [5, 12, 12].</span><span class="sxs-lookup"><span data-stu-id="fc2b1-325">tooinclude one node in hello destination layer that corresponds tooevery node in hello source layer, add Padding = [true, true, true]; and change hello size of RN1 too[5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="fc2b1-326">Dichiarazione delle condivisioni</span><span class="sxs-lookup"><span data-stu-id="fc2b1-326">Share declaration</span></span>
<span data-ttu-id="fc2b1-327">Net# supporta facoltativamente la definizione di più aggregazioni con pesi condivisi.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="fc2b1-328">pesi Hello qualsiasi due pacchetti di possono essere condiviso se le strutture sono hello stesso.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-328">hello weights of any two bundles can be shared if their structures are hello same.</span></span> <span data-ttu-id="fc2b1-329">la seguente sintassi Hello definisce bundle con pesi condivisi:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-329">hello following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="fc2b1-330">Ad esempio, hello condivisione-dichiarazione seguente specifica i nomi dei livelli di hello, che indica che devono essere condivisa pesi sia pregiudizi:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-330">For example, hello following share-declaration specifies hello layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="fc2b1-331">le funzionalità di Hello input vengono suddivisi in due livelli di input con dimensioni uguali.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-331">hello input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="fc2b1-332">i livelli nascosto Hello per calcolare le funzionalità di livello superiore nei due livelli di input hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-332">hello hidden layers then compute higher level features on hello two input layers.</span></span> 
* <span data-ttu-id="fc2b1-333">dichiarazione di Hello condivisione specifica che *H1* e *H2* deve essere calcolato in hello allo stesso modo dal loro rispettivi input.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-333">hello share-declaration specifies that *H1* and *H2* must be computed in hello same way from their respective inputs.</span></span>  

<span data-ttu-id="fc2b1-334">In alternativa, è possibile specificare questo concetto con due dichiarazioni delle condivisioni separate, come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="fc2b1-335">È possibile utilizzare la forma breve hello solo quando i livelli di hello contengono un unico bundle.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-335">You can use hello short form only when hello layers contain a single bundle.</span></span> <span data-ttu-id="fc2b1-336">In generale, è possibile condividere solo quando si struttura rilevanti hello è identico, vale a dire che dispongono di hello stessa dimensione, geometry convolutional stesso e così via.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-336">In general, sharing is possible only when hello relevant structure is identical, meaning that they have hello same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="fc2b1-337">Esempi di utilizzo di Net#</span><span class="sxs-lookup"><span data-stu-id="fc2b1-337">Examples of Net# usage</span></span>
<span data-ttu-id="fc2b1-338">In questa sezione vengono forniti alcuni esempi di come è possibile utilizzare Net # livelli tooadd nascosto, definire modo hello che interagiscono con gli altri livelli livelli nascosti e compilare convolutional reti.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-338">This section provides some examples of how you can use Net# tooadd hidden layers, define hello way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="fc2b1-339">Definire una semplice rete neurale personalizzata, ad esempio "Hello World"</span><span class="sxs-lookup"><span data-stu-id="fc2b1-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="fc2b1-340">Questo semplice esempio viene illustrato come toocreate un neurale rete modello che dispone di un singolo livello nascosto.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-340">This simple example demonstrates how toocreate a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="fc2b1-341">esempio Hello alcuni comandi di base viene illustrato come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-341">hello example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="fc2b1-342">prima riga Hello definisce livello input hello (denominato *dati*).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-342">hello first line defines hello input layer (named *Data*).</span></span> <span data-ttu-id="fc2b1-343">Quando si utilizza hello **auto** (parola chiave), la rete neurale hello include automaticamente tutte le colonne di funzionalità negli esempi di input hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-343">When you use hello  **auto** keyword, hello neural network automatically includes all feature columns in hello input examples.</span></span> 
* <span data-ttu-id="fc2b1-344">seconda riga Hello Crea livello nascosto hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-344">hello second line creates hello hidden layer.</span></span> <span data-ttu-id="fc2b1-345">nome Hello *H* viene assegnato il livello nascosto toohello, che dispone di 200 nodi.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-345">hello name *H* is assigned toohello hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="fc2b1-346">Questo livello è completamente connesso toohello input.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-346">This layer is fully connected toohello input layer.</span></span>
* <span data-ttu-id="fc2b1-347">terza riga Hello definisce il livello di output di hello (denominato *O*), che contiene 10 nodi di output.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-347">hello third line defines hello output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="fc2b1-348">Se la rete neurale hello viene utilizzata per la classificazione, c'è un nodo di output per ogni classe.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-348">If hello neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="fc2b1-349">parola chiave Hello **sigmoidale** indica che il livello di output toohello applicato hello output funzione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-349">hello keyword **sigmoid** indicates that hello output function is applied toohello output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="fc2b1-350">Definire più livelli nascosti: esempio obiettivo computer</span><span class="sxs-lookup"><span data-stu-id="fc2b1-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="fc2b1-351">Hello esempio seguente viene illustrato come toodefine una rete neurale leggermente più complessa con più livelli nascosti personalizzati.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-351">hello following example demonstrates how toodefine a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define hello input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define hello first two hidden layers, using data only from hello Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define hello third hidden layer, which uses as source hello hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define hello output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="fc2b1-352">In questo esempio vengono illustrate diverse funzionalità del linguaggio di specifica di reti neurali hello:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-352">This example illustrates several features of hello neural networks specification language:</span></span>  

* <span data-ttu-id="fc2b1-353">struttura Hello ha due livelli di input, *pixel* e *metadati*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-353">hello structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="fc2b1-354">Hello *pixel* livello è un livello di origine per due bundle di connessione, con livelli di destinazione, *ByRow* e *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-354">hello *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="fc2b1-355">Hello livelli *raccogliere* e *risultato* sono livelli di destinazione in più bundle di connessione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-355">hello layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="fc2b1-356">livello di output di Hello, *risultato*, è un livello di destinazione in due pacchetti di connessione, uno con hello di secondo livello nascosto (raccolta) come un livello di destinazione e hello altro con livello di input hello (metadati) come un livello di destinazione.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-356">hello output layer, *Result*, is a destination layer in two connection bundles; one with hello second level hidden (Gather) as a destination layer, and hello other with hello input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="fc2b1-357">Hello livelli nascosti, *ByRow* e *ByCol*, specificare la connettività filtrate tramite le espressioni del predicato.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-357">hello hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="fc2b1-358">Più precisamente, hello nodo *ByRow* a [x, y] è nodi connessi toohello *pixel* che dispongono di x di coordinate, prima di hello primo indice toohello uguale coordinate del nodo.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-358">More precisely, hello node in *ByRow* at [x, y] is connected toohello nodes in *Pixels* that have hello first index coordinate equal toohello node's first coordinate, x.</span></span> <span data-ttu-id="fc2b1-359">Analogamente, hello nodo *ByCol a [x, y] è nodi connessi toohello _Pixels* che dispongono di coordinate indice secondo di hello all'interno di uno di coordinate a seconda del nodo hello, y.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-359">Similarly, hello node in *ByCol at [x, y] is connected toohello nodes in _Pixels* that have hello second index coordinate within one of hello node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="fc2b1-360">Definire una rete per la classificazione multiclasse convoluzionale: esempio di riconoscimento cifra</span><span class="sxs-lookup"><span data-stu-id="fc2b1-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="fc2b1-361">definizione di Hello di hello seguente rete è progettato toorecognize numeri e illustra alcune tecniche avanzate per la personalizzazione di una rete neurale.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-361">hello definition of hello following network is designed toorecognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="fc2b1-362">struttura Hello ha un solo livello di input, *immagine*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-362">hello structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="fc2b1-363">parola chiave Hello **convolve** indica che i livelli di hello denominati *Conv1* e *Conv2* convolutional livelli.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-363">hello keyword **convolve** indicates that hello layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="fc2b1-364">Ognuna di queste dichiarazioni di livello è seguito da un elenco di attributi convoluzione hello.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-364">Each of these layer declarations is followed by a list of hello convolution attributes.</span></span>
* <span data-ttu-id="fc2b1-365">nascosto di Hello net dispone di un terzo livello, *Hid3*, che è completamente connesso toohello secondo livello nascosto, *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-365">hello net has a third hidden layer, *Hid3*, which is fully connected toohello second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="fc2b1-366">livello di output di Hello, *cifra*, è connessa toohello solo terzo livello nascosto, *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-366">hello output layer, *Digit*, is connected only toohello third hidden layer, *Hid3*.</span></span> <span data-ttu-id="fc2b1-367">parola chiave Hello **tutti** indica il livello di output di hello è completamente connesso troppo*Hid3*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-367">hello keyword **all** indicates that hello output layer is fully connected too*Hid3*.</span></span>
* <span data-ttu-id="fc2b1-368">Hello grado del convoluzione hello è tre (lunghezza di tuple hello hello **InputShape**, **KernelShape**, **Stride**, e **condivisione**).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-368">hello arity of hello convolution is three (hello length of hello tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="fc2b1-369">numero di Hello di pesi per kernel è *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape** \[2] = 1 + 1 * 5 * 5 = 26. Oppure 26 * 50 = 1300*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-369">hello number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="fc2b1-370">È possibile calcolare nodi hello in ogni livello nascosto, come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="fc2b1-370">You can calculate hello nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="fc2b1-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="fc2b1-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="fc2b1-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="fc2b1-374">Hello numero totale di nodi può essere calcolato tramite hello dichiarato dimensionalità di hello dei livelli, [50, 5, 5], come indicato di seguito:  ***MapCount** * **NodeCount** \[ 0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="fc2b1-374">hello total number of nodes can be calculated by using hello declared dimensionality of hello layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="fc2b1-375">Poiché **condivisione**[d] è impostato su False solo per *d = = 0*, numero di hello del kernel è  ***MapCount** * **NodeCount** \[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-375">Because **Sharing**[d] is False only for *d == 0*, hello number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="fc2b1-376">Riconoscimenti</span><span class="sxs-lookup"><span data-stu-id="fc2b1-376">Acknowledgements</span></span>
<span data-ttu-id="fc2b1-377">Hello linguaggio Net # per personalizzare l'architettura di hello delle reti neurali è stato sviluppato da Microsoft da Shon Katzenberger (Architect, Machine Learning) e Alexey Kamenev (tecnico del Software, Microsoft Research).</span><span class="sxs-lookup"><span data-stu-id="fc2b1-377">hello Net# language for customizing hello architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="fc2b1-378">Viene utilizzata internamente per machine learning progetti e applicazioni, da analitica tootext rilevamento di immagine.</span><span class="sxs-lookup"><span data-stu-id="fc2b1-378">It is used internally for machine learning projects and applications ranging from image detection tootext analytics.</span></span> <span data-ttu-id="fc2b1-379">Per ulteriori informazioni, vedere [reti neurali in Machine Learning di Azure - introduzione tooNet #](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span><span class="sxs-lookup"><span data-stu-id="fc2b1-379">For more information, see [Neural Nets in Azure ML - Introduction tooNet#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif

