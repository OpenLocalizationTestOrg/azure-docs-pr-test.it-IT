---
title: Creare modelli di analisi del testo in Azure Machine Learning Studio | Microsoft Docs
description: Come creare modelli di analisi del testo in Azure Machine Learning Studio usando moduli di pre-elaborazione del testo, estrazione degli n-grammi o hashing delle caratteristiche
services: machine-learning
documentationcenter: 
author: rastala
manager: jhubbard
editor: 
ms.assetid: 08cd6723-3ae6-4e99-a924-e650942e461b
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/06/2016
ms.author: roastala
ms.openlocfilehash: 342e81e2497d292ca730bea59e03182d316ffec3
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 07/11/2017
---
# <a name="create-text-analytics-models-in-azure-machine-learning-studio"></a><span data-ttu-id="56dc9-103">Creare modelli di analisi del testo in Azure Machine Learning Studio</span><span class="sxs-lookup"><span data-stu-id="56dc9-103">Create text analytics models in Azure Machine Learning Studio</span></span>
<span data-ttu-id="56dc9-104">È possibile usare Azure Machine Learning per creare modelli di analisi del testo e renderli operativi.</span><span class="sxs-lookup"><span data-stu-id="56dc9-104">You can use Azure Machine Learning to build and operationalize text analytics models.</span></span> <span data-ttu-id="56dc9-105">Questi modelli consentono di risolvere, ad esempio, problemi di classificazione dei documenti o analisi di valutazione.</span><span class="sxs-lookup"><span data-stu-id="56dc9-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span></span>

<span data-ttu-id="56dc9-106">In un esperimento di analisi del testo è necessario in genere:</span><span class="sxs-lookup"><span data-stu-id="56dc9-106">In a text analytics experiment, you would typically:</span></span>

1. <span data-ttu-id="56dc9-107">Pulire e pre-elaborare i set di dati di testo</span><span class="sxs-lookup"><span data-stu-id="56dc9-107">Clean and preprocess text dataset</span></span>
2. <span data-ttu-id="56dc9-108">Estrarre i vettori di caratteristiche numeriche dal testo pre-elaborato</span><span class="sxs-lookup"><span data-stu-id="56dc9-108">Extract numeric feature vectors from pre-processed text</span></span>
3. <span data-ttu-id="56dc9-109">Addestrare il modello di classificazione o regressione</span><span class="sxs-lookup"><span data-stu-id="56dc9-109">Train classification or regression model</span></span>
4. <span data-ttu-id="56dc9-110">Assegnare un punteggio e convalidare il modello</span><span class="sxs-lookup"><span data-stu-id="56dc9-110">Score and validate the model</span></span>
5. <span data-ttu-id="56dc9-111">Distribuire il modello in produzione</span><span class="sxs-lookup"><span data-stu-id="56dc9-111">Deploy the model to production</span></span>

<span data-ttu-id="56dc9-112">In questa esercitazione si apprenderanno questi passaggi eseguendo un modello di analisi di valutazione mediante il set di dati di Amazon Book Reviews (vedere il documento di ricerca “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” di John Blitzer, Mark Dredze e Fernando Pereira; Association of Computational Linguistics (ACL), 2007). Questo set di dati è costituito da punteggi di recensione (1-2 o 4-5) e testo in formato libero.</span><span class="sxs-lookup"><span data-stu-id="56dc9-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span></span> <span data-ttu-id="56dc9-113">L'obiettivo consiste nella stima del punteggio di recensione: basso (1-2) o alto (4-5).</span><span class="sxs-lookup"><span data-stu-id="56dc9-113">The goal is to predict the review score: low (1-2) or high (4-5).</span></span>

<span data-ttu-id="56dc9-114">È possibile trovare gli esperimenti trattati in questa esercitazione nella raccolta Cortana Intelligence:</span><span class="sxs-lookup"><span data-stu-id="56dc9-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span></span>

[<span data-ttu-id="56dc9-115">Stimare le recensioni dei libri</span><span class="sxs-lookup"><span data-stu-id="56dc9-115">Predict Book Reviews</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-1)

[<span data-ttu-id="56dc9-116">Stimare le recensioni dei libri - Esperimento predittivo</span><span class="sxs-lookup"><span data-stu-id="56dc9-116">Predict Book Reviews - Predictive Experiment</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-Predictive-Experiment-1)

## <a name="step-1-clean-and-preprocess-text-dataset"></a><span data-ttu-id="56dc9-117">Passaggio 1: Pulire e pre-elaborare i set di dati di testo</span><span class="sxs-lookup"><span data-stu-id="56dc9-117">Step 1: Clean and preprocess text dataset</span></span>
<span data-ttu-id="56dc9-118">Iniziamo l'esperimento dividendo i punteggi di recensione nei bucket di categoria basso e alto per formulare il problema come classificazione a due classi.</span><span class="sxs-lookup"><span data-stu-id="56dc9-118">We begin the experiment by dividing the review scores into categorical low and high buckets to formulate the problem as two-class classification.</span></span> <span data-ttu-id="56dc9-119">Vengono usati i moduli [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) e [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) (Valori di categoria del gruppo).</span><span class="sxs-lookup"><span data-stu-id="56dc9-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span></span>

![Creazione dell'etichetta](./media/machine-learning-text-analytics-module-tutorial/create-label.png)

<span data-ttu-id="56dc9-121">Quindi si pulirà il testo tramite il modulo [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) .</span><span class="sxs-lookup"><span data-stu-id="56dc9-121">Then, we clean the text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span></span> <span data-ttu-id="56dc9-122">La pulizia riduce il rumore nel set di dati, aiuta a trovare le funzioni più importanti e a migliorare l'accuratezza del modello finale.</span><span class="sxs-lookup"><span data-stu-id="56dc9-122">The cleaning reduces the noise in the dataset, help you find the most important features, and improve the accuracy of the final model.</span></span> <span data-ttu-id="56dc9-123">Vengono rimosse le parole non significative: parole comuni, come articoli e preposizioni, nonché numeri, caratteri speciali, caratteri duplicati, indirizzi di posta elettronica e URL.</span><span class="sxs-lookup"><span data-stu-id="56dc9-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span></span> <span data-ttu-id="56dc9-124">Si converte inoltre il testo in minuscolo, si lemmatizzano le parole e si individuano i delimitatori delle frasi che vengono poi indicati dal simbolo "|||" nel testo pre-elaborato.</span><span class="sxs-lookup"><span data-stu-id="56dc9-124">We also convert the text to lowercase, lemmatize the words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span></span>

![Preprocess Text](./media/machine-learning-text-analytics-module-tutorial/preprocess-text.png)

<span data-ttu-id="56dc9-126">Se si desidera usare un elenco di parole non significative personalizzato?</span><span class="sxs-lookup"><span data-stu-id="56dc9-126">What if you want to use a custom list of stopwords?</span></span> <span data-ttu-id="56dc9-127">È possibile passarlo come input facoltativo.</span><span class="sxs-lookup"><span data-stu-id="56dc9-127">You can pass it in as optional input.</span></span> <span data-ttu-id="56dc9-128">È inoltre possibile usare un'espressione regolare con sintassi C# personalizzata per sostituire le sottostringhe e rimuovere parole da parte del discorso: nomi, verbi o aggettivi.</span><span class="sxs-lookup"><span data-stu-id="56dc9-128">You can also use custom C# syntax regular expression to replace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span></span>

<span data-ttu-id="56dc9-129">Dopo aver completato la pre-elaborazione, si suddividono i dati in set di addestramento e set di test.</span><span class="sxs-lookup"><span data-stu-id="56dc9-129">After the preprocessing is complete, we split the data into train and test sets.</span></span>

## <a name="step-2-extract-numeric-feature-vectors-from-pre-processed-text"></a><span data-ttu-id="56dc9-130">Passaggio 2: Estrarre vettori di caratteristiche numeriche dal testo pre-elaborato</span><span class="sxs-lookup"><span data-stu-id="56dc9-130">Step 2: Extract numeric feature vectors from pre-processed text</span></span>
<span data-ttu-id="56dc9-131">Per compilare un modello per i dati di testo è necessario in genere convertire il testo in formato libero in vettori di caratteristiche numeriche.</span><span class="sxs-lookup"><span data-stu-id="56dc9-131">To build a model for text data, you typically have to convert free-form text into numeric feature vectors.</span></span> <span data-ttu-id="56dc9-132">In questo esempio si usa il modulo [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) per trasformare i dati di testo in tale formato.</span><span class="sxs-lookup"><span data-stu-id="56dc9-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module to transform the text data to such format.</span></span> <span data-ttu-id="56dc9-133">Il modulo accetta una colonna di parole separate da spazi e calcola un dizionario di parole, o n-grammi di parole, che vengono visualizzate nel set di dati.</span><span class="sxs-lookup"><span data-stu-id="56dc9-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span></span> <span data-ttu-id="56dc9-134">Quindi conta il numero di volte in cui ogni parola, o n-gramma, compare in ogni record e crea vettori di caratteristiche da questi conteggi.</span><span class="sxs-lookup"><span data-stu-id="56dc9-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span></span> <span data-ttu-id="56dc9-135">In questa esercitazione impostiamo la dimensione dell'n-gramma su 2 quindi i nostri vettori di caratteristiche includono singole parole e combinazioni di due parole consecutive.</span><span class="sxs-lookup"><span data-stu-id="56dc9-135">In this tutorial, we set N-gram size to 2, so our feature vectors include single words and combinations of two subsequent words.</span></span>

![Estrazione degli n-grammi](./media/machine-learning-text-analytics-module-tutorial/extract-ngrams.png)

<span data-ttu-id="56dc9-137">Ai conteggi di n-grammi si applica la ponderazione TF*IDF (frequenza del termine, frequenza inversa del documento).</span><span class="sxs-lookup"><span data-stu-id="56dc9-137">We apply TF*IDF (Term Frequency Inverse Document Frequency) weighting to N-gram counts.</span></span> <span data-ttu-id="56dc9-138">Questo approccio aggiunge il peso delle parole che compaiono frequentemente in un singolo record ma sono rare nell'intero set di dati.</span><span class="sxs-lookup"><span data-stu-id="56dc9-138">This approach adds weight of words that appear frequently in a single record but are rare across the entire dataset.</span></span> <span data-ttu-id="56dc9-139">Altre opzioni sono la ponderazione binaria, TF e grafica.</span><span class="sxs-lookup"><span data-stu-id="56dc9-139">Other options include binary, TF, and graph weighing.</span></span>

<span data-ttu-id="56dc9-140">Funzioni di testo come queste sono spesso caratterizzate da alta dimensionalità.</span><span class="sxs-lookup"><span data-stu-id="56dc9-140">Such text features often have high dimensionality.</span></span> <span data-ttu-id="56dc9-141">Ad esempio, se il corpo ha 100.000 parole univoche, lo spazio di funzioni avrà 100.000 dimensioni o più se vengono usati gli n-grammi.</span><span class="sxs-lookup"><span data-stu-id="56dc9-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span></span> <span data-ttu-id="56dc9-142">Il modulo Extract N-Gram Features offre un gruppo di opzioni per ridurre la dimensionalità.</span><span class="sxs-lookup"><span data-stu-id="56dc9-142">The Extract N-Gram Features module gives you a set of options to reduce the dimensionality.</span></span> <span data-ttu-id="56dc9-143">È possibile scegliere di escludere le parole che sono brevi o lunghe o troppo insolite o frequenti per avere un valore predittivo significativo.</span><span class="sxs-lookup"><span data-stu-id="56dc9-143">You can choose to exclude words that are short or long, or too uncommon or too frequent to have significant predictive value.</span></span> <span data-ttu-id="56dc9-144">In questa esercitazione si escludono gli n-grammi che vengono visualizzati in meno di 5 record o in più dell'80% dei record.</span><span class="sxs-lookup"><span data-stu-id="56dc9-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span></span>

<span data-ttu-id="56dc9-145">Inoltre è possibile usare la selezione delle funzioni per selezionare solo le funzioni che sono maggiormente correlate con il target di stima.</span><span class="sxs-lookup"><span data-stu-id="56dc9-145">Also, you can use feature selection to select only those features that are the most correlated with your prediction target.</span></span> <span data-ttu-id="56dc9-146">Si usa la selezione di funzioni chi quadro per selezionare 1000 funzioni.</span><span class="sxs-lookup"><span data-stu-id="56dc9-146">We use Chi-Squared feature selection to select 1000 features.</span></span> <span data-ttu-id="56dc9-147">È possibile visualizzare il vocabolario di parole o n-grammi selezionati facendo clic sull'output giusto del modulo Extract N-Gram Features.</span><span class="sxs-lookup"><span data-stu-id="56dc9-147">You can view the vocabulary of selected words or N-grams by clicking the right output of Extract N-grams module.</span></span>

<span data-ttu-id="56dc9-148">In alternativa all'uso al modulo Extract N-Gram Features è possibile usare il modulo Feature Hashing.</span><span class="sxs-lookup"><span data-stu-id="56dc9-148">As an alternative approach to using Extract N-Gram Features, you can use Feature Hashing module.</span></span> <span data-ttu-id="56dc9-149">Si noti tuttavia che [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) non dispone di capacità integrate di selezione delle funzioni o di ponderazione TF*IDF.</span><span class="sxs-lookup"><span data-stu-id="56dc9-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF*IDF weighing.</span></span>

## <a name="step-3-train-classification-or-regression-model"></a><span data-ttu-id="56dc9-150">Passaggio 3: Addestrare il modello di classificazione o regressione</span><span class="sxs-lookup"><span data-stu-id="56dc9-150">Step 3: Train classification or regression model</span></span>
<span data-ttu-id="56dc9-151">Il testo è stato ora trasformato in colonne di caratteristiche numeriche.</span><span class="sxs-lookup"><span data-stu-id="56dc9-151">Now the text has been transformed to numeric feature columns.</span></span> <span data-ttu-id="56dc9-152">Il set di dati contiene ancora le colonne di stringhe dalle fasi precedenti, perciò usiamo Select Columns in Dataset per escluderle.</span><span class="sxs-lookup"><span data-stu-id="56dc9-152">The dataset still contains string columns from previous stages, so we use Select Columns in Dataset to exclude them.</span></span>

<span data-ttu-id="56dc9-153">Usiamo poi [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) per stimare il target: punteggio di recensione alto o basso.</span><span class="sxs-lookup"><span data-stu-id="56dc9-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) to predict our target: high or low review score.</span></span> <span data-ttu-id="56dc9-154">A questo punto il problema di analisi del testo è stato trasformato in un normale problema di classificazione.</span><span class="sxs-lookup"><span data-stu-id="56dc9-154">At this point, the text analytics problem has been transformed into a regular classification problem.</span></span> <span data-ttu-id="56dc9-155">È possibile usare gli strumenti disponibili in Azure Machine Learning per migliorare il modello.</span><span class="sxs-lookup"><span data-stu-id="56dc9-155">You can use the tools available in Azure Machine Learning to improve the model.</span></span> <span data-ttu-id="56dc9-156">Ad esempio è possibile sperimentare diversi classificatori per scoprire l'accuratezza dei loro risultati o usare l'ottimizzazione con iperparametri per migliorare l'accuratezza.</span><span class="sxs-lookup"><span data-stu-id="56dc9-156">For example, you can experiment with different classifiers to find out how accurate results they give, or use hyperparameter tuning to improve the accuracy.</span></span>

![Addestramento e assegnazione dei punteggi](./media/machine-learning-text-analytics-module-tutorial/scoring-text.png)

## <a name="step-4-score-and-validate-the-model"></a><span data-ttu-id="56dc9-158">Passaggio 4: Assegnare un punteggio e convalidare il modello</span><span class="sxs-lookup"><span data-stu-id="56dc9-158">Step 4: Score and validate the model</span></span>
<span data-ttu-id="56dc9-159">Come si convalida il modello addestrato?</span><span class="sxs-lookup"><span data-stu-id="56dc9-159">How would you validate the trained model?</span></span> <span data-ttu-id="56dc9-160">Si assegna un punteggio rispetto al set di dati di test e si valuta l'accuratezza.</span><span class="sxs-lookup"><span data-stu-id="56dc9-160">We score it against the test dataset and evaluate the accuracy.</span></span> <span data-ttu-id="56dc9-161">Tuttavia, il modello ha appreso il vocabolario degli n-grammi e i loro pesi del set di dati di addestramento.</span><span class="sxs-lookup"><span data-stu-id="56dc9-161">However, the model learned the vocabulary of N-grams and their weights from the training dataset.</span></span> <span data-ttu-id="56dc9-162">Pertanto, sarà necessario usare quel vocabolario e quei pesi per l'estrazione delle funzioni dai dati di test, invece di creare il vocabolario di nuovo.</span><span class="sxs-lookup"><span data-stu-id="56dc9-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed to creating the vocabulary anew.</span></span> <span data-ttu-id="56dc9-163">Si aggiunge perciò il modulo Extract N-Gram Features al ramo di assegnazione del punteggio dell'esperimento, si connette il vocabolario di output dal ramo di addestramento e si imposta la modalità di vocabolario in sola lettura.</span><span class="sxs-lookup"><span data-stu-id="56dc9-163">Therefore, we add Extract N-Gram Features module to the scoring branch of the experiment, connect the output vocabulary from training branch, and set the vocabulary mode to read-only.</span></span> <span data-ttu-id="56dc9-164">Si disattiva inoltre il filtro di n-grammi per frequenza impostando il minimo su 1 istanza e il massimo su 100% e si disattiva la selezione delle funzioni.</span><span class="sxs-lookup"><span data-stu-id="56dc9-164">We also disable the filtering of N-grams by frequency by setting the minimum to 1 instance and maximum to 100%, and turn off the feature selection.</span></span>

<span data-ttu-id="56dc9-165">Dopo che la colonna di testo nei dati di test è stata trasformata in colonne di caratteristiche numeriche, si escludono le colonne stringa delle fasi precedenti come nel ramo di addestramento.</span><span class="sxs-lookup"><span data-stu-id="56dc9-165">After the text column in test data has been transformed to numeric feature columns, we exclude the string columns from previous stages like in training branch.</span></span> <span data-ttu-id="56dc9-166">Si usa poi il modulo Score Model per eseguire stime e il modulo Evaluate Model per valutare l'accuratezza.</span><span class="sxs-lookup"><span data-stu-id="56dc9-166">We then use Score Model module to make predictions and Evaluate Model module to evaluate the accuracy.</span></span>

## <a name="step-5-deploy-the-model-to-production"></a><span data-ttu-id="56dc9-167">Passaggio 5: Distribuire il modello in produzione</span><span class="sxs-lookup"><span data-stu-id="56dc9-167">Step 5: Deploy the model to production</span></span>
<span data-ttu-id="56dc9-168">Il modello è quasi pronto per essere distribuito nell'ambiente di produzione.</span><span class="sxs-lookup"><span data-stu-id="56dc9-168">The model is almost ready to be deployed to production.</span></span> <span data-ttu-id="56dc9-169">Se viene distribuito come servizio Web, accetta una stringa di testo in formato libero come input e restituisce una stima "alta" o "bassa".</span><span class="sxs-lookup"><span data-stu-id="56dc9-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span></span> <span data-ttu-id="56dc9-170">Usa il vocabolario di n-grammi appreso per trasformare il testo in funzioni e il modello di regressione logistica addestrato per effettuare una previsione da queste funzioni.</span><span class="sxs-lookup"><span data-stu-id="56dc9-170">It uses the learned N-gram vocabulary to transform the text to features, and trained logistic regression model to make a prediction from those features.</span></span> 

<span data-ttu-id="56dc9-171">Per configurare l'esperimento predittivo è innanzitutto necessario salvare il vocabolario di n-grammi come set di dati e il modello di regressione logistica addestrato del ramo di addestramento dell'esperimento.</span><span class="sxs-lookup"><span data-stu-id="56dc9-171">To set up the predictive experiment, we first save the N-gram vocabulary as dataset, and the trained logistic regression model from the training branch of the experiment.</span></span> <span data-ttu-id="56dc9-172">Quindi si salva l'esperimento usando "Salva con nome" per creare un grafico per l'esperimento predittivo.</span><span class="sxs-lookup"><span data-stu-id="56dc9-172">Then, we save the experiment using "Save As" to create an experiment graph for predictive experiment.</span></span> <span data-ttu-id="56dc9-173">Si rimuove il modulo Split Data e il ramo di addestramento dall'esperimento.</span><span class="sxs-lookup"><span data-stu-id="56dc9-173">We remove the Split Data module and the training branch from the experiment.</span></span> <span data-ttu-id="56dc9-174">Quindi si collega il vocabolario di n-grammi e il modello salvati in precedenza rispettivamente ai moduli Extract N-Gram Features e Score Model.</span><span class="sxs-lookup"><span data-stu-id="56dc9-174">We then connect the previously saved N-gram vocabulary and model to Extract N-Gram Features and Score Model modules, respectively.</span></span> <span data-ttu-id="56dc9-175">Si rimuove anche il modulo Evaluate Model.</span><span class="sxs-lookup"><span data-stu-id="56dc9-175">We also remove the Evaluate Model module.</span></span>

<span data-ttu-id="56dc9-176">Si inseriscono le colonne selezionate nel modulo Select Columns in Dataset prima del modulo Preprocess Text per rimuovere la colonna di etichette e si deseleziona l'opzione "Aggiungi colonna punteggio al set di dati" nel modulo Score Model.</span><span class="sxs-lookup"><span data-stu-id="56dc9-176">We insert Select Columns in Dataset module before Preprocess Text module to remove the label column, and unselect "Append score column to dataset" option in Score Module.</span></span> <span data-ttu-id="56dc9-177">In questo modo il servizio Web non richiede l'etichetta che tenta di prevedere e non riproduce le funzioni di input come risposta.</span><span class="sxs-lookup"><span data-stu-id="56dc9-177">That way, the web service does not request the label it is trying to predict, and does not echo the input features in response.</span></span>

![Esperimento predittivo](./media/machine-learning-text-analytics-module-tutorial/predictive-text.png)

<span data-ttu-id="56dc9-179">Ora abbiamo un esperimento che può essere pubblicato come servizio Web e chiamato mediante le API di richiesta-risposta o di esecuzione in batch.</span><span class="sxs-lookup"><span data-stu-id="56dc9-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="56dc9-180">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="56dc9-180">Next Steps</span></span>
<span data-ttu-id="56dc9-181">Per informazioni sui moduli di analisi del testo, vedere la [documentazione su MSDN](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span><span class="sxs-lookup"><span data-stu-id="56dc9-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span></span>

