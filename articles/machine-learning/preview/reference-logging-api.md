---
title: Informazioni di riferimento sulle API di registrazione ML di Azure | Documentazione Microsoft
description: Informazioni di riferimento sulle API di registrazione.
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ms.openlocfilehash: 1906425c6657fb6232a9dc306b05f9171c9c7bef
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 10/11/2017
---
# <a name="logging-api-reference"></a>Informazioni di riferimento sulle API di registrazione

La raccolta di registrazione ML di Azure consente al programma generare metriche e file che vengono rilevati dal servizio di cronologia per l'analisi successiva. Attualmente, sono supportati alcuni tipi di metriche e file di base e il set di tipi supportati aumenterà con le versioni future del pacchetto Python.

## <a name="uploading-metrics"></a>Metriche di caricamento

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

Per impostazione predefinita, tutte le metriche vengono inviate in maniera asincrona, in modo che l'invio non impedisca l'esecuzione del programma. Quando più metriche vengono inviate in casi limite, ciò può causare problemi di ordinamento. Un esempio è costituito da due metriche registrate contemporaneamente, ma per qualche motivo l'utente preferisce mantenere l'ordine esatto. Un altro caso si verifica quando la metrica deve essere rilevata prima di eseguire un codice che è noto per avere potenzialmente esito negativo in modo rapido. In entrambi i casi, la soluzione consiste nell’_attendere_ fino a quando la metrica non viene registrata completamente prima di procedere:

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>Utilizzo delle metriche

Le metriche sono archiviate dal servizio di cronologia e associate all'esecuzione che le ha prodotte. Sia la scheda di cronologia di esecuzione sia il comando CLI riportato di seguito consentono di recuperare questi (e gli elementi di seguito) dopo che un'esecuzione è stata completata.

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>Elementi (file)

Oltre alle metriche, Azure ML consente all'utente di tenere traccia anche dei file. Per impostazione predefinita, tutti i file scritti nella cartella `outputs` relativa alla directory di lavoro del programma (la cartella di progetto nel contesto di calcolo) vengono caricati nel servizio di cronologia e registrati per analisi successive. Il problema è che le dimensioni dei singoli file devono essere inferiori a 512 MB.


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>Utilizzo di elementi

Per stampare il contenuto di un elemento che è stato rilevato, l’utente può utilizzare la scheda di cronologia di esecuzione per l'esecuzione specificata per **scaricare** o **alzare di livello** l'elemento o usare i comandi CLI seguenti per ottenere lo stesso effetto.

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>Passaggi successivi
- Scorrere le [esercitazioni di diaframma di classificazione, parte 2](tutorial-classifying-iris-part-2.md) per visualizzare la registrazione API in azione.
- Rivedere [Come usare Cronologia di esecuzione e le metriche del modello in Azure Machine Learning Workbench](how-to-use-run-history-model-metrics.md) per comprendere più approfonditamente come le API di registrazione possano essere usate nella cronologia di esecuzione.
