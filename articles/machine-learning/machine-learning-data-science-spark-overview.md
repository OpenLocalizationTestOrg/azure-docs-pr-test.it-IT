---
title: aaaOverview dell'analisi scientifica dei dati utilizzando Spark in HDInsight di Azure | Documenti Microsoft
description: "Hello Spark MLlib toolkit offre funzionalità toohello distribuita HDInsight ambiente di modellazione apprendimento considerevole."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="539bc-103">Panoramica dell'analisi scientifica dei dati con Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="539bc-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="539bc-104">In questo gruppo di argomenti viene illustrato come attività di toouse HDInsight Spark toocomplete comuni analisi scientifica dei dati, ad esempio l'inserimento di dati, progettazione di funzionalità, modellazione e valutazione del modello.</span><span class="sxs-lookup"><span data-stu-id="539bc-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="539bc-105">dati Hello utilizzati sono un esempio di hello 2013 NYC taxi di andata e ritorno e tariffa set di dati.</span><span class="sxs-lookup"><span data-stu-id="539bc-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="539bc-106">i modelli di Hello compilati includono la regressione logistica e lineare, foreste casuali e sfumati alberi con Boosting.</span><span class="sxs-lookup"><span data-stu-id="539bc-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="539bc-107">Hello argomenti anche mostrano come toostore questi modelli in Azure blob storage (WASB) e in che modo tooscore e valutare le prestazioni predittiva.</span><span class="sxs-lookup"><span data-stu-id="539bc-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="539bc-108">Argomenti più avanzati illustrano le modalità di training dei modelli con la convalida incrociata e lo sweep di iperparametri.</span><span class="sxs-lookup"><span data-stu-id="539bc-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="539bc-109">Questo argomento introduttivo fa anche riferimento argomenti hello che descrivono come tooset backup hello cluster Spark necessari passaggi di hello toocomplete nelle procedure dettagliate di hello fornite.</span><span class="sxs-lookup"><span data-stu-id="539bc-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="539bc-110">Spark e MLlib</span><span class="sxs-lookup"><span data-stu-id="539bc-110">Spark and MLlib</span></span>
<span data-ttu-id="539bc-111">[Spark](http://spark.apache.org/) è un framework di elaborazione parallela open source che supporta in memoria prestazioni di elaborazione tooboost hello delle applicazioni analitiche big data.</span><span class="sxs-lookup"><span data-stu-id="539bc-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="539bc-112">motore di elaborazione Spark Hello viene compilato per la velocità, semplicità di utilizzo e analitica sofisticate.</span><span class="sxs-lookup"><span data-stu-id="539bc-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="539bc-113">La funzionalità di calcolo distribuito in memoria di Spark è molto adatto per algoritmi di hello iterativo usato nei calcoli di machine learning e graph.</span><span class="sxs-lookup"><span data-stu-id="539bc-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="539bc-114">[MLlib](http://spark.apache.org/mllib/) è libreria di apprendimento di Spark scalabile di macchine che mette a disposizione hello algoritmico modellazione ambiente distribuito toothis di funzionalità.</span><span class="sxs-lookup"><span data-stu-id="539bc-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="539bc-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="539bc-115">HDInsight Spark</span></span>
<span data-ttu-id="539bc-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) hello Azure ospitata offerta di Spark open source.</span><span class="sxs-lookup"><span data-stu-id="539bc-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="539bc-117">Include inoltre il supporto per **Jupyter PySpark notebook** in cluster Spark hello che è possibile eseguire query interattive di Spark SQL per la trasformazione, filtro e visualizzazione dei dati archiviati nel BLOB di Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="539bc-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="539bc-118">PySpark è hello API Python per Spark.</span><span class="sxs-lookup"><span data-stu-id="539bc-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="539bc-119">frammenti di codice Hello che forniscono soluzioni hello e visualizzare i dati di hello tracciati rilevanti toovisualize hello qui eseguiti in server Jupyter notebook installato nel cluster Spark hello.</span><span class="sxs-lookup"><span data-stu-id="539bc-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="539bc-120">passaggi di modellazione Hello in questi argomenti contengono codice che illustra come tootrain, valutare, salvare e utilizzare ogni tipo di modello.</span><span class="sxs-lookup"><span data-stu-id="539bc-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="539bc-121">Configurazione: cluster Spark e notebook di Jupyter</span><span class="sxs-lookup"><span data-stu-id="539bc-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="539bc-122">La procedura di installazione e il codice forniti in questa procedura dettagliata sono per l'uso di un HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="539bc-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="539bc-123">Ma vengono forniti i notebook di Jupyter per i cluster HDInsight sia Spark 1.6 sia Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="539bc-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="539bc-124">Vengono forniti una descrizione di hello blocchi appunti e collegamenti toothem in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) per il repository di GitHub hello che li contengono.</span><span class="sxs-lookup"><span data-stu-id="539bc-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="539bc-125">Inoltre, codice hello qui e i notebook hello collegato è generico e dovrebbe funzionare in un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="539bc-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="539bc-126">Se non si utilizza HDInsight Spark, passaggi di configurazione e gestione di cluster hello potrebbero essere leggermente diversi rispetto a quanto mostrato di seguito.</span><span class="sxs-lookup"><span data-stu-id="539bc-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="539bc-127">Per praticità, di seguito sono collegamenti hello toohello Jupyter notebook per Spark 1.6 (toobe eseguito nel kernel pySpark hello di hello server Jupyter Notebook) e Spark 2.0 (toobe eseguito nel kernel pySpark3 hello di hello server Jupyter Notebook):</span><span class="sxs-lookup"><span data-stu-id="539bc-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="539bc-128">Notebook Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="539bc-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="539bc-129">Questi blocchi appunti sono toobe eseguito nel kernel pySpark hello del server Jupyter notebook.</span><span class="sxs-lookup"><span data-stu-id="539bc-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="539bc-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): fornisce informazioni su come l'esplorazione dei dati tooperform, modellazione e assegnazione dei punteggi con diversi algoritmi.</span><span class="sxs-lookup"><span data-stu-id="539bc-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="539bc-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): include gli argomenti nel notebook numero 1 e modella lo sviluppo usando l'ottimizzazione degli iperparametri e la convalida incrociata.</span><span class="sxs-lookup"><span data-stu-id="539bc-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="539bc-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): mostra come toooperationalize un modello salvato usando Python in HDInsight cluster.</span><span class="sxs-lookup"><span data-stu-id="539bc-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="539bc-133">Notebook Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="539bc-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="539bc-134">Questi blocchi appunti sono toobe eseguito nel kernel pySpark3 hello del server Jupyter notebook.</span><span class="sxs-lookup"><span data-stu-id="539bc-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="539bc-135">[Spark2.0-pySpark3-Machine-Learning-data-Science-Spark-Advanced-Data-Exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): questo file fornisce informazioni su come l'esplorazione dei dati tooperform, modellazione e assegnazione dei punteggi in Spark 2.0 cluster tramite hello viaggi NYC Taxi e set di dati tariffa descritto [qui](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="539bc-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="539bc-136">Questo blocco può essere un buon punto di partenza per esplorare rapidamente codice hello che è stato fornito per Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="539bc-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="539bc-137">Per un blocco per Appunti più dettagliata analizza hello dati NYC Taxi, vedere notebook avanti di hello in questo elenco.</span><span class="sxs-lookup"><span data-stu-id="539bc-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="539bc-138">Vedere le note di hello seguendo questo elenco di confrontare questi notebook.</span><span class="sxs-lookup"><span data-stu-id="539bc-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="539bc-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): questo file viene illustrato come tooperform dati wrangling (operazioni Spark SQL e frame di dati), l'esplorazione, modellazione e assegnazione dei punteggi usando hello viaggi NYC Taxi e tariffa set di dati descritto [ qui](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="539bc-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="539bc-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): questo file viene illustrato come tooperform dati wrangling (operazioni Spark SQL e frame di dati), l'esplorazione, modellazione e assegnazione dei punteggi usando hello partenza in fase di Airline noto set di dati da 2011 e 2012.</span><span class="sxs-lookup"><span data-stu-id="539bc-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="539bc-141">È integrato hello airline dataset con hello aeroporto weather dati (ad esempio, velocità del vento, temperatura, altitudine e così via) precedenti toomodeling, in modo queste funzionalità weather possono essere incluso nel modello di hello.</span><span class="sxs-lookup"><span data-stu-id="539bc-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="539bc-142">set di dati airline Hello è stato aggiunto notebook toohello Spark 2.0 toobetter illustrano l'utilizzo di hello di algoritmi di classificazione.</span><span class="sxs-lookup"><span data-stu-id="539bc-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="539bc-143">Vedere i seguenti collegamenti per informazioni sui set di dati in fase di partenza airline e set di dati meteo hello:</span><span class="sxs-lookup"><span data-stu-id="539bc-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="539bc-144">Dati sulle partenze puntuali dei voli della compagnia aerea: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="539bc-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="539bc-145">Dati sulle condizioni atmosferiche dell'aeroporto: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="539bc-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="539bc-146">Appunti di Spark 2.0 Hello in hello taxi NYC e airline flight delay-set di dati può richiedere 10 minuti o più toorun (a seconda delle dimensioni di hello del cluster HDI).</span><span class="sxs-lookup"><span data-stu-id="539bc-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="539bc-147">primo notebook in hello sopra elenco Hello Mostra molti aspetti di esplorazione dei dati di hello, training in un blocco per Appunti che accetta toorun meno tempo con ridotti NYC set di dati, in cui hello sono stati già aggiunti a un file taxi e fare del modello di visualizzazione e ML: [ Spark2.0-pySpark3-Machine-Learning-data-Science-Spark-Advanced-Data-Exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) il blocco accetta un molto più breve tempo toofinish (2-3 minuti) e può essere un buon punto di partenza per esplorare rapidamente codice hello abbiamo fornito per Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="539bc-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="539bc-148">Per indicazioni su come rendere operativo hello un modello Spark 2.0 e l'utilizzo di modello per il punteggio, vedere hello [Spark 1.6 documento sul consumo](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) per un esempio di struttura passaggi hello necessari.</span><span class="sxs-lookup"><span data-stu-id="539bc-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="539bc-149">toouse questo su Spark 2.0, sostituire i file di codice Python hello con [questo file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="539bc-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="539bc-150">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="539bc-150">Prerequisites</span></span>
<span data-ttu-id="539bc-151">Hello, seguire le procedure seguenti è correlati tooSpark 1.6.</span><span class="sxs-lookup"><span data-stu-id="539bc-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="539bc-152">Per la versione di hello Spark 2.0, usare hello notebook descritto e collegati toopreviously.</span><span class="sxs-lookup"><span data-stu-id="539bc-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="539bc-153">1. È necessario avere una sottoscrizione di Azure.</span><span class="sxs-lookup"><span data-stu-id="539bc-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="539bc-154">Se non è già disponibile, vedere l'articolo che illustra [come ottenere una versione di valutazione gratuita di Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="539bc-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="539bc-155">2. è necessario un toocomplete cluster Spark 1.6 questa procedura dettagliata.</span><span class="sxs-lookup"><span data-stu-id="539bc-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="539bc-156">toocreate uno, vedere le istruzioni di hello fornite [Introduzione: creare Apache Spark in Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="539bc-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="539bc-157">viene specificato il tipo di cluster Hello e la versione da hello **Seleziona tipo di Cluster** menu.</span><span class="sxs-lookup"><span data-stu-id="539bc-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![Configurare il cluster](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="539bc-159">Per un argomento che illustra come toouse Scala anziché Python toocomplete attività per un processo di analisi scientifica dei dati end-to-end, vedere hello [analisi scientifica dei dati con Scala Spark in Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="539bc-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="539bc-160">Hello dati NYC 2013 Taxi</span><span class="sxs-lookup"><span data-stu-id="539bc-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="539bc-161">dati di andata e ritorno Taxi NYC Hello è di circa 20 GB di file compressi valori delimitati da virgole (CSV) (~ 48 GB non compressi), che comprendono 173 milioni hello e singoli trip tariffe a pagamento per ogni itinerario.</span><span class="sxs-lookup"><span data-stu-id="539bc-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="539bc-162">Ogni record di andata e ritorno include hello preleva deposito e ora, hack anonimi (driver) il numero di licenza e numero medallion (id univoco del taxi).</span><span class="sxs-lookup"><span data-stu-id="539bc-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="539bc-163">dati Hello copre tutti i percorsi nell'anno hello 2013 e viene forniti in hello dopo i due set di dati per ogni mese:</span><span class="sxs-lookup"><span data-stu-id="539bc-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="539bc-164">file CSV di Hello 'trip_data' contengono i dettagli di andata e ritorno, ad esempio il numero di persone, sollevare e dropoff punta, attivarsi durata e la lunghezza di andata e ritorno.</span><span class="sxs-lookup"><span data-stu-id="539bc-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="539bc-165">Di seguito vengono forniti alcuni record di esempio:</span><span class="sxs-lookup"><span data-stu-id="539bc-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="539bc-166">file CSV di Hello 'trip_fare' contengono i dettagli della tariffa di hello pagata per ogni itinerario, ad esempio il tipo di pagamento, quantità tariffa, supplemento e le imposte, suggerimenti e pedaggio e hello totale pagato.</span><span class="sxs-lookup"><span data-stu-id="539bc-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="539bc-167">Di seguito vengono forniti alcuni record di esempio:</span><span class="sxs-lookup"><span data-stu-id="539bc-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="539bc-168">È stato reindirizzato a un campione di 0,1% di questi file e di andata e ritorno hello unita in join\_dati e andata e ritorno\_presentare file CVS in toouse un singolo set di dati come set di dati input hello per questa procedura dettagliata.</span><span class="sxs-lookup"><span data-stu-id="539bc-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="539bc-169">viaggi toojoin chiave univoca Hello\_dati e andata e ritorno\_tariffa è costituito da campi hello: medallion, le maggiori\_titolo e prelievo\_datetime.</span><span class="sxs-lookup"><span data-stu-id="539bc-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="539bc-170">Ogni record del set di dati hello contiene hello gli attributi che rappresentano un trip NYC Taxi seguenti:</span><span class="sxs-lookup"><span data-stu-id="539bc-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="539bc-171">Campo</span><span class="sxs-lookup"><span data-stu-id="539bc-171">Field</span></span> | <span data-ttu-id="539bc-172">Breve descrizione</span><span class="sxs-lookup"><span data-stu-id="539bc-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="539bc-173">medallion</span><span class="sxs-lookup"><span data-stu-id="539bc-173">medallion</span></span> |<span data-ttu-id="539bc-174">Numero di licenza anonimo (ID univoco del taxi).</span><span class="sxs-lookup"><span data-stu-id="539bc-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="539bc-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="539bc-175">hack_license</span></span> |<span data-ttu-id="539bc-176">Numero di licenza anonimo di vetture a noleggio</span><span class="sxs-lookup"><span data-stu-id="539bc-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="539bc-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="539bc-177">vendor_id</span></span> |<span data-ttu-id="539bc-178">ID del fornitore del taxi</span><span class="sxs-lookup"><span data-stu-id="539bc-178">Taxi vendor id</span></span> |
| <span data-ttu-id="539bc-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="539bc-179">rate_code</span></span> |<span data-ttu-id="539bc-180">Tariffe dei taxi di NYC</span><span class="sxs-lookup"><span data-stu-id="539bc-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="539bc-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="539bc-181">store_and_fwd_flag</span></span> |<span data-ttu-id="539bc-182">Contrassegno di registrazione e inoltro</span><span class="sxs-lookup"><span data-stu-id="539bc-182">Store and forward flag</span></span> |
| <span data-ttu-id="539bc-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="539bc-183">pickup_datetime</span></span> |<span data-ttu-id="539bc-184">Data e ora di partenza</span><span class="sxs-lookup"><span data-stu-id="539bc-184">Pick up date & time</span></span> |
| <span data-ttu-id="539bc-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="539bc-185">dropoff_datetime</span></span> |<span data-ttu-id="539bc-186">Data e ora di arrivo</span><span class="sxs-lookup"><span data-stu-id="539bc-186">Dropoff date & time</span></span> |
| <span data-ttu-id="539bc-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="539bc-187">pickup_hour</span></span> |<span data-ttu-id="539bc-188">Ora di partenza</span><span class="sxs-lookup"><span data-stu-id="539bc-188">Pick up hour</span></span> |
| <span data-ttu-id="539bc-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="539bc-189">pickup_week</span></span> |<span data-ttu-id="539bc-190">Prelevare settimana dell'anno hello</span><span class="sxs-lookup"><span data-stu-id="539bc-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="539bc-191">weekday</span><span class="sxs-lookup"><span data-stu-id="539bc-191">weekday</span></span> |<span data-ttu-id="539bc-192">Giorno della settimana (intervallo 1-7)</span><span class="sxs-lookup"><span data-stu-id="539bc-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="539bc-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="539bc-193">passenger_count</span></span> |<span data-ttu-id="539bc-194">Numero di passeggeri in una corsa del taxi</span><span class="sxs-lookup"><span data-stu-id="539bc-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="539bc-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="539bc-195">trip_time_in_secs</span></span> |<span data-ttu-id="539bc-196">Tempo delle corse in secondi</span><span class="sxs-lookup"><span data-stu-id="539bc-196">Trip time in seconds</span></span> |
| <span data-ttu-id="539bc-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="539bc-197">trip_distance</span></span> |<span data-ttu-id="539bc-198">Distanza delle corse percorsa in miglia</span><span class="sxs-lookup"><span data-stu-id="539bc-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="539bc-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="539bc-199">pickup_longitude</span></span> |<span data-ttu-id="539bc-200">Longitudine di partenza</span><span class="sxs-lookup"><span data-stu-id="539bc-200">Pick up longitude</span></span> |
| <span data-ttu-id="539bc-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="539bc-201">pickup_latitude</span></span> |<span data-ttu-id="539bc-202">Latitudine di partenza</span><span class="sxs-lookup"><span data-stu-id="539bc-202">Pick up latitude</span></span> |
| <span data-ttu-id="539bc-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="539bc-203">dropoff_longitude</span></span> |<span data-ttu-id="539bc-204">Longitudine di arrivo</span><span class="sxs-lookup"><span data-stu-id="539bc-204">Dropoff longitude</span></span> |
| <span data-ttu-id="539bc-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="539bc-205">dropoff_latitude</span></span> |<span data-ttu-id="539bc-206">Latitudine di arrivo</span><span class="sxs-lookup"><span data-stu-id="539bc-206">Dropoff latitude</span></span> |
| <span data-ttu-id="539bc-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="539bc-207">direct_distance</span></span> |<span data-ttu-id="539bc-208">Distanza diretta tra le località di partenza e di arrivo</span><span class="sxs-lookup"><span data-stu-id="539bc-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="539bc-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="539bc-209">payment_type</span></span> |<span data-ttu-id="539bc-210">Tipo di pagamento (contanti, carta di credito e così via).</span><span class="sxs-lookup"><span data-stu-id="539bc-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="539bc-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="539bc-211">fare_amount</span></span> |<span data-ttu-id="539bc-212">Imposto della tariffa in</span><span class="sxs-lookup"><span data-stu-id="539bc-212">Fare amount in</span></span> |
| <span data-ttu-id="539bc-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="539bc-213">surcharge</span></span> |<span data-ttu-id="539bc-214">Sovrapprezzo</span><span class="sxs-lookup"><span data-stu-id="539bc-214">Surcharge</span></span> |
| <span data-ttu-id="539bc-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="539bc-215">mta_tax</span></span> |<span data-ttu-id="539bc-216">Tassa MTA</span><span class="sxs-lookup"><span data-stu-id="539bc-216">Mta tax</span></span> |
| <span data-ttu-id="539bc-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="539bc-217">tip_amount</span></span> |<span data-ttu-id="539bc-218">Importo delle mance</span><span class="sxs-lookup"><span data-stu-id="539bc-218">Tip amount</span></span> |
| <span data-ttu-id="539bc-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="539bc-219">tolls_amount</span></span> |<span data-ttu-id="539bc-220">Importo dei pedaggi</span><span class="sxs-lookup"><span data-stu-id="539bc-220">Tolls amount</span></span> |
| <span data-ttu-id="539bc-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="539bc-221">total_amount</span></span> |<span data-ttu-id="539bc-222">Importo totale</span><span class="sxs-lookup"><span data-stu-id="539bc-222">Total amount</span></span> |
| <span data-ttu-id="539bc-223">tipped</span><span class="sxs-lookup"><span data-stu-id="539bc-223">tipped</span></span> |<span data-ttu-id="539bc-224">Mancia lasciata (0/1 per no o sì)</span><span class="sxs-lookup"><span data-stu-id="539bc-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="539bc-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="539bc-225">tip_class</span></span> |<span data-ttu-id="539bc-226">Categoria mance (0: $ 0, 1: $ 0-5, 2: $ 6-10, 3: $ 11-20, 4: > $ 20)</span><span class="sxs-lookup"><span data-stu-id="539bc-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="539bc-227">Eseguire il codice da un server Jupyter notebook nel cluster Spark hello</span><span class="sxs-lookup"><span data-stu-id="539bc-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="539bc-228">È possibile avviare hello server Jupyter Notebook da hello portale di Azure.</span><span class="sxs-lookup"><span data-stu-id="539bc-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="539bc-229">Trovare il cluster Spark nel dashboard e farvi clic sopra tooenter pagina di gestione per il cluster.</span><span class="sxs-lookup"><span data-stu-id="539bc-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="539bc-230">Fare clic su Blocco note hello tooopen associato al cluster Spark hello, **dashboard del Cluster** -> **server Jupyter Notebook** .</span><span class="sxs-lookup"><span data-stu-id="539bc-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Dashboard del cluster](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="539bc-232">È inoltre possibile esplorare troppo***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter notebook.</span><span class="sxs-lookup"><span data-stu-id="539bc-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="539bc-233">Sostituisce parte CLUSTERNAME hello di questo URL con nome hello di un cluster personale.</span><span class="sxs-lookup"><span data-stu-id="539bc-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="539bc-234">È necessario password hello per notebook amministratore account tooaccess hello.</span><span class="sxs-lookup"><span data-stu-id="539bc-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![Sfogliare i notebook di Jupyter](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="539bc-236">Selezionare PySpark toosee una directory che contiene alcuni esempi di Appunti sotto forma di pacchetto che utilizzano hello notebook PySpark API.hello che contengono gli esempi di codice hello per il gruppo di argomento Spark sono disponibili in [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="539bc-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="539bc-237">È possibile caricare notebook hello direttamente da [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello server notebook jupyter il cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="539bc-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="539bc-238">Scegliere hello hello home page del server Jupyter **caricare** pulsante nella parte destra della schermata di hello hello.</span><span class="sxs-lookup"><span data-stu-id="539bc-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="539bc-239">Verrà visualizzata una finestra di esplorazione file,</span><span class="sxs-lookup"><span data-stu-id="539bc-239">It opens a file explorer.</span></span> <span data-ttu-id="539bc-240">Qui è possibile incollare l'URL di GitHub (contenuto non elaborato) hello di hello Notebook e fare clic su **aprire**.</span><span class="sxs-lookup"><span data-stu-id="539bc-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="539bc-241">Vedrai il nome di file hello dell'elenco di file server Jupyter con un **caricare** nuovamente clic sul pulsante.</span><span class="sxs-lookup"><span data-stu-id="539bc-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="539bc-242">Fare clic sul pulsante **Upload** (Carica).</span><span class="sxs-lookup"><span data-stu-id="539bc-242">Click this **Upload** button.</span></span> <span data-ttu-id="539bc-243">A questo punto sono stati importati notebook hello.</span><span class="sxs-lookup"><span data-stu-id="539bc-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="539bc-244">Ripetere questi hello tooupload passaggi altri blocchi appunti di questa procedura dettagliata.</span><span class="sxs-lookup"><span data-stu-id="539bc-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="539bc-245">È possibile fare doppio clic su collegamenti hello del browser e selezionare **Copia collegamento** tooget hello URL contenuto non elaborato a github.</span><span class="sxs-lookup"><span data-stu-id="539bc-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="539bc-246">È possibile incollare l'URL in hello Jupyter caricare file Esplora la finestra di dialogo.</span><span class="sxs-lookup"><span data-stu-id="539bc-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="539bc-247">A questo punto è possibile:</span><span class="sxs-lookup"><span data-stu-id="539bc-247">Now you can:</span></span>

* <span data-ttu-id="539bc-248">Visualizzare codice hello facendo notebook hello.</span><span class="sxs-lookup"><span data-stu-id="539bc-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="539bc-249">Eseguire ogni cella premendo **MAIUSC+INVIO**.</span><span class="sxs-lookup"><span data-stu-id="539bc-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="539bc-250">Eseguire l'intero blocco hello facendo clic su **cella** -> **eseguire**.</span><span class="sxs-lookup"><span data-stu-id="539bc-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="539bc-251">Utilizzare hello visualizzazione automatica delle query.</span><span class="sxs-lookup"><span data-stu-id="539bc-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="539bc-252">kernel PySpark Hello Visualizza automaticamente l'output di hello delle query SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="539bc-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="539bc-253">Hello opzione tooselect tra diversi tipi di visualizzazioni (tabella, a torta, linea, Area o barra) viene fornita tramite hello **tipo** pulsanti di menu in blocco per Appunti hello:</span><span class="sxs-lookup"><span data-stu-id="539bc-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![Curva ROC di regressione logistica per approccio generico](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="539bc-255">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="539bc-255">What's next?</span></span>
<span data-ttu-id="539bc-256">Ora che si sono configurati con un cluster HDInsight Spark e caricate notebook Jupyter hello, si è pronti toowork tramite argomenti hello corrispondenti toohello tre PySpark notebook.</span><span class="sxs-lookup"><span data-stu-id="539bc-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="539bc-257">Vengono visualizzate come tooexplore i dati e come quindi toocreate e utilizzare i modelli.</span><span class="sxs-lookup"><span data-stu-id="539bc-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="539bc-258">Hello avanzate di esplorazione dei dati e modellazione notebook Mostra come tooinclude convalida incrociata, hyper-parameter sweep e valutazione del modello.</span><span class="sxs-lookup"><span data-stu-id="539bc-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="539bc-259">**Esplorazione dei dati e modellazione con Spark:** esplorare hello set di dati e creare, assegnare un punteggio e valutare i modelli di machine learning hello affrontando hello [creare modelli di classificazione e regressione binari per i dati con hello Spark Toolkit MLlib](machine-learning-data-science-spark-data-exploration-modeling.md) argomento.</span><span class="sxs-lookup"><span data-stu-id="539bc-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="539bc-260">**Utilizzo del modello:** toolearn come modelli di classificazione e regressione hello tooscore creato in questo argomento, vedere [punteggio e valutare i modelli di apprendimento macchina compilato Spark](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="539bc-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="539bc-261">**Convalida incrociata e sweep di iperparametri**: vedere [Esplorazione e modellazione avanzate dei dati con Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) per informazioni su come istruire i modelli sulla convalida incrociata e lo sweep di iperparametri</span><span class="sxs-lookup"><span data-stu-id="539bc-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

