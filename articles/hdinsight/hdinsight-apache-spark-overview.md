---
title: Introduzione a Spark in HDInsight | Microsoft Docs
description: "Questo articolo fornisce un'introduzione a Spark in HDInsight e presenta i diversi scenari in cui è possibile usare il cluster Spark in HDInsight."
keywords: informazioni su apache spark,cluster spark,introduzione a spark,spark in hdinsight
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="5642c-104">Introduzione a Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="5642c-105">Questo articolo fornisce un'introduzione a Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="5642c-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="5642c-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> è un framework open source di elaborazione parallela che supporta l'elaborazione in memoria per migliorare le prestazioni di applicazioni analitiche di Big Data.</span><span class="sxs-lookup"><span data-stu-id="5642c-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="5642c-107">Il cluster Spark in HDInsight è compatibile con Archiviazione di Azure (WASB) e con Azure Data Lake Store. È quindi possibile elaborare con facilità tramite un cluster Spark i dati esistenti archiviati in Azure.</span><span class="sxs-lookup"><span data-stu-id="5642c-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="5642c-108">Quando si crea un cluster Spark in HDInsight, si creano risorse di calcolo di Azure con Spark installato e configurato.</span><span class="sxs-lookup"><span data-stu-id="5642c-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="5642c-109">Bastano circa dieci minuti per creare un cluster di Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="5642c-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="5642c-110">I dati da elaborare vengono archiviati in Archiviazione di Azure o Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5642c-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="5642c-111">Vedere [Usare l'Archiviazione di Azure con HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="5642c-112">**Per creare un cluster Spark in HDInsight**, vedere [Guida introduttiva: Creare un cluster Spark in HDInsight ed eseguire query interattive usando Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="5642c-113">Informazioni su Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="5642c-114">I cluster Spark in HDInsight offrono un servizio Spark completamente gestito.</span><span class="sxs-lookup"><span data-stu-id="5642c-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="5642c-115">I vantaggi della creazione di un cluster Spark in HDInsight sono elencati qui.</span><span class="sxs-lookup"><span data-stu-id="5642c-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="5642c-116">Funzionalità</span><span class="sxs-lookup"><span data-stu-id="5642c-116">Feature</span></span> | <span data-ttu-id="5642c-117">Descrizione</span><span class="sxs-lookup"><span data-stu-id="5642c-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="5642c-118">Facilità di creazione dei cluster Spark</span><span class="sxs-lookup"><span data-stu-id="5642c-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="5642c-119">È possibile creare un nuovo cluster Spark in HDInsight in pochi minuti mediante il portale di Azure, Azure PowerShell o HDInsight .NET SDK.</span><span class="sxs-lookup"><span data-stu-id="5642c-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="5642c-120">Vedere [Introduzione ai cluster Spark in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="5642c-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="5642c-121">Semplicità d'uso</span><span class="sxs-lookup"><span data-stu-id="5642c-121">Ease of use</span></span> |<span data-ttu-id="5642c-122">Il cluster Spark in HDInsight include notebook di Jupyter e Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="5642c-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="5642c-123">È possibile usarli per la visualizzazione e l'elaborazione interattiva di dati.</span><span class="sxs-lookup"><span data-stu-id="5642c-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="5642c-124">API REST</span><span class="sxs-lookup"><span data-stu-id="5642c-124">REST APIs</span></span> |<span data-ttu-id="5642c-125">I cluster Spark in HDInsight includono [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), un server dei processi Spark basato sull'API REST per l'invi e il monitoraggio remoto dei processi.</span><span class="sxs-lookup"><span data-stu-id="5642c-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="5642c-126">Supporto per Archivio Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="5642c-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="5642c-127">È possibile configurare un cluster Spark in HDInsight per l'uso di Azure Data Lake Store come spazio di archiviazione aggiuntivo o come risorsa di archiviazione primaria (solo con cluster HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="5642c-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="5642c-128">Per altre informazioni su Archivio Data Lake, vedere [Panoramica di Archivio Azure Data Lake](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="5642c-129">Integrazione con servizi di Azure</span><span class="sxs-lookup"><span data-stu-id="5642c-129">Integration with Azure services</span></span> |<span data-ttu-id="5642c-130">Il cluster Spark in HDInsight viene fornito con un connettore per Hub eventi di Azure.</span><span class="sxs-lookup"><span data-stu-id="5642c-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="5642c-131">Gli utenti possono creare applicazioni di streaming mediante Hub eventi, oltre a [Kafka](http://kafka.apache.org/)che è già disponibile come parte di Spark.</span><span class="sxs-lookup"><span data-stu-id="5642c-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="5642c-132">Supporto per R Server</span><span class="sxs-lookup"><span data-stu-id="5642c-132">Support for R Server</span></span> | <span data-ttu-id="5642c-133">È possibile impostare R Server in un cluster HDInsight Spark per eseguire calcoli R distribuiti con la velocità garantita da un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="5642c-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="5642c-134">Per altre informazioni, vedere [Introduzione all'uso di R Server in HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="5642c-135">Integrazione con IDE di terze parti</span><span class="sxs-lookup"><span data-stu-id="5642c-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="5642c-136">HDInsight fornisce i plug-in per gli IDE, ad esempio IntelliJ IDEA ed Eclipse, che possono essere usati per creare e inviare applicazioni in un cluster Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="5642c-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="5642c-137">Per altre informazioni, vedere [Usare Azure Toolkit per IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) e [Usare Azure Toolkit per Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="5642c-138">Query simultanee</span><span class="sxs-lookup"><span data-stu-id="5642c-138">Concurrent Queries</span></span> |<span data-ttu-id="5642c-139">I cluster Spark in HDInsight supportano le query simultanee.</span><span class="sxs-lookup"><span data-stu-id="5642c-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="5642c-140">In questo modo più query da un utente o più query da vari utenti e applicazioni possono condividere le stesse risorse di cluster.</span><span class="sxs-lookup"><span data-stu-id="5642c-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="5642c-141">La memorizzazione nella cache nelle unità SSD</span><span class="sxs-lookup"><span data-stu-id="5642c-141">Caching on SSDs</span></span> |<span data-ttu-id="5642c-142">È possibile scegliere di memorizzare i dati in memoria o nelle SSD associate ai nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="5642c-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="5642c-143">La memorizzazione nella cache in memoria offre le migliori prestazioni di query ma può essere costosa; la memorizzazione nella cache in SSDs fornisce un'ottima opzione per migliorare le prestazioni delle query senza la necessità di creare un cluster di dimensioni necessario ad adattare l'intero set di dati in memoria.</span><span class="sxs-lookup"><span data-stu-id="5642c-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="5642c-144">Integrazione con strumenti di Business Intelligence</span><span class="sxs-lookup"><span data-stu-id="5642c-144">Integration with BI Tools</span></span> |<span data-ttu-id="5642c-145">I cluster Spark in HDInsight offrono connettori per strumenti di Business Intelligence, come [Power BI](http://www.powerbi.com/) e [Tableau](http://www.tableau.com/products/desktop), per l'analisi dei dati.</span><span class="sxs-lookup"><span data-stu-id="5642c-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="5642c-146">Librerie Anaconda precaricate</span><span class="sxs-lookup"><span data-stu-id="5642c-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="5642c-147">I cluster Spark in HDInsight sono dotati di librerie Anaconda preinstallate</span><span class="sxs-lookup"><span data-stu-id="5642c-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="5642c-148">[Anaconda](http://docs.continuum.io/anaconda/) offre quasi 200 librerie per Machine Learning, l'analisi dei dati, la visualizzazione e così via.</span><span class="sxs-lookup"><span data-stu-id="5642c-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="5642c-149">Scalabilità</span><span class="sxs-lookup"><span data-stu-id="5642c-149">Scalability</span></span> |<span data-ttu-id="5642c-150">Anche se è possibile specificare il numero di nodi del cluster durante la fase di creazione, in seguito può essere necessario aumentare o ridurre il cluster sulla base del carico di lavoro.</span><span class="sxs-lookup"><span data-stu-id="5642c-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="5642c-151">Tutti i cluster HDInsight consentono di modificare il numero di nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="5642c-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="5642c-152">È anche possibile eliminare i cluster Spark senza alcuna perdita di dati perché tutti i dati sono archiviati in Archiviazione di Azure o Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5642c-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="5642c-153">Supporto 24/7</span><span class="sxs-lookup"><span data-stu-id="5642c-153">24/7 Support</span></span> |<span data-ttu-id="5642c-154">I cluster Spark in HDInsight includono il supporto continuo a livello aziendale e un Contratto di servizio che garantisce tempi di attività pari al 99,9%.</span><span class="sxs-lookup"><span data-stu-id="5642c-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="5642c-155">Quali sono i casi d'uso per Spark in HDInsight?</span><span class="sxs-lookup"><span data-stu-id="5642c-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="5642c-156">I cluster Spark in HDInsight consentono gli scenari principali seguenti.</span><span class="sxs-lookup"><span data-stu-id="5642c-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="5642c-157">Analisi dei dati interattivi e Business Intelligence</span><span class="sxs-lookup"><span data-stu-id="5642c-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="5642c-158">Esaminare un'esercitazione</span><span class="sxs-lookup"><span data-stu-id="5642c-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="5642c-159">Apache Spark in HDInsight archivia i dati nell'Archiviazione di Azure o in Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5642c-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="5642c-160">Gli esperti aziendali e i responsabili decisionali possono analizzare e generare rapporti su dati e usare Microsoft Power BI per creare rapporti dai dati analizzati.</span><span class="sxs-lookup"><span data-stu-id="5642c-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="5642c-161">Gli analisti possono iniziare a usare dati non strutturati/parzialmente strutturati in una risorsa di archiviazione cluster, definire uno schema per i dati usando notebook e quindi creare modelli di dati usando Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="5642c-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="5642c-162">I cluster Spark in HDInsight supportano anche alcuni strumenti di BI di terze parti, ad esempio Tableau, e sono quindi una piattaforma ottimale per gli analisti di dati, gli esperti aziendali e i decision maker principali.</span><span class="sxs-lookup"><span data-stu-id="5642c-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="5642c-163">Machine Learning in Spark</span><span class="sxs-lookup"><span data-stu-id="5642c-163">Spark Machine Learning</span></span>
[<span data-ttu-id="5642c-164">Esaminare un'esercitazione: stima delle temperature di compilazione mediante i dati HVAC</span><span class="sxs-lookup"><span data-stu-id="5642c-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="5642c-165">Esaminare un'esercitazione: stima dei risultati di ispezione del cibo</span><span class="sxs-lookup"><span data-stu-id="5642c-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="5642c-166">Apache Spark include [MLlib](http://spark.apache.org/mllib/), una libreria di Machine Learning basata su Spark, che è possibile usare da un cluster Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="5642c-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="5642c-167">Il cluster Spark in HDInsight include inoltre Anaconda, una distribuzione di Python con un'ampia gamma di pacchetti per l'apprendimento automatico.</span><span class="sxs-lookup"><span data-stu-id="5642c-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="5642c-168">Aggiungendo il supporto incorporato per notebook Jupyter e Zeppelin si otterrà un ambiente di qualità elevata per la creazione di applicazioni di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="5642c-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="5642c-169">Analisi dei dati in tempo reale e streaming in Spark</span><span class="sxs-lookup"><span data-stu-id="5642c-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="5642c-170">Esaminare un'esercitazione</span><span class="sxs-lookup"><span data-stu-id="5642c-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="5642c-171">I cluster Spark in HDInsight offrono un supporto completo per la creazione di soluzioni di analisi in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="5642c-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="5642c-172">Mentre Spark ha già connettori per acquisire i dati da molte origini, quali socket Kafka, Flume, Twitter, ZeroMQ o TCP, Spark in HDInsight aggiunge un eccellente supporto per l'inserimento di dati da Hub eventi di Azure.</span><span class="sxs-lookup"><span data-stu-id="5642c-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="5642c-173">Hub eventi è il servizio di Accodamento messaggi maggiormente usato in Azure.</span><span class="sxs-lookup"><span data-stu-id="5642c-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="5642c-174">La disponibilità di un supporto per Hub eventi rende i cluster Spark in HDInsight la piattaforma ideale per la compilazione della pipeline di analisi in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="5642c-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="5642c-175"><a name="next-steps"></a>Quali componenti sono inclusi come parte di un cluster di Spark?</span><span class="sxs-lookup"><span data-stu-id="5642c-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="5642c-176">I cluster Spark in HDInsight includono i componenti seguenti che sono disponibili nei cluster per impostazione predefinita.</span><span class="sxs-lookup"><span data-stu-id="5642c-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="5642c-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="5642c-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="5642c-178">Viene fornito con Spark Core, Spark SQL, streaming API Spark, GraphX e MLlib Spark.</span><span class="sxs-lookup"><span data-stu-id="5642c-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="5642c-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="5642c-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="5642c-180">Livy</span><span class="sxs-lookup"><span data-stu-id="5642c-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="5642c-181">Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="5642c-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="5642c-182">Notebook Zeppelin</span><span class="sxs-lookup"><span data-stu-id="5642c-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="5642c-183">I cluster Spark in HDInsight forniscono inoltre un [driver ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) per la connettività ai cluster Spark in HDInsight da strumenti di Business Intelligence, quali Microsoft Power BI e Tableau.</span><span class="sxs-lookup"><span data-stu-id="5642c-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="5642c-184">Dove iniziare?</span><span class="sxs-lookup"><span data-stu-id="5642c-184">Where do I start?</span></span>
<span data-ttu-id="5642c-185">Iniziare con la creazione di un cluster Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="5642c-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="5642c-186">Vedere [Guida introduttiva: creare un cluster di Spark in HDInsight ed eseguire query interattive usando Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="5642c-187">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="5642c-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="5642c-188">Scenari</span><span class="sxs-lookup"><span data-stu-id="5642c-188">Scenarios</span></span>
* [<span data-ttu-id="5642c-189">Spark con Business Intelligence: eseguire l'analisi interattiva dei dati con strumenti di Business Intelligence mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="5642c-190">Spark con Machine Learning: utilizzare Spark in HDInsight per l'analisi della temperatura di compilazione utilizzando dati HVAC</span><span class="sxs-lookup"><span data-stu-id="5642c-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="5642c-191">Spark con Machine Learning: usare Spark in HDInsight per prevedere i risultati del controllo degli alimenti</span><span class="sxs-lookup"><span data-stu-id="5642c-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="5642c-192">Streaming Spark: usare Spark in HDInsight per la creazione di applicazioni di streaming in tempo reale</span><span class="sxs-lookup"><span data-stu-id="5642c-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="5642c-193">Analisi dei log del sito Web mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="5642c-194">Creare ed eseguire applicazioni</span><span class="sxs-lookup"><span data-stu-id="5642c-194">Create and run applications</span></span>
* [<span data-ttu-id="5642c-195">Creare un'applicazione autonoma con Scala</span><span class="sxs-lookup"><span data-stu-id="5642c-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="5642c-196">Eseguire processi in modalità remota in un cluster Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="5642c-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="5642c-197">Strumenti ed estensioni</span><span class="sxs-lookup"><span data-stu-id="5642c-197">Tools and extensions</span></span>
* [<span data-ttu-id="5642c-198">Usare il plug-in degli strumenti HDInsight per IntelliJ IDEA per creare e inviare applicazioni Spark in Scala</span><span class="sxs-lookup"><span data-stu-id="5642c-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="5642c-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely (Usare il plug-in Strumenti HDInsight per IntelliJ IDEA per eseguire il debug di applicazioni Spark in remoto)</span><span class="sxs-lookup"><span data-stu-id="5642c-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="5642c-200">Usare i notebook di Zeppelin con un cluster Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="5642c-201">Kernel disponibili per notebook di Jupyter nel cluster Spark per HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="5642c-202">Usare pacchetti esterni con i notebook Jupyter</span><span class="sxs-lookup"><span data-stu-id="5642c-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="5642c-203">Installare Jupyter Notebook nel computer e connetterlo a un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="5642c-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="5642c-204">Gestire risorse</span><span class="sxs-lookup"><span data-stu-id="5642c-204">Manage resources</span></span>
* [<span data-ttu-id="5642c-205">Gestire le risorse del cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="5642c-206">Tenere traccia ed eseguire il debug di processi in esecuzione nel cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="5642c-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="5642c-207">[Problemi noti di Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="5642c-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
