---
title: Opzioni del contesto di calcolo per R Server in HDInsight - Azure | Documentazione Microsoft
description: Informazioni sulle diverse opzioni del contesto di calcolo disponibili per gli utenti con R Server in HDInsight
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 47f4441612be4f363ba82cc22b09786a6f3bfdc3
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/29/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="6511f-103">Opzioni del contesto di calcolo per R Server su HDInsight (anteprima)</span><span class="sxs-lookup"><span data-stu-id="6511f-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="6511f-104">Microsoft R Server in Azure HDInsight controlla l'esecuzione delle chiamate, impostando il contesto di calcolo.</span><span class="sxs-lookup"><span data-stu-id="6511f-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="6511f-105">In questo articolo vengono descritte le opzioni disponibili per specificare se e come l'esecuzione venga parallelizzata tra i core del nodo perimetrale o del cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="6511f-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="6511f-106">Il nodo perimetrale di un cluster offre una posizione pratica per connettersi al cluster ed eseguire gli script R.</span><span class="sxs-lookup"><span data-stu-id="6511f-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="6511f-107">Con un nodo perimetrale è possibile eseguire le funzioni distribuite parallelizzate di ScaleR nei core del server del nodo perimetrale.</span><span class="sxs-lookup"><span data-stu-id="6511f-107">With an edge node, you have the option of running the parallelized distributed functions of ScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="6511f-108">È anche possibile eseguire tali funzioni tra i nodi del cluster usando contesti di calcolo Hadoop MapReduce o Spark di ScaleR.</span><span class="sxs-lookup"><span data-stu-id="6511f-108">You can also run them across the nodes of the cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="6511f-109">Microsoft R Server in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="6511f-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="6511f-110">[Microsoft R Server in Azure HDInsight](hdinsight-hadoop-r-server-overview.md) fornisce le funzionalità più recenti per l'analisi basata su R.</span><span class="sxs-lookup"><span data-stu-id="6511f-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="6511f-111">Può usare i dati archiviati in un contenitore HDFS nell'account di archiviazione [BLOB di Azure](../storage/common/storage-introduction.md "Archiviazione BLOB di Azure"), in un Data Lake Store o nel file system locale di Linux.</span><span class="sxs-lookup"><span data-stu-id="6511f-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="6511f-112">Poiché R Server si basa su R open source, le applicazioni basate su R compilate dall'utente possono applicare gli oltre 8000 pacchetti R open source.</span><span class="sxs-lookup"><span data-stu-id="6511f-112">Since R Server is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="6511f-113">Possono anche usare le routine di [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), il pacchetto di analisi dei Big Data di Microsoft incluso in R Server.</span><span class="sxs-lookup"><span data-stu-id="6511f-113">They can also use the routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="6511f-114">Contesti di calcolo per un nodo perimetrale</span><span class="sxs-lookup"><span data-stu-id="6511f-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="6511f-115">In generale, uno script R eseguito in R Server nel nodo perimetrale viene eseguito all'interno dell'interprete R in tale nodo.</span><span class="sxs-lookup"><span data-stu-id="6511f-115">In general, an R script that's run in R Server on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="6511f-116">L'eccezione è costituita dai passaggi che chiamano una funzione ScaleR.</span><span class="sxs-lookup"><span data-stu-id="6511f-116">The exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="6511f-117">Le chiamate ScaleR vengono eseguite in un ambiente di calcolo determinato dall'impostazione del contesto di calcolo di ScaleR.</span><span class="sxs-lookup"><span data-stu-id="6511f-117">The ScaleR calls run in a compute environment that is determined by how you set the ScaleR compute context.</span></span>  <span data-ttu-id="6511f-118">Quando si esegue lo script R da un nodo perimetrale, i valori possibili del contesto di calcolo sono:</span><span class="sxs-lookup"><span data-stu-id="6511f-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="6511f-119">sequenziale locale (*"local"*)</span><span class="sxs-lookup"><span data-stu-id="6511f-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="6511f-120">parallelo locale (*"localpar"*)</span><span class="sxs-lookup"><span data-stu-id="6511f-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="6511f-121">MapReduce</span><span class="sxs-lookup"><span data-stu-id="6511f-121">Map Reduce</span></span>
- <span data-ttu-id="6511f-122">Spark</span><span class="sxs-lookup"><span data-stu-id="6511f-122">Spark</span></span>

<span data-ttu-id="6511f-123">Le opzioni *"local"* e *"localpar"* differiscono solo per la modalità di esecuzione delle chiamate **rxExec**.</span><span class="sxs-lookup"><span data-stu-id="6511f-123">The *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="6511f-124">Entrambe eseguono chiamate ad altre funzioni di ricezione in modo parallelo tra le memorie centrali disponibili, se non diversamente specificato, mediante l'uso dell'opzione ScaleR **numCoresToUse**, ad esempio `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="6511f-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="6511f-125">Le opzioni di esecuzione parallela offrono prestazioni ottimali.</span><span class="sxs-lookup"><span data-stu-id="6511f-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="6511f-126">Nella tabella seguente vengono riepilogate le varie opzioni di contesto di calcolo per impostare l'esecuzione delle chiamate:</span><span class="sxs-lookup"><span data-stu-id="6511f-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="6511f-127">Contesto di calcolo</span><span class="sxs-lookup"><span data-stu-id="6511f-127">Compute context</span></span>  | <span data-ttu-id="6511f-128">Come impostarlo</span><span class="sxs-lookup"><span data-stu-id="6511f-128">How to set</span></span>                      | <span data-ttu-id="6511f-129">Contesto di esecuzione</span><span class="sxs-lookup"><span data-stu-id="6511f-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="6511f-130">Sequenziale locale</span><span class="sxs-lookup"><span data-stu-id="6511f-130">Local sequential</span></span> | <span data-ttu-id="6511f-131">rxSetComputeContext('local')</span><span class="sxs-lookup"><span data-stu-id="6511f-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="6511f-132">Esecuzione in parallelo attraverso i core del server del nodo perimetrale, ad eccezione delle chiamate rxExec che vengono eseguite in serie</span><span class="sxs-lookup"><span data-stu-id="6511f-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="6511f-133">Parallelo locale</span><span class="sxs-lookup"><span data-stu-id="6511f-133">Local parallel</span></span>   | <span data-ttu-id="6511f-134">rxSetComputeContext('localpar')</span><span class="sxs-lookup"><span data-stu-id="6511f-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="6511f-135">Esecuzione in parallelo tra i core del server del nodo perimetrale</span><span class="sxs-lookup"><span data-stu-id="6511f-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="6511f-136">Spark</span><span class="sxs-lookup"><span data-stu-id="6511f-136">Spark</span></span>            | <span data-ttu-id="6511f-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="6511f-137">RxSpark()</span></span>                       | <span data-ttu-id="6511f-138">Esecuzione parallelizzata distribuita tramite Spark tra i nodi del cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="6511f-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="6511f-139">MapReduce</span><span class="sxs-lookup"><span data-stu-id="6511f-139">Map Reduce</span></span>       | <span data-ttu-id="6511f-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="6511f-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="6511f-141">Esecuzione parallelizzata distribuita tramite MapReduce tra i nodi del cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="6511f-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="6511f-142">Linee guida per la scelta di un contesto di calcolo</span><span class="sxs-lookup"><span data-stu-id="6511f-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="6511f-143">Quale delle tre opzioni consenta l'esecuzione parallelizzata dipende dalla natura del proprio lavoro di analitica, dalle dimensioni e dalla posizione dei dati.</span><span class="sxs-lookup"><span data-stu-id="6511f-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="6511f-144">Non esiste una formula fissa che indichi quale contesto di calcolo usare.</span><span class="sxs-lookup"><span data-stu-id="6511f-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="6511f-145">Esistono tuttavia alcuni principi guida che consentono di effettuare la scelta appropriata, o almeno consentono di limitare le scelte prima di eseguire un benchmark.</span><span class="sxs-lookup"><span data-stu-id="6511f-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="6511f-146">Ecco alcuni dei principi guida:</span><span class="sxs-lookup"><span data-stu-id="6511f-146">These guiding principles include:</span></span>

- <span data-ttu-id="6511f-147">Il file system locale di Linux è più veloce rispetto ad HDFS.</span><span class="sxs-lookup"><span data-stu-id="6511f-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="6511f-148">Le analisi ripetute risultano più veloci se i dati sono locali e in formato XDF.</span><span class="sxs-lookup"><span data-stu-id="6511f-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="6511f-149">È preferibile eseguire il flusso di piccole quantità di dati da un'origine dati di testo.</span><span class="sxs-lookup"><span data-stu-id="6511f-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="6511f-150">Se la quantità di dati è più grande, è necessario convertirli con estensione XDF prima dell'analisi.</span><span class="sxs-lookup"><span data-stu-id="6511f-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="6511f-151">Il sovraccarico dovuto alla copia o allo streaming dei dati nel nodo perimetrale per l'analisi diventa ingestibile per quantità di dati molto grandi.</span><span class="sxs-lookup"><span data-stu-id="6511f-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="6511f-152">Spark è più veloce rispetto a Map Reduce per l'analisi in Hadoop.</span><span class="sxs-lookup"><span data-stu-id="6511f-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="6511f-153">Dati questi principi, la sezione seguente illustra alcune regole generali per la selezione di un contesto di calcolo.</span><span class="sxs-lookup"><span data-stu-id="6511f-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="6511f-154">Local</span><span class="sxs-lookup"><span data-stu-id="6511f-154">Local</span></span>
* <span data-ttu-id="6511f-155">Se la quantità di dati da analizzare è limitata e non sono richieste analisi ripetute, eseguirne il flusso direttamente in una routine di analisi usando *"local"* o *"localpar"*.</span><span class="sxs-lookup"><span data-stu-id="6511f-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="6511f-156">Se la quantità di dati da analizzare è limitata o media e richiede analisi ripetute, copiare i dati nel file system locale, importarli in XDF e analizzarli con *"local"* o *"localpar"*.</span><span class="sxs-lookup"><span data-stu-id="6511f-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="6511f-157">Hadoop Spark</span><span class="sxs-lookup"><span data-stu-id="6511f-157">Hadoop Spark</span></span>
* <span data-ttu-id="6511f-158">Se la quantità di dati da analizzare è grande, importare i dati in un DataFrame Spark usando **RxHiveData** o **RxParquetData** oppure in HDFS in formato XDF, a meno che lo spazio di archiviazione non sia un problema, e analizzarli usando il contesto di calcolo di Spark.</span><span class="sxs-lookup"><span data-stu-id="6511f-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="6511f-159">Hadoop MapReduce</span><span class="sxs-lookup"><span data-stu-id="6511f-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="6511f-160">Usare il contesto di calcolo MapReduce solo se si riscontra un problema insormontabile riguardo al contesto di calcolo Spark, poiché di norma risulta essere più lento.</span><span class="sxs-lookup"><span data-stu-id="6511f-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="6511f-161">Guida in linea su rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="6511f-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="6511f-162">Per altre informazioni ed esempi di contesti di calcolo di ScaleR, vedere la guida in linea di R sul metodo rxSetComputeContext, ad esempio:</span><span class="sxs-lookup"><span data-stu-id="6511f-162">For more information and examples of ScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="6511f-163">È anche possibile vedere la "[Guida all'elaborazione distribuita di ScaleR](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)" disponibile nella pagina relativa a [Server R MSDN](https://msdn.microsoft.com/library/mt674634.aspx "Server R in MSDN nella libreria MSDN").</span><span class="sxs-lookup"><span data-stu-id="6511f-163">You can also refer to the “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from the [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="6511f-164">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="6511f-164">Next steps</span></span>
<span data-ttu-id="6511f-165">In questo articolo sono state descritte le opzioni disponibili per specificare se e come l'esecuzione venga parallelizzata tra i core del nodo perimetrale o del cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="6511f-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="6511f-166">Per altre informazioni sull'uso di R Server con i cluster HDInsight, vedere gli argomenti seguenti:</span><span class="sxs-lookup"><span data-stu-id="6511f-166">To learn more about how to use R Server with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="6511f-167">Panoramica: R Server su HDInsight (anteprima)</span><span class="sxs-lookup"><span data-stu-id="6511f-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="6511f-168">Introduzione all'uso di R Server su HDInsight (anteprima)</span><span class="sxs-lookup"><span data-stu-id="6511f-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="6511f-169">Aggiungere RStudio Server a HDInsight (se non è stato aggiunto durante la creazione del cluster)</span><span class="sxs-lookup"><span data-stu-id="6511f-169">Add RStudio Server to HDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* [<span data-ttu-id="6511f-170">Opzioni di Archiviazione di Azure per R Server su HDInsight</span><span class="sxs-lookup"><span data-stu-id="6511f-170">Azure Storage options for R Server on HDInsight</span></span>](hdinsight-hadoop-r-server-storage.md)

