---
title: Ridimensionamento dei processi con Analisi di flusso di Azure e funzioni di Azure Machine Learning | Microsoft Docs
description: "Informazioni su come ridimensionare correttamente i processi di Analisi di flusso, con il partizionamento, le unità di streaming e altro ancora, quando si usano funzioni di Azure Machine Learning."
keywords: 
documentationcenter: 
services: stream-analytics
author: jeffstokes72
manager: jhubbard
editor: cgronlun
ms.assetid: 47ce7c5e-1de1-41ca-9a26-b5ecce814743
ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 03/28/2017
ms.author: jeffstok
ms.openlocfilehash: 5e07e4efcd14cd8c12124cb34058ef6c345f7f47
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/29/2017
---
# <a name="scale-your-stream-analytics-job-with-azure-machine-learning-functions"></a><span data-ttu-id="6818c-103">Ridimensionare il processo di Analisi di flusso con funzioni di Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="6818c-103">Scale your Stream Analytics job with Azure Machine Learning functions</span></span>
<span data-ttu-id="6818c-104">Spesso è piuttosto semplice impostare un processo di Analisi di flusso e usarlo per analizzare alcuni dati di esempio.</span><span class="sxs-lookup"><span data-stu-id="6818c-104">It is often quite easy to set up an Stream Analytics job and run some sample data through it.</span></span> <span data-ttu-id="6818c-105">Cosa fare quando è necessario eseguire lo stesso processo con volume di dati più elevato?</span><span class="sxs-lookup"><span data-stu-id="6818c-105">What should we do when we need to run the same job with higher data volume?</span></span> <span data-ttu-id="6818c-106">Bisogna capire come configurare il processo di Analisi di flusso per il ridimensionamento.</span><span class="sxs-lookup"><span data-stu-id="6818c-106">It requires us to understand how to configure the Stream Analytics job so that it will scale.</span></span> <span data-ttu-id="6818c-107">Questo documento illustra in particolare gli aspetti specifici del ridimensionamento di processi di Analisi di flusso con funzioni di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-107">In this document, we will focus on the special aspects of scaling Stream Analytics jobs with Machine Learning functions.</span></span> <span data-ttu-id="6818c-108">Per informazioni su come ridimensionare processi di Analisi di flusso in generale, vedere l'articolo relativo al [ridimensionamento dei processi](stream-analytics-scale-jobs.md).</span><span class="sxs-lookup"><span data-stu-id="6818c-108">For information on how to scale Stream Analytics jobs in general see the article [Scaling jobs](stream-analytics-scale-jobs.md).</span></span>

## <a name="what-is-an-azure-machine-learning-function-in-stream-analytics"></a><span data-ttu-id="6818c-109">Che cos'è una funzione di Azure Machine Learning in Analisi di flusso?</span><span class="sxs-lookup"><span data-stu-id="6818c-109">What is an Azure Machine Learning function in Stream Analytics?</span></span>
<span data-ttu-id="6818c-110">Una funzione di Machine Learning in Analisi di flusso può essere usata come una normale chiamata di funzione nel linguaggio di query di Analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-110">A Machine Learning function in Stream Analytics can be used like a regular function call in the Stream Analytics query language.</span></span> <span data-ttu-id="6818c-111">Tuttavia, le chiamate di funzione sono in realtà richieste del servizio Web Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-111">However, behind the scene, the function calls are actually Azure Machine Learning Web Service requests.</span></span> <span data-ttu-id="6818c-112">I servizi Web Machine Learning supportano l'invio in batch di più righe, dette mini-batch, nella stessa chiamata all'API del servizio Web per migliorare la velocità effettiva globale.</span><span class="sxs-lookup"><span data-stu-id="6818c-112">Machine Learning web services support “batching” multiple rows, which is called mini-batch, in the same web service API call, to improve overall throughput.</span></span> <span data-ttu-id="6818c-113">Per altri dettagli, vedere gli articoli relativi alle [funzioni di Azure Machine Learning in Analisi di flusso](https://blogs.technet.microsoft.com/machinelearning/2015/12/10/azure-ml-now-available-as-a-function-in-azure-stream-analytics/) e ai [servizi Web Azure Machine Learning](../machine-learning/machine-learning-consume-web-services.md).</span><span class="sxs-lookup"><span data-stu-id="6818c-113">Please see the following articles for more details; [Azure Machine Learning functions in Stream Analytics](https://blogs.technet.microsoft.com/machinelearning/2015/12/10/azure-ml-now-available-as-a-function-in-azure-stream-analytics/) and [Azure Machine Learning Web Services](../machine-learning/machine-learning-consume-web-services.md).</span></span>

## <a name="configure-a-stream-analytics-job-with-machine-learning-functions"></a><span data-ttu-id="6818c-114">Configurare un processo di Analisi di flusso con funzioni di Machine Learning</span><span class="sxs-lookup"><span data-stu-id="6818c-114">Configure a Stream Analytics job with Machine Learning functions</span></span>
<span data-ttu-id="6818c-115">Quando si configura una funzione di Machine Learning per un processo di Analisi di flusso è necessario prendere in considerazione due parametri, le dimensioni batch delle chiamate di funzione di Machine Learning e le unità di streaming (SU) di cui viene effettuato il provisioning per il processo di Analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-115">When configuring a Machine Learning function for Stream Analytics job, there are two parameters to consider, the batch size of the Machine Learning function calls, and the streaming units (SUs) provisioned for the Stream Analytics job.</span></span> <span data-ttu-id="6818c-116">Per determinare i relativi valori appropriati, occorre prima scegliere tra latenza e velocità effettiva, vale a dire la latenza del processo di Analisi di flusso e la velocità effettiva di ogni unità di streaming.</span><span class="sxs-lookup"><span data-stu-id="6818c-116">To determine the appropriate values for these, first a decision must be made between latency and throughput, that is, latency of the Stream Analytics job, and throughput of each SU.</span></span> <span data-ttu-id="6818c-117">È sempre possibile aggiungere unità di streaming a un processo per aumentare la velocità effettiva di una query di Analisi di flusso con partizionamento efficiente, anche se le unità di streaming aumentano il costo di esecuzione del processo.</span><span class="sxs-lookup"><span data-stu-id="6818c-117">SUs may always be added to a job to increase throughput of a well partitioned Stream Analytics query, although additional SUs increases the cost of running the job.</span></span>

<span data-ttu-id="6818c-118">È quindi importante determinare la *tolleranza* della latenza nell'esecuzione di un processo di Analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-118">Therefore it is important to determine the *tolerance* of latency in running a Stream Analytics job.</span></span> <span data-ttu-id="6818c-119">La latenza aggiuntiva dovuta all'esecuzione di richieste del servizio Azure Machine Learning aumenta naturalmente con le dimensioni batch, che si sommano alla latenza del processo di Analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-119">Additional latency from running Azure Machine Learning service requests will naturally increase with batch size, which will compound the latency of the Stream Analytics job.</span></span> <span data-ttu-id="6818c-120">L'aumento delle dimensioni batch consente d'altra parte al processo di analisi di flusso di elaborare *più eventi con lo *stesso numero* di richieste del servizio Web di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-120">On the other hand, increasing batch size allows the Stream Analytics job to process *more events with the *same number* of Machine Learning web service requests.</span></span> <span data-ttu-id="6818c-121">L'aumento della latenza del servizio Web Machine Learning è spesso sublineare all'aumento delle dimensioni. È quindi importante stabilire le dimensioni batch più convenienti per un servizio Web Machine Learning in una determinata situazione.</span><span class="sxs-lookup"><span data-stu-id="6818c-121">Often the increase of Machine Learning web service latency is sub-linear to the increase of batch size so it is important to consider the most cost-efficient batch size for a Machine Learning web service in any given situation.</span></span> <span data-ttu-id="6818c-122">Le dimensioni batch predefinite per le richieste al servizio Web sono pari a 1000 e possono essere modificate usando l'[API REST di Analisi di flusso](https://msdn.microsoft.com/library/mt653706.aspx "API REST di Analisi di flusso") o il [client di PowerShell per Analisi di flusso](stream-analytics-monitor-and-manage-jobs-use-powershell.md "client di PowerShell per Analisi di flusso").</span><span class="sxs-lookup"><span data-stu-id="6818c-122">The default batch size for the web service requests is 1000 and may be modified either by using the [Stream Analytics REST API](https://msdn.microsoft.com/library/mt653706.aspx "Stream Analytics REST API") or the [PowerShell client for Stream Analytics](stream-analytics-monitor-and-manage-jobs-use-powershell.md "PowerShell client for Stream Analytics").</span></span>

<span data-ttu-id="6818c-123">Dopo aver determinato le dimensioni batch, è possibile determinare la quantità di unità di streaming (SU) in base al numero di eventi che la funzione deve elaborare al secondo.</span><span class="sxs-lookup"><span data-stu-id="6818c-123">Once a batch size has been determined, the amount of streaming units (SUs) can be determined, based on the number of events that the function needs to process per second.</span></span> <span data-ttu-id="6818c-124">Per altre informazioni sulle unità di streaming, vedere [Processi di scalabilità di Analisi di flusso](stream-analytics-scale-jobs.md).</span><span class="sxs-lookup"><span data-stu-id="6818c-124">For more information about streaming units, see [Stream Analytics scale jobs](stream-analytics-scale-jobs.md).</span></span>

<span data-ttu-id="6818c-125">In generale, sono presenti 20 connessioni simultanee al servizio Web Machine Learning ogni 6 unità di streaming, ma anche i processi per 1 unità di streaming e per 3 unità di streaming ricevono 20 connessioni simultanee.</span><span class="sxs-lookup"><span data-stu-id="6818c-125">In general, there are 20 concurrent connections to the Machine Learning web service for every 6 SUs, except that 1 SU jobs and 3 SU jobs will get 20 concurrent connections also.</span></span>  <span data-ttu-id="6818c-126">Ad esempio, se la velocità dei dati di input è di 200.000 eventi al secondo e le dimensioni batch hanno il valore predefinito di 1000, la latenza del servizio Web risultante con un mini-batch di 1000 eventi è di 200 ms.</span><span class="sxs-lookup"><span data-stu-id="6818c-126">For example, if the input data rate is 200,000 events per second and the batch size is left to the default of 1000 the resulting web service latency with 1000 events mini-batch is 200ms.</span></span> <span data-ttu-id="6818c-127">Ciò significa che ogni connessione può inviare 5 richieste al servizio Web Machine Learning in un secondo.</span><span class="sxs-lookup"><span data-stu-id="6818c-127">This means every connection can make 5 requests to the Machine Learning web service in a second.</span></span> <span data-ttu-id="6818c-128">Con 20 connessioni, il processo di Analisi di flusso può elaborare 20.000 eventi in 200 ms, ovvero 100.000 eventi al secondo.</span><span class="sxs-lookup"><span data-stu-id="6818c-128">With 20 connections, the Stream Analytics job can process 20,000 events in 200ms  and therefore 100,000 events in a second.</span></span> <span data-ttu-id="6818c-129">Quindi, per elaborare 200.000 eventi al secondo, il processo di Analisi di flusso necessita di 40 connessioni simultanee, pari a 12 unità di streaming.</span><span class="sxs-lookup"><span data-stu-id="6818c-129">So to process 200,000 events per second, the Stream Analytics job needs 40 concurrent connections, which comes out to 12 SUs.</span></span> <span data-ttu-id="6818c-130">Il diagramma seguente illustra le richieste dal processo di Analisi di flusso all'endpoint di servizio Web Machine Learning. Ogni 6 unità di streaming sono presenti al massimo 20 connessioni simultanee al servizio Web Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-130">The diagram below illustrates the requests from the Stream Analytics job to the Machine Learning web service endpoint – Every 6 SUs has 20 concurrent connections to Machine Learning web service at max.</span></span>

<span data-ttu-id="6818c-131">![Esempio di processo per ridimensionare Analisi di flusso con funzioni di Machine Learning 2](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-00.png "Esempio di processo per ridimensionare Analisi di flusso con funzioni di Machine Learning 2")</span><span class="sxs-lookup"><span data-stu-id="6818c-131">![Scale Stream Analytics with Machine Learning Functions 2 job example](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-00.png "Scale Stream Analytics with Machine Learning Functions 2 job example")</span></span>

<span data-ttu-id="6818c-132">In generale, posto che ***B*** sta per dimensioni batch e ***L*** sta per latenza del servizio Web per le dimensioni batch B in millisecondi, la velocità effettiva di un processo di Analisi di flusso con ***N*** unità di streaming è:</span><span class="sxs-lookup"><span data-stu-id="6818c-132">In general, ***B*** for batch size, ***L*** for the web service latency at batch size B in milliseconds, the throughput of an Stream Analytics job with ***N*** SUs is:</span></span>

<span data-ttu-id="6818c-133">![Formula per ridimensionare Analisi di flusso con funzioni di Machine Learning](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-02.png "Formula per ridimensionare Analisi di flusso con funzioni di Machine Learning")</span><span class="sxs-lookup"><span data-stu-id="6818c-133">![Scale Stream Analytics with Machine Learning Functions Formula](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-02.png "Scale Stream Analytics with Machine Learning Functions Formula")</span></span>

<span data-ttu-id="6818c-134">Prendendo in considerazione anche il numero massimo di chiamate simultanee sul lato del servizio Web Machine Learning, è consigliabile impostare il valore massimo, che attualmente è 200.</span><span class="sxs-lookup"><span data-stu-id="6818c-134">An additional consideration may be the 'max concurrent calls' on the Machine Learning web service side, it’s recommended to set this to the maximum value (200 currently).</span></span>

<span data-ttu-id="6818c-135">Per altre informazioni su questa impostazione, vedere l'articolo relativo al [ridimensionamento di servizi Web Machine Learning](../machine-learning/machine-learning-scaling-webservice.md).</span><span class="sxs-lookup"><span data-stu-id="6818c-135">For more information on this setting please review the [Scaling article for Machine Learning Web Services](../machine-learning/machine-learning-scaling-webservice.md).</span></span>

## <a name="example--sentiment-analysis"></a><span data-ttu-id="6818c-136">Esempio: Analisi di valutazione</span><span class="sxs-lookup"><span data-stu-id="6818c-136">Example – Sentiment Analysis</span></span>
<span data-ttu-id="6818c-137">L'esempio seguente include un processo di Analisi di flusso con la funzione di Machine Learning di analisi di valutazione, come descritto nell' [esercitazione sull'integrazione tra Analisi di flusso e Machine Learning](stream-analytics-machine-learning-integration-tutorial.md).</span><span class="sxs-lookup"><span data-stu-id="6818c-137">The following example includes a Stream Analytics job with the sentiment analysis Machine Learning function, as described in the [Stream Analytics Machine Learning integration tutorial](stream-analytics-machine-learning-integration-tutorial.md).</span></span>

<span data-ttu-id="6818c-138">La query è una semplice query completamente partizionata seguita dalla funzione di **valutazione** , come illustrato di seguito:</span><span class="sxs-lookup"><span data-stu-id="6818c-138">The query is a simple fully partitioned query followed by the **sentiment** function, as shown below:</span></span>

    WITH subquery AS (
        SELECT text, sentiment(text) as result from input
    )

    Select text, result.[Score]
    Into output
    From subquery

<span data-ttu-id="6818c-139">Si consideri uno scenario in cui, con una velocità effettiva di 10.000 tweet al secondo è necessario creare un processo di Analisi di flusso per eseguire l'analisi di valutazione dei tweet, o eventi.</span><span class="sxs-lookup"><span data-stu-id="6818c-139">Consider the following scenario; with a throughput of 10,000 tweets per second a Stream Analytics job must be created to perform sentiment analysis of the tweets (events).</span></span> <span data-ttu-id="6818c-140">Usando 1 unità di streaming, questo processo di Analisi di flusso può riuscire a gestire il traffico?</span><span class="sxs-lookup"><span data-stu-id="6818c-140">Using 1 SU, could this Stream Analytics job be able to handle the traffic?</span></span> <span data-ttu-id="6818c-141">Mantenendo le dimensioni batch predefinite, pari a 1000, il processo deve riuscire a gestire l'input.</span><span class="sxs-lookup"><span data-stu-id="6818c-141">Using the default batch size of 1000 the job should be able to keep up with the input.</span></span> <span data-ttu-id="6818c-142">La funzione di Machine Learning aggiuntiva deve anche generare meno di un secondo di latenza, ovvero la latenza generale predefinita del servizio Web Machine Learning di analisi di valutazione, con dimensioni batch predefinite pari a 1000.</span><span class="sxs-lookup"><span data-stu-id="6818c-142">Further the added Machine Learning function should generate no more than a second of latency, which is the general default latency of the sentiment analysis Machine Learning web service (with a default batch size of 1000).</span></span> <span data-ttu-id="6818c-143">La latenza **totale** o end-to-end del processo di Analisi di flusso sarebbe normalmente di pochi secondi.</span><span class="sxs-lookup"><span data-stu-id="6818c-143">The Stream Analytics job’s **overall** or end-to-end latency would typically be a few seconds.</span></span> <span data-ttu-id="6818c-144">Esaminare ora più da vicino questo processo di Analisi di flusso, *in particolare* le chiamate di funzione di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-144">Take a more detailed look into this Stream Analytics job, *especially* the Machine Learning function calls.</span></span> <span data-ttu-id="6818c-145">Con dimensioni batch pari a 1000, una velocità effettiva di 10.000 eventi richiederà circa 10 richieste al servizio Web.</span><span class="sxs-lookup"><span data-stu-id="6818c-145">Having the batch size as 1000, a throughput of 10,000 events will take about 10 requests to web service.</span></span> <span data-ttu-id="6818c-146">Anche con 1 unità di streaming, il numero di connessioni simultanee è sufficiente per gestire il traffico di input.</span><span class="sxs-lookup"><span data-stu-id="6818c-146">Even with 1 SU, there are enough concurrent connections to accommodate this input traffic.</span></span>

<span data-ttu-id="6818c-147">Ma cosa accade se la frequenza degli eventi di input aumenta di 100 volte e il processo di Analisi di flusso deve elaborare 1.000.000 di tweet al secondo?</span><span class="sxs-lookup"><span data-stu-id="6818c-147">But what if the input event rate increases by 100x and now the Stream Analytics job needs to process 1,000,000 tweets per second?</span></span> <span data-ttu-id="6818c-148">Sono disponibili due opzioni:</span><span class="sxs-lookup"><span data-stu-id="6818c-148">There are two options:</span></span>

1. <span data-ttu-id="6818c-149">Aumentare le dimensioni batch.</span><span class="sxs-lookup"><span data-stu-id="6818c-149">Increase the batch size, or</span></span>
2. <span data-ttu-id="6818c-150">Partizionare il flusso di input per elaborare gli eventi in parallelo.</span><span class="sxs-lookup"><span data-stu-id="6818c-150">Partition the input stream to process the events in parallel</span></span>

<span data-ttu-id="6818c-151">Con la prima opzione aumenta la **latenza** del processo.</span><span class="sxs-lookup"><span data-stu-id="6818c-151">With the first option, the job **latency** will increase.</span></span>

<span data-ttu-id="6818c-152">Con la seconda opzione è necessario effettuare il provisioning di altre unità di streaming e quindi generare un numero maggiore di richieste simultanee al servizio Web Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-152">With the second option, more SUs would need to be provisioned and therefore generate more concurrent Machine Learning web service requests.</span></span> <span data-ttu-id="6818c-153">Ciò significa che aumenta il **costo** del processo.</span><span class="sxs-lookup"><span data-stu-id="6818c-153">This means the job **cost** will increase.</span></span>

<span data-ttu-id="6818c-154">Si supponga che la latenza del servizio Web Machine Learning di analisi di valutazione sia pari a 200 ms per batch di 1000 eventi o meno, 250 ms per batch di 5.000 eventi, 300 ms per batch di 10.000 eventi o 500 ms per batch di 25.000 eventi.</span><span class="sxs-lookup"><span data-stu-id="6818c-154">Assume the latency of the sentiment analysis Machine Learning web service is 200ms for 1000-event batches or below, 250ms for 5,000-event batches, 300ms for 10,000-event batches or 500ms for 25,000-event batches.</span></span>

1. <span data-ttu-id="6818c-155">Usando la prima opzione, **non** effettuando quindi il provisioning di altre unità di streaming, sarebbe possibile aumentare le dimensioni batch a **25.000**.</span><span class="sxs-lookup"><span data-stu-id="6818c-155">Using the first option, (**not** provisioning more SUs), the batch size could be increased to **25,000**.</span></span> <span data-ttu-id="6818c-156">Questo consentirebbe al processo di elaborare 1.000.000 di eventi con 20 connessioni simultanee al servizio Web Machine Learning, con una latenza di 500 ms per ogni chiamata.</span><span class="sxs-lookup"><span data-stu-id="6818c-156">This in turn would allow the job to process 1,000,000 events with 20 concurrent connections to the Machine Learning web service (with a latency of 500ms per call).</span></span> <span data-ttu-id="6818c-157">La latenza aggiuntiva del processo di Analisi di flusso dovuta alle richieste della funzione di valutazione rispetto alle richieste del servizio Web Machine Learning aumenterebbe da **200 ms** a **500 ms**.</span><span class="sxs-lookup"><span data-stu-id="6818c-157">So the additional latency of the Stream Analytics job due to the sentiment function requests against the Machine Learning web service requests would be increased from **200ms** to **500ms**.</span></span> <span data-ttu-id="6818c-158">Si noti tuttavia che **non è possibile** aumentare le dimensioni batch all'infinito, dato che i servizi Web Machine Learning richiedono dimensioni del payload della richiesta pari a 4 MB. Le richieste al servizio Web di dimensioni inferiori scadono dopo 100 secondi di attività.</span><span class="sxs-lookup"><span data-stu-id="6818c-158">However, note that batch size **cannot** be increased infinitely as the Machine Learning web services requires the payload size of a request be 4MB or smaller web service requests timeout after 100 seconds of operation.</span></span>
2. <span data-ttu-id="6818c-159">Se si usa la seconda opzione, le dimensioni batch rimangono pari a 1000. Con una latenza del servizio Web di 200 ms, ogni 20 connessioni simultanee al servizio Web sarebbe possibile elaborare 1000 * 20 * 5 = 100.000 eventi al secondo.</span><span class="sxs-lookup"><span data-stu-id="6818c-159">Using the second option, the batch size is left at 1000, with 200ms web service latency, every 20 concurrent connections to the web service would be able to process 1000 * 20 * 5 events = 100,000 per second.</span></span> <span data-ttu-id="6818c-160">Per elaborare 1.000.000 di eventi al secondo, quindi, il processo richiederebbe 60 unità di streaming.</span><span class="sxs-lookup"><span data-stu-id="6818c-160">So to process 1,000,000 events per second, the job would need 60 SUs.</span></span> <span data-ttu-id="6818c-161">Rispetto alla prima opzione, il processo di Analisi di flusso invierebbe più richieste batch al servizio Web, generando così un costo maggiore.</span><span class="sxs-lookup"><span data-stu-id="6818c-161">Compared to the first option, Stream Analytics job would make more web service batch requests, in turn generating an increased cost.</span></span>

<span data-ttu-id="6818c-162">Di seguito è riportata una tabella della velocità effettiva del processo di Analisi di flusso per diverse unità di streaming e dimensioni batch, in numero di eventi al secondo.</span><span class="sxs-lookup"><span data-stu-id="6818c-162">Below is a table for the throughput of the Stream Analytics job for different SUs and batch sizes (in number of events per second).</span></span>

| <span data-ttu-id="6818c-163">Dimensioni batch (latenza ML)</span><span class="sxs-lookup"><span data-stu-id="6818c-163">batch size (ML latency)</span></span> | <span data-ttu-id="6818c-164">500 (200 ms)</span><span class="sxs-lookup"><span data-stu-id="6818c-164">500 (200ms)</span></span> | <span data-ttu-id="6818c-165">1.000 (200 ms)</span><span class="sxs-lookup"><span data-stu-id="6818c-165">1,000 (200ms)</span></span> | <span data-ttu-id="6818c-166">5.000 (250 ms)</span><span class="sxs-lookup"><span data-stu-id="6818c-166">5,000 (250ms)</span></span> | <span data-ttu-id="6818c-167">10.000 (300 ms)</span><span class="sxs-lookup"><span data-stu-id="6818c-167">10,000 (300ms)</span></span> | <span data-ttu-id="6818c-168">25.000 (500 ms)</span><span class="sxs-lookup"><span data-stu-id="6818c-168">25,000 (500ms)</span></span> |
| --- | --- | --- | --- | --- | --- |
| <span data-ttu-id="6818c-169">**1 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-169">**1 SU**</span></span> |<span data-ttu-id="6818c-170">2.500</span><span class="sxs-lookup"><span data-stu-id="6818c-170">2,500</span></span> |<span data-ttu-id="6818c-171">5.000</span><span class="sxs-lookup"><span data-stu-id="6818c-171">5,000</span></span> |<span data-ttu-id="6818c-172">20.000</span><span class="sxs-lookup"><span data-stu-id="6818c-172">20,000</span></span> |<span data-ttu-id="6818c-173">30.000</span><span class="sxs-lookup"><span data-stu-id="6818c-173">30,000</span></span> |<span data-ttu-id="6818c-174">50.000</span><span class="sxs-lookup"><span data-stu-id="6818c-174">50,000</span></span> |
| <span data-ttu-id="6818c-175">**3 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-175">**3 SUs**</span></span> |<span data-ttu-id="6818c-176">2.500</span><span class="sxs-lookup"><span data-stu-id="6818c-176">2,500</span></span> |<span data-ttu-id="6818c-177">5.000</span><span class="sxs-lookup"><span data-stu-id="6818c-177">5,000</span></span> |<span data-ttu-id="6818c-178">20.000</span><span class="sxs-lookup"><span data-stu-id="6818c-178">20,000</span></span> |<span data-ttu-id="6818c-179">30.000</span><span class="sxs-lookup"><span data-stu-id="6818c-179">30,000</span></span> |<span data-ttu-id="6818c-180">50.000</span><span class="sxs-lookup"><span data-stu-id="6818c-180">50,000</span></span> |
| <span data-ttu-id="6818c-181">**6 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-181">**6 SUs**</span></span> |<span data-ttu-id="6818c-182">2.500</span><span class="sxs-lookup"><span data-stu-id="6818c-182">2,500</span></span> |<span data-ttu-id="6818c-183">5.000</span><span class="sxs-lookup"><span data-stu-id="6818c-183">5,000</span></span> |<span data-ttu-id="6818c-184">20.000</span><span class="sxs-lookup"><span data-stu-id="6818c-184">20,000</span></span> |<span data-ttu-id="6818c-185">30.000</span><span class="sxs-lookup"><span data-stu-id="6818c-185">30,000</span></span> |<span data-ttu-id="6818c-186">50.000</span><span class="sxs-lookup"><span data-stu-id="6818c-186">50,000</span></span> |
| <span data-ttu-id="6818c-187">**12 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-187">**12 SUs**</span></span> |<span data-ttu-id="6818c-188">5.000</span><span class="sxs-lookup"><span data-stu-id="6818c-188">5,000</span></span> |<span data-ttu-id="6818c-189">10.000</span><span class="sxs-lookup"><span data-stu-id="6818c-189">10,000</span></span> |<span data-ttu-id="6818c-190">40.000</span><span class="sxs-lookup"><span data-stu-id="6818c-190">40,000</span></span> |<span data-ttu-id="6818c-191">60.000</span><span class="sxs-lookup"><span data-stu-id="6818c-191">60,000</span></span> |<span data-ttu-id="6818c-192">100.000</span><span class="sxs-lookup"><span data-stu-id="6818c-192">100,000</span></span> |
| <span data-ttu-id="6818c-193">**18 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-193">**18 SUs**</span></span> |<span data-ttu-id="6818c-194">7.500</span><span class="sxs-lookup"><span data-stu-id="6818c-194">7,500</span></span> |<span data-ttu-id="6818c-195">15.000</span><span class="sxs-lookup"><span data-stu-id="6818c-195">15,000</span></span> |<span data-ttu-id="6818c-196">60.000</span><span class="sxs-lookup"><span data-stu-id="6818c-196">60,000</span></span> |<span data-ttu-id="6818c-197">90.000</span><span class="sxs-lookup"><span data-stu-id="6818c-197">90,000</span></span> |<span data-ttu-id="6818c-198">150.000</span><span class="sxs-lookup"><span data-stu-id="6818c-198">150,000</span></span> |
| <span data-ttu-id="6818c-199">**24 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-199">**24 SUs**</span></span> |<span data-ttu-id="6818c-200">10.000</span><span class="sxs-lookup"><span data-stu-id="6818c-200">10,000</span></span> |<span data-ttu-id="6818c-201">20.000</span><span class="sxs-lookup"><span data-stu-id="6818c-201">20,000</span></span> |<span data-ttu-id="6818c-202">80.000</span><span class="sxs-lookup"><span data-stu-id="6818c-202">80,000</span></span> |<span data-ttu-id="6818c-203">120.000</span><span class="sxs-lookup"><span data-stu-id="6818c-203">120,000</span></span> |<span data-ttu-id="6818c-204">200.000</span><span class="sxs-lookup"><span data-stu-id="6818c-204">200,000</span></span> |
| <span data-ttu-id="6818c-205">**…**</span><span class="sxs-lookup"><span data-stu-id="6818c-205">**…**</span></span> |<span data-ttu-id="6818c-206">…</span><span class="sxs-lookup"><span data-stu-id="6818c-206">…</span></span> |<span data-ttu-id="6818c-207">…</span><span class="sxs-lookup"><span data-stu-id="6818c-207">…</span></span> |<span data-ttu-id="6818c-208">…</span><span class="sxs-lookup"><span data-stu-id="6818c-208">…</span></span> |<span data-ttu-id="6818c-209">…</span><span class="sxs-lookup"><span data-stu-id="6818c-209">…</span></span> |<span data-ttu-id="6818c-210">…</span><span class="sxs-lookup"><span data-stu-id="6818c-210">…</span></span> |
| <span data-ttu-id="6818c-211">**60 unità di archiviazione**</span><span class="sxs-lookup"><span data-stu-id="6818c-211">**60 SUs**</span></span> |<span data-ttu-id="6818c-212">25.000</span><span class="sxs-lookup"><span data-stu-id="6818c-212">25,000</span></span> |<span data-ttu-id="6818c-213">50.000</span><span class="sxs-lookup"><span data-stu-id="6818c-213">50,000</span></span> |<span data-ttu-id="6818c-214">200.000</span><span class="sxs-lookup"><span data-stu-id="6818c-214">200,000</span></span> |<span data-ttu-id="6818c-215">300.000</span><span class="sxs-lookup"><span data-stu-id="6818c-215">300,000</span></span> |<span data-ttu-id="6818c-216">500.000</span><span class="sxs-lookup"><span data-stu-id="6818c-216">500,000</span></span> |

<span data-ttu-id="6818c-217">A questo punto dovrebbe essere chiaro il funzionamento delle funzioni di Machine Learning in Analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-217">By now, you should already have a good understanding of how Machine Learning functions in Stream Analytics work.</span></span> <span data-ttu-id="6818c-218">I processi di Analisi di flusso eseguono il pull dei dati dalle origini dati e ogni pull restituisce un batch di eventi al processo di Analisi di flusso per l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="6818c-218">You likely also understand that Stream Analytics jobs “pull” data from data sources and each “pull” returns a batch of events for the Stream Analytics job to process.</span></span> <span data-ttu-id="6818c-219">Come influisce tale modello pull sulle richieste al servizio Web Machine Learning?</span><span class="sxs-lookup"><span data-stu-id="6818c-219">How does this pull model impact the Machine Learning web service requests?</span></span>

<span data-ttu-id="6818c-220">In genere, le dimensioni batch impostate per le funzioni di Machine Learning non sono esattamente divisibili per il numero di eventi restituiti da ogni pull del processo di Analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-220">Normally, the batch size we set for Machine Learning functions won’t exactly be divisible by the number of events returned by each Stream Analytics job “pull”.</span></span> <span data-ttu-id="6818c-221">Quando ciò accade, il servizio web Machine Learning viene chiamato con batch parziali.</span><span class="sxs-lookup"><span data-stu-id="6818c-221">When this occurs the Machine Learning web service will be called with “partial” batches.</span></span> <span data-ttu-id="6818c-222">Questo per non causare un sovraccarico della latenza dei processi nell'unione di eventi tra un pull e l'altro.</span><span class="sxs-lookup"><span data-stu-id="6818c-222">This is done to not incur additional job latency overhead in coalescing events from pull to pull.</span></span>

## <a name="new-function-related-monitoring-metrics"></a><span data-ttu-id="6818c-223">Nuove metriche di monitoraggio correlate alle funzioni</span><span class="sxs-lookup"><span data-stu-id="6818c-223">New function-related monitoring metrics</span></span>
<span data-ttu-id="6818c-224">Nell'area di monitoraggio di un processo di Analisi di flusso sono state aggiunte altre tre metriche relative alle funzioni.</span><span class="sxs-lookup"><span data-stu-id="6818c-224">In the Monitor area of a Stream Analytics job, three additional function-related metrics have been added.</span></span> <span data-ttu-id="6818c-225">Le metriche sono FUNCTION REQUESTS, FUNCTION EVENTS e FAILED FUNCTION REQUESTS e sono illustrate nella figura seguente.</span><span class="sxs-lookup"><span data-stu-id="6818c-225">They are FUNCTION REQUESTS, FUNCTION EVENTS and FAILED FUNCTION REQUESTS, as shown in the graphic below.</span></span>

<span data-ttu-id="6818c-226">![Metriche per ridimensionare Analisi di flusso con funzioni di Machine Learning](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-01.png "Metriche per ridimensionare Analisi di flusso con funzioni di Machine Learning")</span><span class="sxs-lookup"><span data-stu-id="6818c-226">![Scale Stream Analytics with Machine Learning Functions Metrics](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-01.png "Scale Stream Analytics with Machine Learning Functions Metrics")</span></span>

<span data-ttu-id="6818c-227">Di seguito sono riportate le rispettive definizioni.</span><span class="sxs-lookup"><span data-stu-id="6818c-227">The are defined as follows:</span></span>

<span data-ttu-id="6818c-228">**FUNCTION REQUESTS**: numero di richieste di funzione.</span><span class="sxs-lookup"><span data-stu-id="6818c-228">**FUNCTION REQUESTS**: The number of function requests.</span></span>

<span data-ttu-id="6818c-229">**FUNCTION EVENTS**: numero di eventi nelle richieste di funzione.</span><span class="sxs-lookup"><span data-stu-id="6818c-229">**FUNCTION EVENTS**: The number events in the function requests.</span></span>

<span data-ttu-id="6818c-230">**FAILED FUNCTION REQUESTS**: numero di richieste di funzione non riuscite.</span><span class="sxs-lookup"><span data-stu-id="6818c-230">**FAILED FUNCTION REQUESTS**: The number of failed function requests.</span></span>

## <a name="key-takeaways"></a><span data-ttu-id="6818c-231">Risultati principali</span><span class="sxs-lookup"><span data-stu-id="6818c-231">Key Takeaways</span></span>
<span data-ttu-id="6818c-232">Per riepilogare i punti principali, per ridimensionare un processo di Analisi di flusso con funzioni di Machine Learning è necessario prendere in considerazione gli elementi seguenti:</span><span class="sxs-lookup"><span data-stu-id="6818c-232">To summarize the main points, in order to scale an Stream Analytics job with Machine Learning functions, the following items must be considered:</span></span>

1. <span data-ttu-id="6818c-233">Frequenza degli eventi di input.</span><span class="sxs-lookup"><span data-stu-id="6818c-233">The input event rate</span></span>
2. <span data-ttu-id="6818c-234">Latenza consentita per il processo di Analisi di flusso in esecuzione e dimensioni batch delle richieste al servizio Web Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6818c-234">The tolerated latency for the running Stream Analytics job (and thus the batch size of the Machine Learning web service requests)</span></span>
3. <span data-ttu-id="6818c-235">Unità di streaming di Analisi di flusso di cui è stato effettuato il provisioning e numero di richieste al servizio Web Machine Learning, oltre ai costi aggiuntivi correlati alle funzioni.</span><span class="sxs-lookup"><span data-stu-id="6818c-235">The provisioned Stream Analytics SUs and the number of Machine Learning web service requests (the additional function-related costs)</span></span>

<span data-ttu-id="6818c-236">È stata usata come esempio una query di Analisi di flusso completamente partizionata.</span><span class="sxs-lookup"><span data-stu-id="6818c-236">A fully partitioned Stream Analytics query was used as an example.</span></span> <span data-ttu-id="6818c-237">Se è necessaria una query più complessa, è possibile usare il [forum di analisi di flusso di Azure](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics) per ottenere altre informazioni dal team di analisi di flusso.</span><span class="sxs-lookup"><span data-stu-id="6818c-237">If a more complex query is needed the [Azure Stream Analytics forum](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics) is a great resource for getting additional help from the Stream Analytics team.</span></span>

## <a name="next-steps"></a><span data-ttu-id="6818c-238">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="6818c-238">Next steps</span></span>
<span data-ttu-id="6818c-239">Per altre informazioni su Analisi di flusso, vedere:</span><span class="sxs-lookup"><span data-stu-id="6818c-239">To learn more about Stream Analytics, see:</span></span>

* [<span data-ttu-id="6818c-240">Introduzione all'uso di Analisi dei flussi di Azure</span><span class="sxs-lookup"><span data-stu-id="6818c-240">Get started using Azure Stream Analytics</span></span>](stream-analytics-real-time-fraud-detection.md)
* [<span data-ttu-id="6818c-241">Ridimensionare i processi di Analisi dei flussi di Azure</span><span class="sxs-lookup"><span data-stu-id="6818c-241">Scale Azure Stream Analytics jobs</span></span>](stream-analytics-scale-jobs.md)
* [<span data-ttu-id="6818c-242">Informazioni di riferimento sul linguaggio di query di Analisi dei flussi di Azure</span><span class="sxs-lookup"><span data-stu-id="6818c-242">Azure Stream Analytics Query Language Reference</span></span>](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [<span data-ttu-id="6818c-243">Informazioni di riferimento sulle API REST di gestione di Analisi di flusso di Azure</span><span class="sxs-lookup"><span data-stu-id="6818c-243">Azure Stream Analytics Management REST API Reference</span></span>](https://msdn.microsoft.com/library/azure/dn835031.aspx)
