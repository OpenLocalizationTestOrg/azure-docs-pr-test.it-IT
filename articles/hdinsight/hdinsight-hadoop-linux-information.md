---
title: Suggerimenti per l'uso di Hadoop in HDInsight basato su Linux - Azure | Documentazione Microsoft
description: "Ottenere suggerimenti di implementazione per l’uso di cluster HDInsight (Hadoop) basati su Linux in un ambiente Linux familiare, in esecuzione nel cloud di Azure."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: c41c611c-5798-4c14-81cc-bed1e26b5609
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 8c6ff4a6b8617cda9b12be060c7c7bed62cb3f44
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/03/2017
---
# <a name="information-about-using-hdinsight-on-linux"></a><span data-ttu-id="b6135-103">Informazioni sull'uso di HDInsight in Linux</span><span class="sxs-lookup"><span data-stu-id="b6135-103">Information about using HDInsight on Linux</span></span>

<span data-ttu-id="b6135-104">I cluster Azure HDInsight mettono a disposizione Hadoop in un ambiente Linux familiare, in esecuzione nel cloud di Azure.</span><span class="sxs-lookup"><span data-stu-id="b6135-104">Azure HDInsight clusters provide Hadoop on a familiar Linux environment, running in the Azure cloud.</span></span> <span data-ttu-id="b6135-105">Per la maggior parte delle operazioni, dovrebbe funzionare esattamente come qualsiasi altra installazione di Hadoop in Linux.</span><span class="sxs-lookup"><span data-stu-id="b6135-105">For most things, it should work exactly as any other Hadoop-on-Linux installation.</span></span> <span data-ttu-id="b6135-106">Questo documento indica le differenze specifiche che è opportuno conoscere.</span><span class="sxs-lookup"><span data-stu-id="b6135-106">This document calls out specific differences that you should be aware of.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="b6135-107">Linux è l'unico sistema operativo usato in HDInsight versione 3.4 o successiva.</span><span class="sxs-lookup"><span data-stu-id="b6135-107">Linux is the only operating system used on HDInsight version 3.4 or greater.</span></span> <span data-ttu-id="b6135-108">Per altre informazioni, vedere la sezione relativa al [ritiro di HDInsight in Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span><span class="sxs-lookup"><span data-stu-id="b6135-108">For more information, see [HDInsight retirement on Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span></span>

## <a name="prerequisites"></a><span data-ttu-id="b6135-109">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="b6135-109">Prerequisites</span></span>

<span data-ttu-id="b6135-110">In molti passaggi di questo documento vengono usate le utilità seguenti che devono essere installate nel sistema.</span><span class="sxs-lookup"><span data-stu-id="b6135-110">Many of the steps in this document use the following utilities, which may need to be installed on your system.</span></span>

* <span data-ttu-id="b6135-111">[cURL](https://curl.haxx.se/) : consente di comunicare con servizi basati su Web</span><span class="sxs-lookup"><span data-stu-id="b6135-111">[cURL](https://curl.haxx.se/) - used to communicate with web-based services</span></span>
* <span data-ttu-id="b6135-112">[jq](https://stedolan.github.io/jq/) : consente di analizzare i documenti JSON</span><span class="sxs-lookup"><span data-stu-id="b6135-112">[jq](https://stedolan.github.io/jq/) - used to parse JSON documents</span></span>
* <span data-ttu-id="b6135-113">[Interfaccia della riga di comando di Azure 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (anteprima): consente di gestire in remoto i servizi di Azure</span><span class="sxs-lookup"><span data-stu-id="b6135-113">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (preview) - used to remotely manage Azure services</span></span>

## <a name="users"></a><span data-ttu-id="b6135-114">Utenti</span><span class="sxs-lookup"><span data-stu-id="b6135-114">Users</span></span>

<span data-ttu-id="b6135-115">A meno che non sia [aggiunto al dominio](hdinsight-domain-joined-introduction.md), HDInsight deve essere considerato un sistema a **utente singolo**.</span><span class="sxs-lookup"><span data-stu-id="b6135-115">Unless [domain-joined](hdinsight-domain-joined-introduction.md), HDInsight should be considered a **single-user** system.</span></span> <span data-ttu-id="b6135-116">Con il cluster viene creato un singolo account utente SSH, con autorizzazioni a livello di amministratore.</span><span class="sxs-lookup"><span data-stu-id="b6135-116">A single SSH user account is created with the cluster, with administrator level permissions.</span></span> <span data-ttu-id="b6135-117">Possono essere creati altri account SSH, che avranno sempre l'accesso di amministratore al cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-117">Additional SSH accounts can be created, but they also have administrator access to the cluster.</span></span>

<span data-ttu-id="b6135-118">HDInsight aggiunto al dominio offre il supporto per più utenti e impostazioni di autorizzazioni e ruoli più granulari.</span><span class="sxs-lookup"><span data-stu-id="b6135-118">Domain-joined HDInsight supports multiple users and more granular permission and role settings.</span></span> <span data-ttu-id="b6135-119">Per altre informazioni, vedere [Manage Domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md) (Gestire cluster HDInsight aggiunti al dominio).</span><span class="sxs-lookup"><span data-stu-id="b6135-119">For more information, see [Manage Domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md).</span></span>

## <a name="domain-names"></a><span data-ttu-id="b6135-120">Nomi di dominio</span><span class="sxs-lookup"><span data-stu-id="b6135-120">Domain names</span></span>

<span data-ttu-id="b6135-121">Il nome di dominio completo (FQDN) da usare per la connessione al cluster da Internet è **&lt;nome cluster>.azurehdinsight.net** o (solo per SSH) **&lt;nome cluster-ssh>.azurehdinsight.net**.</span><span class="sxs-lookup"><span data-stu-id="b6135-121">The fully qualified domain name (FQDN) to use when connecting to the cluster from the internet is **&lt;clustername>.azurehdinsight.net** or (for SSH only) **&lt;clustername-ssh>.azurehdinsight.net**.</span></span>

<span data-ttu-id="b6135-122">Internamente, ogni nodo del cluster ha un nome assegnato durante la configurazione del cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-122">Internally, each node in the cluster has a name that is assigned during cluster configuration.</span></span> <span data-ttu-id="b6135-123">Per individuare i nomi del cluster, vedere la pagina **Host** nell'interfaccia utente Web Ambari.</span><span class="sxs-lookup"><span data-stu-id="b6135-123">To find the cluster names, see the **Hosts** page on the Ambari Web UI.</span></span> <span data-ttu-id="b6135-124">È anche possibile usare il codice seguente per restituire un elenco di host dall'API REST Ambari:</span><span class="sxs-lookup"><span data-stu-id="b6135-124">You can also use the following to return a list of hosts from the Ambari REST API:</span></span>

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts" | jq '.items[].Hosts.host_name'

<span data-ttu-id="b6135-125">Sostituire **PASSWORD** con la password dell'account amministratore e **CLUSTERNAME** con il nome del cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-125">Replace **PASSWORD** with the password of the admin account, and **CLUSTERNAME** with the name of your cluster.</span></span> <span data-ttu-id="b6135-126">Questo comando restituisce un documento JSON che contiene un elenco degli host nel cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-126">This command returns a JSON document that contains a list of the hosts in the cluster.</span></span> <span data-ttu-id="b6135-127">Jq viene usato per estrarre il valore dell'elemento `host_name` per ogni host.</span><span class="sxs-lookup"><span data-stu-id="b6135-127">Jq is used to extract the `host_name` element value for each host.</span></span>

<span data-ttu-id="b6135-128">Se è necessario trovare il nome del nodo per un servizio specifico, è possibile eseguire una query in Ambari per tale componente.</span><span class="sxs-lookup"><span data-stu-id="b6135-128">If you need to find the name of the node for a specific service, you can query Ambari for that component.</span></span> <span data-ttu-id="b6135-129">Ad esempio, per trovare gli host per il nodo con nome HDFS, usare il comando seguente:</span><span class="sxs-lookup"><span data-stu-id="b6135-129">For example, to find the hosts for the HDFS name node, use the following command:</span></span>

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/services/HDFS/components/NAMENODE" | jq '.host_components[].HostRoles.host_name'

<span data-ttu-id="b6135-130">Questo comando restituisce un documento JSON che descrive il servizio e quindi jq estrae solo il valore `host_name` per gli host.</span><span class="sxs-lookup"><span data-stu-id="b6135-130">This command returns a JSON document describing the service, and then jq pulls out only the `host_name` value for the hosts.</span></span>

## <a name="remote-access-to-services"></a><span data-ttu-id="b6135-131">Accesso remoto ai servizi</span><span class="sxs-lookup"><span data-stu-id="b6135-131">Remote access to services</span></span>

* <span data-ttu-id="b6135-132">**Ambari (Web)**: https://&lt;nomecluster>.azurehdinsight.net</span><span class="sxs-lookup"><span data-stu-id="b6135-132">**Ambari (web)** - https://&lt;clustername>.azurehdinsight.net</span></span>

    <span data-ttu-id="b6135-133">Eseguire l'autenticazione usando il nome utente e la password di amministratore cluster, quindi accedere ad Ambari.</span><span class="sxs-lookup"><span data-stu-id="b6135-133">Authenticate by using the cluster administrator user and password, and then log in to Ambari.</span></span>

    <span data-ttu-id="b6135-134">L'autenticazione è in testo non crittografato. Usare sempre HTTPS per garantire che la connessione sia protetta.</span><span class="sxs-lookup"><span data-stu-id="b6135-134">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="b6135-135">Alcune delle interfacce utente Web disponibili tramite Ambari hanno accesso ai nodi tramite un nome di dominio interno.</span><span class="sxs-lookup"><span data-stu-id="b6135-135">Some of the web UIs available through Ambari access nodes using an internal domain name.</span></span> <span data-ttu-id="b6135-136">I nomi di dominio interno non sono accessibili al pubblico da Internet.</span><span class="sxs-lookup"><span data-stu-id="b6135-136">Internal domain names are not publicly accessible over the internet.</span></span> <span data-ttu-id="b6135-137">È possibile ricevere errori di "server non trovato" se si tenta di accedere ad alcune funzionalità tramite Internet.</span><span class="sxs-lookup"><span data-stu-id="b6135-137">You may receive "server not found" errors when trying to access some features over the Internet.</span></span>
    >
    > <span data-ttu-id="b6135-138">Per usare le funzionalità complete dell'interfaccia utente Web di Ambari, usare un tunnel SSH per inoltrare il traffico Web al nodo head del cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-138">To use the full functionality of the Ambari web UI, use an SSH tunnel to proxy web traffic to the cluster head node.</span></span> <span data-ttu-id="b6135-139">Vedere [Usare il tunneling SSH per accedere all'interfaccia Web di Ambari, ResourceManager, JobHistory, NameNode, Oozie e altre interfacce Web](hdinsight-linux-ambari-ssh-tunnel.md)</span><span class="sxs-lookup"><span data-stu-id="b6135-139">See [Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UIs](hdinsight-linux-ambari-ssh-tunnel.md)</span></span>

* <span data-ttu-id="b6135-140">**Ambari (REST)**: https://&lt;nomecluster>.azurehdinsight.net/ambari</span><span class="sxs-lookup"><span data-stu-id="b6135-140">**Ambari (REST)** - https://&lt;clustername>.azurehdinsight.net/ambari</span></span>

    > [!NOTE]
    > <span data-ttu-id="b6135-141">Eseguire l'autenticazione usando il nome utente e la password di amministratore cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-141">Authenticate by using the cluster administrator user and password.</span></span>
    >
    > <span data-ttu-id="b6135-142">L'autenticazione è in testo non crittografato. Usare sempre HTTPS per garantire che la connessione sia protetta.</span><span class="sxs-lookup"><span data-stu-id="b6135-142">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

* <span data-ttu-id="b6135-143">**WebHCat (Templeton)**: https://&lt;nomecluster>.azurehdinsight.net/templeton</span><span class="sxs-lookup"><span data-stu-id="b6135-143">**WebHCat (Templeton)** - https://&lt;clustername>.azurehdinsight.net/templeton</span></span>

    > [!NOTE]
    > <span data-ttu-id="b6135-144">Eseguire l'autenticazione usando il nome utente e la password di amministratore cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-144">Authenticate by using the cluster administrator user and password.</span></span>
    >
    > <span data-ttu-id="b6135-145">L'autenticazione è in testo non crittografato. Usare sempre HTTPS per garantire che la connessione sia protetta.</span><span class="sxs-lookup"><span data-stu-id="b6135-145">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

* <span data-ttu-id="b6135-146">**SSH** - &lt;nome cluster>-ssh.azurehdinsight.net sulla porta 22 o 23.</span><span class="sxs-lookup"><span data-stu-id="b6135-146">**SSH** - &lt;clustername>-ssh.azurehdinsight.net on port 22 or 23.</span></span> <span data-ttu-id="b6135-147">La porta 22 viene utilizzata per connettersi al nodo head primario, mentre la porta 23 viene utilizzata per connettersi a quello secondario.</span><span class="sxs-lookup"><span data-stu-id="b6135-147">Port 22 is used to connect to the primary headnode, while 23 is used to connect to the secondary.</span></span> <span data-ttu-id="b6135-148">Per maggiori informazioni sui nodi head, vedere [Disponibilità e affidabilità dei cluster Hadoop in HDInsight](hdinsight-high-availability-linux.md).</span><span class="sxs-lookup"><span data-stu-id="b6135-148">For more information on the head nodes, see [Availability and reliability of Hadoop clusters in HDInsight](hdinsight-high-availability-linux.md).</span></span>

    > [!NOTE]
    > <span data-ttu-id="b6135-149">È possibile accedere al nodo head del cluster solo tramite SSH da un computer client.</span><span class="sxs-lookup"><span data-stu-id="b6135-149">You can only access the cluster head nodes through SSH from a client machine.</span></span> <span data-ttu-id="b6135-150">Una volta connessi, è quindi possibile accedere ai nodi di lavoro mediante SSH da un nodo head.</span><span class="sxs-lookup"><span data-stu-id="b6135-150">Once connected, you can then access the worker nodes by using SSH from a headnode.</span></span>

## <a name="file-locations"></a><span data-ttu-id="b6135-151">Percorsi dei file</span><span class="sxs-lookup"><span data-stu-id="b6135-151">File locations</span></span>

<span data-ttu-id="b6135-152">I file relativi ad Hadoop si trovano nei nodi del cluster in `/usr/hdp`.</span><span class="sxs-lookup"><span data-stu-id="b6135-152">Hadoop-related files can be found on the cluster nodes at `/usr/hdp`.</span></span> <span data-ttu-id="b6135-153">La directory contiene le sottodirectory seguenti:</span><span class="sxs-lookup"><span data-stu-id="b6135-153">This directory contains the following subdirectories:</span></span>

* <span data-ttu-id="b6135-154">**2.2.4.9-1**: il nome della directory è la versione di Hortonworks Data Platform usata da HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b6135-154">**2.2.4.9-1**: The directory name is the version of the Hortonworks Data Platform used by HDInsight.</span></span> <span data-ttu-id="b6135-155">Il numero nel cluster può essere diverso da quello elencato di seguito.</span><span class="sxs-lookup"><span data-stu-id="b6135-155">The number on your cluster may be different than the one listed here.</span></span>
* <span data-ttu-id="b6135-156">**current**: questa directory contiene collegamenti alle sottodirectory nella directory **2.2.4.9-1**.</span><span class="sxs-lookup"><span data-stu-id="b6135-156">**current**: This directory contains links to subdirectories under the **2.2.4.9-1** directory.</span></span> <span data-ttu-id="b6135-157">Questa directory esiste in modo da non dover ricordare il numero di versione.</span><span class="sxs-lookup"><span data-stu-id="b6135-157">This directory exists so that you don't have to remember the version number.</span></span>

<span data-ttu-id="b6135-158">I dati di esempio e i file con estensione jar sono disponibili nel file system Hadoop Distributed File System (HDFS) in `/example` e `/HdiSamples`</span><span class="sxs-lookup"><span data-stu-id="b6135-158">Example data and JAR files can be found on Hadoop Distributed File System at `/example` and `/HdiSamples`</span></span>

## <a name="hdfs-azure-storage-and-data-lake-store"></a><span data-ttu-id="b6135-159">HDFS, Archiviazione di Azure e Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="b6135-159">HDFS, Azure Storage, and Data Lake Store</span></span>

<span data-ttu-id="b6135-160">Nella maggior parte delle distribuzioni di Hadoop, il file system HDFS è supportato dall'archiviazione locale nei computer del cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-160">In most Hadoop distributions, HDFS is backed by local storage on the machines in the cluster.</span></span> <span data-ttu-id="b6135-161">L'uso di sistema locale può essere costoso per una soluzione basata su cloud dove viene addebitata una tariffa oraria o al minuto per le risorse di calcolo.</span><span class="sxs-lookup"><span data-stu-id="b6135-161">Using local storage can be costly for a cloud-based solution where you are charged hourly or by minute for compute resources.</span></span>

<span data-ttu-id="b6135-162">HDInsight usa i BLOB in Archiviazione di Azure o Azure Data Lake Store come archivio predefinito.</span><span class="sxs-lookup"><span data-stu-id="b6135-162">HDInsight uses either blobs in Azure Storage or Azure Data Lake Store as the default store.</span></span> <span data-ttu-id="b6135-163">Questo servizio offre i seguenti vantaggi:</span><span class="sxs-lookup"><span data-stu-id="b6135-163">These services provide the following benefits:</span></span>

* <span data-ttu-id="b6135-164">Archiviazione a lungo termine economica</span><span class="sxs-lookup"><span data-stu-id="b6135-164">Cheap long-term storage</span></span>
* <span data-ttu-id="b6135-165">Accessibilità da servizi esterni, ad esempio siti Web, utilità di caricamento e download di file, SDK di linguaggi diversi e Web browser</span><span class="sxs-lookup"><span data-stu-id="b6135-165">Accessibility from external services such as websites, file upload/download utilities, various language SDKs, and web browsers</span></span>

> [!WARNING]
> <span data-ttu-id="b6135-166">HDInsight supporta solo account di archiviazione di Azure __per uso generico__.</span><span class="sxs-lookup"><span data-stu-id="b6135-166">HDInsight only supports __General-purpose__ Azure Storage accounts.</span></span> <span data-ttu-id="b6135-167">Non supporta attualmente il tipo di account di __archiviazione BLOB__.</span><span class="sxs-lookup"><span data-stu-id="b6135-167">It does not currently support the __Blob storage__ account type.</span></span>

<span data-ttu-id="b6135-168">Un account di Archiviazione di Azure può contenere fino a 4,75 TB, anche se ogni BLOB (o file, da una prospettiva HDInsight) può arrivare fino a 195 GB.</span><span class="sxs-lookup"><span data-stu-id="b6135-168">An Azure Storage account can hold up to 4.75 TB, though individual blobs (or files from an HDInsight perspective) can only go up to 195 GB.</span></span> <span data-ttu-id="b6135-169">Azure Data Lake Store è scalabile in modo dinamico fino a contenere miliardi di file, con singoli file di dimensioni superiori a petabyte.</span><span class="sxs-lookup"><span data-stu-id="b6135-169">Azure Data Lake Store can grow dynamically to hold trillions of files, with individual files greater than a petabyte.</span></span> <span data-ttu-id="b6135-170">Per altre informazioni, leggere gli articoli di approfondimento sui [BLOB](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) e su [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).</span><span class="sxs-lookup"><span data-stu-id="b6135-170">For more information, see [Understanding blobs](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) and [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).</span></span>

<span data-ttu-id="b6135-171">Quando si usa Archiviazione di Azure o Data Lake Store, non è necessario eseguire alcuna operazione speciale da HDInsight per accedere ai dati.</span><span class="sxs-lookup"><span data-stu-id="b6135-171">When using either Azure Storage or Data Lake Store, you don't have to do anything special from HDInsight to access the data.</span></span> <span data-ttu-id="b6135-172">Ad esempio, il comando seguente elenca i file della cartella `/example/data`, indipendentemente dal fatto che sia disponibile in Archiviazione di Azure o in Data Lake Store:</span><span class="sxs-lookup"><span data-stu-id="b6135-172">For example, the following command lists files in the `/example/data` folder regardless of whether it is stored on Azure Storage or Data Lake Store:</span></span>

    hdfs dfs -ls /example/data

### <a name="uri-and-scheme"></a><span data-ttu-id="b6135-173">URI e schema</span><span class="sxs-lookup"><span data-stu-id="b6135-173">URI and scheme</span></span>

<span data-ttu-id="b6135-174">Alcuni comandi richiedono di specificare lo schema come parte dell'URI quando si accede a un file.</span><span class="sxs-lookup"><span data-stu-id="b6135-174">Some commands may require you to specify the scheme as part of the URI when accessing a file.</span></span> <span data-ttu-id="b6135-175">Ad esempio, il componente Storm-HDFS richiede di specificare lo schema.</span><span class="sxs-lookup"><span data-stu-id="b6135-175">For example, the Storm-HDFS component requires you to specify the scheme.</span></span> <span data-ttu-id="b6135-176">Quando si usa un archivio non predefinito (aggiunto al cluster come spazio di archiviazione "aggiuntivo"), è sempre necessario usare lo schema come parte dell'URI.</span><span class="sxs-lookup"><span data-stu-id="b6135-176">When using non-default storage (storage added as "additional" storage to the cluster), you must always use the scheme as part of the URI.</span></span>

<span data-ttu-id="b6135-177">Quando si usa __Archiviazione di Azure__, usare uno degli schemi URI seguenti:</span><span class="sxs-lookup"><span data-stu-id="b6135-177">When using __Azure Storage__, use one of the following URI schemes:</span></span>

* <span data-ttu-id="b6135-178">`wasb:///`: per accedere allo spazio di archiviazione predefinito usando la comunicazione non crittografata.</span><span class="sxs-lookup"><span data-stu-id="b6135-178">`wasb:///`: Access default storage using unencrypted communication.</span></span>

* <span data-ttu-id="b6135-179">`wasbs:///`: per accedere allo spazio di archiviazione predefinito usando la comunicazione crittografata.</span><span class="sxs-lookup"><span data-stu-id="b6135-179">`wasbs:///`: Access default storage using encrypted communication.</span></span>  <span data-ttu-id="b6135-180">Lo schema wasbs è supportato solo da HDInsight versione 3.6 in poi.</span><span class="sxs-lookup"><span data-stu-id="b6135-180">The wasbs scheme is supported only from HDInsight version 3.6 onwards.</span></span>

* <span data-ttu-id="b6135-181">`wasb://<container-name>@<account-name>.blob.core.windows.net/`: usato durante la comunicazione con un account di archiviazione non predefinito,</span><span class="sxs-lookup"><span data-stu-id="b6135-181">`wasb://<container-name>@<account-name>.blob.core.windows.net/`: Used when communicating with a non-default storage account.</span></span> <span data-ttu-id="b6135-182">ad esempio quando si dispone di un account di archiviazione aggiuntivo o quando si accede a dati archiviati in un account di archiviazione pubblicamente accessibile.</span><span class="sxs-lookup"><span data-stu-id="b6135-182">For example, when you have an additional storage account or when accessing data stored in a publicly accessible storage account.</span></span>

<span data-ttu-id="b6135-183">Quando si usa __Data Lake Store__, usare uno degli schemi URI seguenti:</span><span class="sxs-lookup"><span data-stu-id="b6135-183">When using __Data Lake Store__, use one of the following URI schemes:</span></span>

* <span data-ttu-id="b6135-184">`adl:///`: per accedere all' archivio Data Lake predefinito per il cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-184">`adl:///`: Access the default Data Lake Store for the cluster.</span></span>

* <span data-ttu-id="b6135-185">`adl://<storage-name>.azuredatalakestore.net/`: usato durante la comunicazione con un Data Lake Store non predefinito.</span><span class="sxs-lookup"><span data-stu-id="b6135-185">`adl://<storage-name>.azuredatalakestore.net/`: Used when communicating with a non-default Data Lake Store.</span></span> <span data-ttu-id="b6135-186">Usato anche per accedere ai dati all'esterno della directory radice del cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b6135-186">Also used to access data outside the root directory of your HDInsight cluster.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="b6135-187">Quando si usa Data Lake Store come archivio predefinito per HDInsight, è necessario specificare un percorso all'interno dell'archivio da usare come radice per l'archiviazione HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b6135-187">When using Data Lake Store as the default store for HDInsight, you must specify a path within the store to use as the root of HDInsight storage.</span></span> <span data-ttu-id="b6135-188">Il percorso predefinito è `/clusters/<cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="b6135-188">The default path is `/clusters/<cluster-name>/`.</span></span>
>
> <span data-ttu-id="b6135-189">Quando si usa `/` o `adl:///` per accedere ai dati, è possibile accedere solo ai dati memorizzati nella directory radice del cluster, ad esempio `/clusters/<cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="b6135-189">When using `/` or `adl:///` to access data, you can only access data stored in the root (for example, `/clusters/<cluster-name>/`) of the cluster.</span></span> <span data-ttu-id="b6135-190">Per accedere ai dati in un punto qualsiasi dell'archivio, usare il formato `adl://<storage-name>.azuredatalakestore.net/`.</span><span class="sxs-lookup"><span data-stu-id="b6135-190">To access data anywhere in the store, use the `adl://<storage-name>.azuredatalakestore.net/` format.</span></span>

### <a name="what-storage-is-the-cluster-using"></a><span data-ttu-id="b6135-191">Archivio usato dal cluster</span><span class="sxs-lookup"><span data-stu-id="b6135-191">What storage is the cluster using</span></span>

<span data-ttu-id="b6135-192">Ambari consente di recuperare le informazioni relative alla configurazione di archiviazione predefinita per il cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-192">You can use Ambari to retrieve the default storage configuration for the cluster.</span></span> <span data-ttu-id="b6135-193">Usare il comando seguente per recuperare le informazioni di configurazione HDFS tramite curl e filtrarle tramite [jq](https://stedolan.github.io/jq/):</span><span class="sxs-lookup"><span data-stu-id="b6135-193">Use the following command to retrieve HDFS configuration information using curl, and filter it using [jq](https://stedolan.github.io/jq/):</span></span>

```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'```

> [!NOTE]
> <span data-ttu-id="b6135-194">Viene restituita la prima configurazione applicata al server (`service_config_version=1`) che contiene queste informazioni.</span><span class="sxs-lookup"><span data-stu-id="b6135-194">This returns the first configuration applied to the server (`service_config_version=1`), which contains this information.</span></span> <span data-ttu-id="b6135-195">Potrebbe essere necessario elencare tutte le versioni di configurazione per trovare quella più recente.</span><span class="sxs-lookup"><span data-stu-id="b6135-195">You may need to list all configuration versions to find the latest one.</span></span>

<span data-ttu-id="b6135-196">Il comando restituisce un valore simile all'URI seguente:</span><span class="sxs-lookup"><span data-stu-id="b6135-196">This command returns a value similar to the following URIs:</span></span>

* <span data-ttu-id="b6135-197">`wasb://<container-name>@<account-name>.blob.core.windows.net` se si usa un account di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="b6135-197">`wasb://<container-name>@<account-name>.blob.core.windows.net` if using an Azure Storage account.</span></span>

    <span data-ttu-id="b6135-198">Il nome dell'account è il nome dell'account di archiviazione di Azure, mentre il nome del contenitore è il contenitore BLOB che è la radice del cluster di archiviazione.</span><span class="sxs-lookup"><span data-stu-id="b6135-198">The account name is the name of the Azure Storage account, while the container name is the blob container that is the root of the cluster storage.</span></span>

* <span data-ttu-id="b6135-199">`adl://home` se si usa Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="b6135-199">`adl://home` if using Azure Data Lake Store.</span></span> <span data-ttu-id="b6135-200">Per recuperare il nome dell'archivio Data Lake, usare la chiamata REST seguente:</span><span class="sxs-lookup"><span data-stu-id="b6135-200">To get the Data Lake Store name, use the following REST call:</span></span>

    ```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.hostname"] | select(. != null)'```

    <span data-ttu-id="b6135-201">Questo comando restituisce il nome host seguente: `<data-lake-store-account-name>.azuredatalakestore.net`.</span><span class="sxs-lookup"><span data-stu-id="b6135-201">This command returns the following host name: `<data-lake-store-account-name>.azuredatalakestore.net`.</span></span>

    <span data-ttu-id="b6135-202">Per recuperare la directory che nell'archivio è la radice di HDInsight, usare la chiamata REST seguente:</span><span class="sxs-lookup"><span data-stu-id="b6135-202">To get the directory within the store that is the root for HDInsight, use the following REST call:</span></span>

    ```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.mountpoint"] | select(. != null)'```

    <span data-ttu-id="b6135-203">Il comando restituisce un percorso simile al seguente: `/clusters/<hdinsight-cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="b6135-203">This command returns a path similar to the following path: `/clusters/<hdinsight-cluster-name>/`.</span></span>

<span data-ttu-id="b6135-204">Per individuare le informazioni di archiviazione usando il portale di Azure, seguire questa procedura:</span><span class="sxs-lookup"><span data-stu-id="b6135-204">You can also find the storage information using the Azure portal by using the following steps:</span></span>

1. <span data-ttu-id="b6135-205">Nel [portale di Azure](https://portal.azure.com/)selezionare il cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b6135-205">In the [Azure portal](https://portal.azure.com/), select your HDInsight cluster.</span></span>

2. <span data-ttu-id="b6135-206">Nella sezione **Proprietà** selezionare **Account di archiviazione**.</span><span class="sxs-lookup"><span data-stu-id="b6135-206">From the **Properties** section, select **Storage Accounts**.</span></span> <span data-ttu-id="b6135-207">Vengono visualizzate le informazioni di archiviazione del cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-207">The storage information for the cluster is displayed.</span></span>

### <a name="how-do-i-access-files-from-outside-hdinsight"></a><span data-ttu-id="b6135-208">Come accedere ai file dall'esterno di HDInsight</span><span class="sxs-lookup"><span data-stu-id="b6135-208">How do I access files from outside HDInsight</span></span>

<span data-ttu-id="b6135-209">Esistono vari modi per accedere ai dati dall'esterno del cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b6135-209">There are a various ways to access data from outside the HDInsight cluster.</span></span> <span data-ttu-id="b6135-210">Di seguito sono indicati alcuni collegamenti a utilità e SDK da usare per lavorare con i dati:</span><span class="sxs-lookup"><span data-stu-id="b6135-210">The following are a few links to utilities and SDKs that can be used to work with your data:</span></span>

<span data-ttu-id="b6135-211">Se si usa __Archiviazione di Azure__, vedere i collegamenti seguenti per informazioni sulle modalità di accesso ai dati:</span><span class="sxs-lookup"><span data-stu-id="b6135-211">If using __Azure Storage__, see the following links for ways that you can access your data:</span></span>

* <span data-ttu-id="b6135-212">[Interfaccia della riga di comando di Azure 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2): comandi dell'interfaccia della riga di comando per l'uso con Azure.</span><span class="sxs-lookup"><span data-stu-id="b6135-212">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2): Command-Line interface commands for working with Azure.</span></span> <span data-ttu-id="b6135-213">Dopo l'installazione, usare il comando `az storage` per informazioni sull'uso dell'archiviazione o `az storage blob` per i comandi specifici dei BLOB.</span><span class="sxs-lookup"><span data-stu-id="b6135-213">After installing, use the `az storage` command for help on using storage, or `az storage blob` for blob-specific commands.</span></span>
* <span data-ttu-id="b6135-214">[blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage): uno script Python per l'uso con i BLOB in Archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="b6135-214">[blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage): A python script for working with blobs in Azure Storage.</span></span>
* <span data-ttu-id="b6135-215">Vari SDK:</span><span class="sxs-lookup"><span data-stu-id="b6135-215">Various SDKs:</span></span>

    * [<span data-ttu-id="b6135-216">Java</span><span class="sxs-lookup"><span data-stu-id="b6135-216">Java</span></span>](https://github.com/Azure/azure-sdk-for-java)
    * [<span data-ttu-id="b6135-217">Node.js</span><span class="sxs-lookup"><span data-stu-id="b6135-217">Node.js</span></span>](https://github.com/Azure/azure-sdk-for-node)
    * [<span data-ttu-id="b6135-218">PHP</span><span class="sxs-lookup"><span data-stu-id="b6135-218">PHP</span></span>](https://github.com/Azure/azure-sdk-for-php)
    * [<span data-ttu-id="b6135-219">Python</span><span class="sxs-lookup"><span data-stu-id="b6135-219">Python</span></span>](https://github.com/Azure/azure-sdk-for-python)
    * [<span data-ttu-id="b6135-220">Ruby</span><span class="sxs-lookup"><span data-stu-id="b6135-220">Ruby</span></span>](https://github.com/Azure/azure-sdk-for-ruby)
    * [<span data-ttu-id="b6135-221">.NET</span><span class="sxs-lookup"><span data-stu-id="b6135-221">.NET</span></span>](https://github.com/Azure/azure-sdk-for-net)
    * [<span data-ttu-id="b6135-222">API REST di archiviazione</span><span class="sxs-lookup"><span data-stu-id="b6135-222">Storage REST API</span></span>](https://msdn.microsoft.com/library/azure/dd135733.aspx)

<span data-ttu-id="b6135-223">Se si usa __Azure Data Lake Store__, vedere i collegamenti seguenti per informazioni sulle modalità di accesso ai dati:</span><span class="sxs-lookup"><span data-stu-id="b6135-223">If using __Azure Data Lake Store__, see the following links for ways that you can access your data:</span></span>

* [<span data-ttu-id="b6135-224">Web browser</span><span class="sxs-lookup"><span data-stu-id="b6135-224">Web browser</span></span>](../data-lake-store/data-lake-store-get-started-portal.md)
* [<span data-ttu-id="b6135-225">PowerShell</span><span class="sxs-lookup"><span data-stu-id="b6135-225">PowerShell</span></span>](../data-lake-store/data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="b6135-226">Interfaccia della riga di comando di Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="b6135-226">Azure CLI 2.0</span></span>](../data-lake-store/data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="b6135-227">API REST WebHDFS</span><span class="sxs-lookup"><span data-stu-id="b6135-227">WebHDFS REST API</span></span>](../data-lake-store/data-lake-store-get-started-rest-api.md)
* [<span data-ttu-id="b6135-228">Strumenti di Data Lake per Visual Studio</span><span class="sxs-lookup"><span data-stu-id="b6135-228">Data Lake Tools for Visual Studio</span></span>](https://www.microsoft.com/download/details.aspx?id=49504)
* [<span data-ttu-id="b6135-229">.NET</span><span class="sxs-lookup"><span data-stu-id="b6135-229">.NET</span></span>](../data-lake-store/data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="b6135-230">Java</span><span class="sxs-lookup"><span data-stu-id="b6135-230">Java</span></span>](../data-lake-store/data-lake-store-get-started-java-sdk.md)
* [<span data-ttu-id="b6135-231">Python</span><span class="sxs-lookup"><span data-stu-id="b6135-231">Python</span></span>](../data-lake-store/data-lake-store-get-started-python.md)

## <span data-ttu-id="b6135-232"><a name="scaling"></a>Ridimensionamento del cluster</span><span class="sxs-lookup"><span data-stu-id="b6135-232"><a name="scaling"></a>Scaling your cluster</span></span>

<span data-ttu-id="b6135-233">La funzionalità di ridimensionamento del cluster consente di modificare il numero di nodi dati usati da un cluster in modo dinamico.</span><span class="sxs-lookup"><span data-stu-id="b6135-233">The cluster scaling feature allows you to dynamically change the number of data nodes used by a cluster.</span></span> <span data-ttu-id="b6135-234">È possibile eseguire operazioni di ridimensionamento mentre altri processi sono in esecuzione nel cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-234">You can perform scaling operations while other jobs or processes are running on a cluster.</span></span>

<span data-ttu-id="b6135-235">L'operazione di ridimensionamento può influire sui tipi di cluster come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="b6135-235">The different cluster types are affected by scaling as follows:</span></span>

* <span data-ttu-id="b6135-236">**Hadoop**: durante la riduzione del numero di nodi in un cluster, alcuni servizi nel cluster vengono riavviati.</span><span class="sxs-lookup"><span data-stu-id="b6135-236">**Hadoop**: When scaling down the number of nodes in a cluster, some of the services in the cluster are restarted.</span></span> <span data-ttu-id="b6135-237">È quindi possibile che al termine dell'operazione di ridimensionamento, i processi in esecuzione o in sospeso abbiano esito negativo.</span><span class="sxs-lookup"><span data-stu-id="b6135-237">Scaling operations can cause jobs running or pending to fail at the completion of the scaling operation.</span></span> <span data-ttu-id="b6135-238">In questo caso, inviare nuovamente i processi una volta completata l'operazione.</span><span class="sxs-lookup"><span data-stu-id="b6135-238">You can resubmit the jobs once the operation is complete.</span></span>
* <span data-ttu-id="b6135-239">**HBase**: i server a livello di area vengono bilanciati automaticamente entro pochi minuti dal completamento dell'operazione di ridimensionamento.</span><span class="sxs-lookup"><span data-stu-id="b6135-239">**HBase**: Regional servers are automatically balanced within a few minutes after completion of the scaling operation.</span></span> <span data-ttu-id="b6135-240">Per bilanciare manualmente i server a livello di area, seguire questa procedura:</span><span class="sxs-lookup"><span data-stu-id="b6135-240">To manually balance regional servers, use the following steps:</span></span>

    1. <span data-ttu-id="b6135-241">Connettersi al cluster HDInsight tramite SSH.</span><span class="sxs-lookup"><span data-stu-id="b6135-241">Connect to the HDInsight cluster using SSH.</span></span> <span data-ttu-id="b6135-242">Per altre informazioni, vedere [Usare SSH con HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="b6135-242">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

    2. <span data-ttu-id="b6135-243">Usare il codice seguente per avviare la shell HBase:</span><span class="sxs-lookup"><span data-stu-id="b6135-243">Use the following to start the HBase shell:</span></span>

            hbase shell

    3. <span data-ttu-id="b6135-244">Una volta caricata la shell HBase, usare il codice seguente per bilanciare manualmente i server a livello di area:</span><span class="sxs-lookup"><span data-stu-id="b6135-244">Once the HBase shell has loaded, use the following to manually balance the regional servers:</span></span>

            balancer

* <span data-ttu-id="b6135-245">**Storm**: al termine dell'operazione di ridimensionamento, ribilanciare qualsiasi topologia Storm in esecuzione.</span><span class="sxs-lookup"><span data-stu-id="b6135-245">**Storm**: You should rebalance any running Storm topologies after a scaling operation has been performed.</span></span> <span data-ttu-id="b6135-246">Il ridimensionamento consente alla topologia di rettificare le impostazioni di parallelismo in base al nuovo numero di nodi nel cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-246">Rebalancing allows the topology to readjust parallelism settings based on the new number of nodes in the cluster.</span></span> <span data-ttu-id="b6135-247">Per ribilanciare le topologie in esecuzione, usare una delle opzioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="b6135-247">To rebalance running topologies, use one of the following options:</span></span>

    * <span data-ttu-id="b6135-248">**SSH**: connettersi al server e usare il comando seguente per ribilanciare una topologia:</span><span class="sxs-lookup"><span data-stu-id="b6135-248">**SSH**: Connect to the server and use the following command to rebalance a topology:</span></span>

            storm rebalance TOPOLOGYNAME

        <span data-ttu-id="b6135-249">È anche possibile specificare parametri per eseguire l'override degli hint di parallelismo forniti in origine dalla topologia.</span><span class="sxs-lookup"><span data-stu-id="b6135-249">You can also specify parameters to override the parallelism hints originally provided by the topology.</span></span> <span data-ttu-id="b6135-250">Ad esempio, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` riconfigura la topologia con 5 processi di lavoro, 3 esecutori per il componente blue-spout e 10 esecutori per il componente yellow-bolt.</span><span class="sxs-lookup"><span data-stu-id="b6135-250">For example, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` reconfigures the topology to 5 worker processes, 3 executors for the blue-spout component, and 10 executors for the yellow-bolt component.</span></span>

    * <span data-ttu-id="b6135-251">**Interfaccia utente Storm**: usare la procedura seguente per ribilanciare una topologia usando l'interfaccia utente Storm.</span><span class="sxs-lookup"><span data-stu-id="b6135-251">**Storm UI**: Use the following steps to rebalance a topology using the Storm UI.</span></span>

        1. <span data-ttu-id="b6135-252">Aprire **https://CLUSTERNAME.azurehdinsight.net/stormui** nel Web browser, dove CLUSTERNAME corrisponde al nome del cluster Storm.</span><span class="sxs-lookup"><span data-stu-id="b6135-252">Open **https://CLUSTERNAME.azurehdinsight.net/stormui** in your web browser, where CLUSTERNAME is the name of your Storm cluster.</span></span> <span data-ttu-id="b6135-253">Se richiesto, immettere il nome amministratore (admin) del cluster HDInsight e la password specificata durante la creazione del cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-253">If prompted, enter the HDInsight cluster administrator (admin) name and password you specified when creating the cluster.</span></span>
        2. <span data-ttu-id="b6135-254">Selezionare la topologia da ribilanciare e quindi fare clic sul pulsante **Rebalance** (Ribilancia).</span><span class="sxs-lookup"><span data-stu-id="b6135-254">Select the topology you wish to rebalance, then select the **Rebalance** button.</span></span> <span data-ttu-id="b6135-255">Specificare il ritardo prima dell'esecuzione dell'operazione di ribilanciamento.</span><span class="sxs-lookup"><span data-stu-id="b6135-255">Enter the delay before the rebalance operation is performed.</span></span>

<span data-ttu-id="b6135-256">Per informazioni specifiche sul ridimensionamento del cluster HDInsight, vedere:</span><span class="sxs-lookup"><span data-stu-id="b6135-256">For specific information on scaling your HDInsight cluster, see:</span></span>

* [<span data-ttu-id="b6135-257">Gestire cluster Hadoop in HDInsight con il portale di Azure</span><span class="sxs-lookup"><span data-stu-id="b6135-257">Manage Hadoop clusters in HDInsight by using the Azure portal</span></span>](hdinsight-administer-use-portal-linux.md#scale-clusters)
* [<span data-ttu-id="b6135-258">Gestire cluster Hadoop in HDInsight usando Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="b6135-258">Manage Hadoop clusters in HDInsight by using Azure PowerShell</span></span>](hdinsight-administer-use-command-line.md#scale-clusters)

## <a name="how-do-i-install-hue-or-other-hadoop-component"></a><span data-ttu-id="b6135-259">Come si installa Hue (o un altro componente Hadoop)?</span><span class="sxs-lookup"><span data-stu-id="b6135-259">How do I install Hue (or other Hadoop component)?</span></span>

<span data-ttu-id="b6135-260">HDInsight è un servizio gestito.</span><span class="sxs-lookup"><span data-stu-id="b6135-260">HDInsight is a managed service.</span></span> <span data-ttu-id="b6135-261">Se Azure rileva un problema con il cluster, è possibile eliminare il nodo con l'errore e creare un nodo per sostituirlo.</span><span class="sxs-lookup"><span data-stu-id="b6135-261">If Azure detects a problem with the cluster, it may delete the failing node and create a node to replace it.</span></span> <span data-ttu-id="b6135-262">Se si esegue l'installazione manuale degli elementi nel cluster, questi non vengono salvati in modo permanente quando si esegue questa operazione.</span><span class="sxs-lookup"><span data-stu-id="b6135-262">If you manually install things on the cluster, they are not persisted when this operation occurs.</span></span> <span data-ttu-id="b6135-263">Usare invece le [azioni script di HDInsight](hdinsight-hadoop-customize-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="b6135-263">Instead, use [HDInsight Script Actions](hdinsight-hadoop-customize-cluster.md).</span></span> <span data-ttu-id="b6135-264">Un'azione script può essere usata per apportare le modifiche seguenti:</span><span class="sxs-lookup"><span data-stu-id="b6135-264">A script action can be used to make the following changes:</span></span>

* <span data-ttu-id="b6135-265">Installare e configurare un servizio o un sito Web, ad esempio Spark o Hue.</span><span class="sxs-lookup"><span data-stu-id="b6135-265">Install and configure a service or web site such as Spark or Hue.</span></span>
* <span data-ttu-id="b6135-266">Installare o configurare un componente che richiede modifiche di configurazione in più nodi del cluster,</span><span class="sxs-lookup"><span data-stu-id="b6135-266">Install and configure a component that requires configuration changes on multiple nodes in the cluster.</span></span> <span data-ttu-id="b6135-267">ad esempio una variabile di ambiente necessaria, la creazione di una directory di registrazione o la creazione di un file di configurazione.</span><span class="sxs-lookup"><span data-stu-id="b6135-267">For example, a required environment variable, creating of a logging directory, or creation of a configuration file.</span></span>

<span data-ttu-id="b6135-268">Le azioni script sono script Bash.</span><span class="sxs-lookup"><span data-stu-id="b6135-268">Script Actions are Bash scripts.</span></span> <span data-ttu-id="b6135-269">Gli script vengono eseguiti durante il provisioning del cluster e possono essere usati per installare e configurare componenti aggiuntivi nel cluster.</span><span class="sxs-lookup"><span data-stu-id="b6135-269">The scripts run during cluster provisioning, and can be used to install and configure additional components on the cluster.</span></span> <span data-ttu-id="b6135-270">Sono disponibili script di esempio per installare i componenti seguenti:</span><span class="sxs-lookup"><span data-stu-id="b6135-270">Example scripts are provided for installing the following components:</span></span>

* [<span data-ttu-id="b6135-271">Hue</span><span class="sxs-lookup"><span data-stu-id="b6135-271">Hue</span></span>](hdinsight-hadoop-hue-linux.md)
* [<span data-ttu-id="b6135-272">Giraph,</span><span class="sxs-lookup"><span data-stu-id="b6135-272">Giraph</span></span>](hdinsight-hadoop-giraph-install-linux.md)
* [<span data-ttu-id="b6135-273">Solr</span><span class="sxs-lookup"><span data-stu-id="b6135-273">Solr</span></span>](hdinsight-hadoop-solr-install-linux.md)

<span data-ttu-id="b6135-274">Per informazioni su come sviluppare azioni script personalizzate, vedere [Sviluppo di azioni script con HDInsight](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="b6135-274">For information on developing your own Script Actions, see [Script Action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

### <a name="jar-files"></a><span data-ttu-id="b6135-275">File con estensione jar</span><span class="sxs-lookup"><span data-stu-id="b6135-275">Jar files</span></span>

<span data-ttu-id="b6135-276">Alcune tecnologie Hadoop vengono fornite in file con estensione jar indipendenti contenenti funzioni usate come parte di un processo MapReduce o dall'interno di Pig o Hive.</span><span class="sxs-lookup"><span data-stu-id="b6135-276">Some Hadoop technologies are provided in self-contained jar files that contain functions used as part of a MapReduce job, or from inside Pig or Hive.</span></span> <span data-ttu-id="b6135-277">Sebbene sia possibile installarli usando azioni script, spesso non richiedono alcuna installazione e possono essere caricati nel cluster dopo il provisioning ed essere usati direttamente.</span><span class="sxs-lookup"><span data-stu-id="b6135-277">While these can be installed using Script Actions, they often don't require any setup and can be uploaded to the cluster after provisioning and used directly.</span></span> <span data-ttu-id="b6135-278">Per assicurarsi che il componente venga mantenuto dopo la nuova creazione dell'immagine del cluster, è possibile archiviare il file nella risorsa di archiviazione predefinita per il cluster (WASB o ADL).</span><span class="sxs-lookup"><span data-stu-id="b6135-278">If you want to make sure the component survives reimaging of the cluster, you can store the jar file in the default storage for your cluster (WASB or ADL).</span></span>

<span data-ttu-id="b6135-279">Se ad esempio si desidera usare l'ultima versione di [DataFu](http://datafu.incubator.apache.org/), è possibile scaricare un file con estensione jar contenente il progetto e caricarlo nel cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b6135-279">For example, if you want to use the latest version of [DataFu](http://datafu.incubator.apache.org/), you can download a jar containing the project and upload it to the HDInsight cluster.</span></span> <span data-ttu-id="b6135-280">Seguire quindi la documentazione di DataFu per informazioni sull'uso da Pig o Hive.</span><span class="sxs-lookup"><span data-stu-id="b6135-280">Then follow the DataFu documentation on how to use it from Pig or Hive.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="b6135-281">Alcuni componenti che sono file con estensione jar autonomi vengono forniti con HDInsight, ma non sono presenti nel percorso.</span><span class="sxs-lookup"><span data-stu-id="b6135-281">Some components that are standalone jar files are provided with HDInsight, but are not in the path.</span></span> <span data-ttu-id="b6135-282">Se si desidera un componente specifico, è possibile usare il comando seguente per cercarlo nel cluster:</span><span class="sxs-lookup"><span data-stu-id="b6135-282">If you are looking for a specific component, you can use the follow to search for it on your cluster:</span></span>
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> <span data-ttu-id="b6135-283">Viene restituito il percorso dei file con estensione jar corrispondenti.</span><span class="sxs-lookup"><span data-stu-id="b6135-283">This command returns the path of any matching jar files.</span></span>

<span data-ttu-id="b6135-284">Per usare una versione diversa di un componente, caricare la versione desiderata e usarla nei processi.</span><span class="sxs-lookup"><span data-stu-id="b6135-284">To use a different version of a component, upload the version you need and use it in your jobs.</span></span>

> [!WARNING]
> <span data-ttu-id="b6135-285">I componenti forniti con il cluster HDInsight sono supportati in modo completo e il supporto tecnico Microsoft contribuirà a isolare e risolvere i problemi correlati a questi componenti.</span><span class="sxs-lookup"><span data-stu-id="b6135-285">Components provided with the HDInsight cluster are fully supported and Microsoft Support helps to isolate and resolve issues related to these components.</span></span>
>
> <span data-ttu-id="b6135-286">I componenti personalizzati ricevono supporto commercialmente ragionevole per semplificare la risoluzione dei problemi.</span><span class="sxs-lookup"><span data-stu-id="b6135-286">Custom components receive commercially reasonable support to help you to further troubleshoot the issue.</span></span> <span data-ttu-id="b6135-287">È possibile che si ottenga la risoluzione dei problemi o che venga richiesto di usare i canali disponibili per le tecnologie open source, in cui è possibile ottenere supporto approfondito per la tecnologia specifica.</span><span class="sxs-lookup"><span data-stu-id="b6135-287">This might result in resolving the issue OR asking you to engage available channels for the open source technologies where deep expertise for that technology is found.</span></span> <span data-ttu-id="b6135-288">È ad esempio possibile ricorrere a molti siti di community, come il [forum MSDN per HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight) o [http://stackoverflow.com](http://stackoverflow.com).</span><span class="sxs-lookup"><span data-stu-id="b6135-288">For example, there are many community sites that can be used, like: [MSDN forum for HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight), [http://stackoverflow.com](http://stackoverflow.com).</span></span> <span data-ttu-id="b6135-289">Per i progetti Apache sono anche disponibili siti specifici in [http://apache.org](http://apache.org), ad esempio [Hadoop](http://hadoop.apache.org/) e [Spark](http://spark.apache.org/).</span><span class="sxs-lookup"><span data-stu-id="b6135-289">Also Apache projects have project sites on [http://apache.org](http://apache.org), for example: [Hadoop](http://hadoop.apache.org/), [Spark](http://spark.apache.org/).</span></span>

## <a name="next-steps"></a><span data-ttu-id="b6135-290">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="b6135-290">Next steps</span></span>

* [<span data-ttu-id="b6135-291">Eseguire la migrazione da HDInsight basato su Windows a HDInsight basato su Linux</span><span class="sxs-lookup"><span data-stu-id="b6135-291">Migrate from Windows-based HDInsight to Linux-based</span></span>](hdinsight-migrate-from-windows-to-linux.md)
* [<span data-ttu-id="b6135-292">Usare Hive con HDInsight</span><span class="sxs-lookup"><span data-stu-id="b6135-292">Use Hive with HDInsight</span></span>](hdinsight-use-hive.md)
* [<span data-ttu-id="b6135-293">Usare Pig con HDInsight</span><span class="sxs-lookup"><span data-stu-id="b6135-293">Use Pig with HDInsight</span></span>](hdinsight-use-pig.md)
* [<span data-ttu-id="b6135-294">Usare processi MapReduce con HDInsight</span><span class="sxs-lookup"><span data-stu-id="b6135-294">Use MapReduce jobs with HDInsight</span></span>](hdinsight-use-mapreduce.md)
