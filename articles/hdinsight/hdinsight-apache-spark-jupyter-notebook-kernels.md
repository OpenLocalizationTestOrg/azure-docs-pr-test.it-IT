---
title: cluster aaaKernels per server Jupyter notebook in Spark in HDInsight di Azure | Documenti Microsoft
description: Informazioni su hello PySpark PySpark3 e Spark. x Server Jupyter notebook disponibili con i cluster Spark in HDInsight di Azure.
keywords: notebook jupyter in spark, spark jupyter
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="cad77-104">Kernel per il notebook di Jupyter nei cluster Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="cad77-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="cad77-105">I cluster di HDInsight Spark includono kernel che è possibile utilizzare con i notebook Jupyter hello in Spark per il testing delle applicazioni.</span><span class="sxs-lookup"><span data-stu-id="cad77-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="cad77-106">Un kernel è un programma che esegue e interpreta il codice.</span><span class="sxs-lookup"><span data-stu-id="cad77-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="cad77-107">tre kernel Hello sono:</span><span class="sxs-lookup"><span data-stu-id="cad77-107">hello three kernels are:</span></span>

- <span data-ttu-id="cad77-108">**PySpark** per le applicazioni scritte in Python2</span><span class="sxs-lookup"><span data-stu-id="cad77-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="cad77-109">**PySpark3** per le applicazioni scritte in Python3</span><span class="sxs-lookup"><span data-stu-id="cad77-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="cad77-110">**Spark** per le applicazioni scritte in Scala</span><span class="sxs-lookup"><span data-stu-id="cad77-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="cad77-111">In questo articolo viene illustrato come toouse questi kernel e i vantaggi di hello del loro uso.</span><span class="sxs-lookup"><span data-stu-id="cad77-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="cad77-112">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="cad77-112">Prerequisites</span></span>

* <span data-ttu-id="cad77-113">Un cluster Apache Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="cad77-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="cad77-114">Per istruzioni, vedere l'articolo relativo alla [creazione di cluster Apache Spark in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="cad77-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="cad77-115">Creare un notebook di Jupyter in HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="cad77-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="cad77-116">Da hello [portale di Azure](https://portal.azure.com/), aprire il cluster.</span><span class="sxs-lookup"><span data-stu-id="cad77-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="cad77-117">Vedere [elenco e visualizzare i cluster](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) per le istruzioni di hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="cad77-118">cluster Hello viene aperto in un nuovo pannello portale.</span><span class="sxs-lookup"><span data-stu-id="cad77-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="cad77-119">Da hello **collegamenti rapidi** fare clic su **Cluster dashboard** tooopen hello **Cluster dashboard** blade.</span><span class="sxs-lookup"><span data-stu-id="cad77-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="cad77-120">Se non viene visualizzato **collegamenti rapidi**, fare clic su **Panoramica** dal menu a sinistra nel pannello hello hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="cad77-121">![Notebook di Jupyter in Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Notebook di Jupyter in Spark")</span><span class="sxs-lookup"><span data-stu-id="cad77-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="cad77-122">Fare clic su **Notebook di Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="cad77-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="cad77-123">Se richiesto, immettere le credenziali di amministratore hello cluster hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="cad77-124">È anche possibile raggiungere notebook Jupyter hello in cluster Spark dall'apertura hello seguente URL nel browser.</span><span class="sxs-lookup"><span data-stu-id="cad77-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="cad77-125">Sostituire **CLUSTERNAME** con nome hello del cluster:</span><span class="sxs-lookup"><span data-stu-id="cad77-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="cad77-126">Fare clic su **New**, quindi fare clic su **Pyspark**, **PySpark3**, o **Spark** toocreate un notebook.</span><span class="sxs-lookup"><span data-stu-id="cad77-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="cad77-127">Utilizzare kernel Spark hello per le applicazioni di Scala e kernel PySpark Applications Python2 kernel PySpark3 Python3 Applications.</span><span class="sxs-lookup"><span data-stu-id="cad77-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="cad77-128">![Kernel per il notebook di Jupyter in Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernel per il notebook di Jupyter in Spark")</span><span class="sxs-lookup"><span data-stu-id="cad77-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="cad77-129">Verrà visualizzata la finestra di un blocco per Appunti con kernel hello che è stata selezionata.</span><span class="sxs-lookup"><span data-stu-id="cad77-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="cad77-130">Vantaggi dell'utilizzo di kernel hello</span><span class="sxs-lookup"><span data-stu-id="cad77-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="cad77-131">Ecco alcuni vantaggi dell'utilizzo kernel nuovo hello con server Jupyter notebook nei cluster HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="cad77-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="cad77-132">**Contesti predefiniti**.</span><span class="sxs-lookup"><span data-stu-id="cad77-132">**Preset contexts**.</span></span> <span data-ttu-id="cad77-133">Con **PySpark**, **PySpark3**, o hello **Spark** kernel, non è necessario contesti di Spark o Hive hello tooset in modo esplicito prima di iniziare con le applicazioni.</span><span class="sxs-lookup"><span data-stu-id="cad77-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="cad77-134">I contesti sono disponibili per impostazione predefinita.</span><span class="sxs-lookup"><span data-stu-id="cad77-134">These are available by default.</span></span> <span data-ttu-id="cad77-135">Questi contesti sono:</span><span class="sxs-lookup"><span data-stu-id="cad77-135">These contexts are:</span></span>
   
   * <span data-ttu-id="cad77-136">**sc** : per il contesto Spark</span><span class="sxs-lookup"><span data-stu-id="cad77-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="cad77-137">**sqlContext** : per il contesto Hive</span><span class="sxs-lookup"><span data-stu-id="cad77-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="cad77-138">In tal caso, non è istruzioni toorun come hello seguenti contesti hello tooset:</span><span class="sxs-lookup"><span data-stu-id="cad77-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="cad77-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="cad77-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="cad77-140">In alternativa, è possibile utilizzare direttamente hello preimpostato contesti nell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="cad77-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="cad77-141">**Celle magic**.</span><span class="sxs-lookup"><span data-stu-id="cad77-141">**Cell magics**.</span></span> <span data-ttu-id="cad77-142">Hello kernel PySpark fornisce alcuni predefinite "magics", che sono comandi speciale che è possibile chiamare con `%%` (ad esempio, `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="cad77-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="cad77-143">comando magic Hello deve essere hello prima parola di una cella di codice e consentono a più righe di contenuto.</span><span class="sxs-lookup"><span data-stu-id="cad77-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="cad77-144">parola chiave Hello deve essere prima parola di hello nella cella hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="cad77-145">Aggiunta di qualsiasi altro magic hello, anche i commenti, causa un errore.</span><span class="sxs-lookup"><span data-stu-id="cad77-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="cad77-146">Per altre informazioni sui magic, vedere [questa pagina](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="cad77-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="cad77-147">Hello nella tabella seguente sono elencati magics diversi hello disponibili attraverso il kernel hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="cad77-148">Magic</span><span class="sxs-lookup"><span data-stu-id="cad77-148">Magic</span></span> | <span data-ttu-id="cad77-149">Esempio</span><span class="sxs-lookup"><span data-stu-id="cad77-149">Example</span></span> | <span data-ttu-id="cad77-150">Descrizione</span><span class="sxs-lookup"><span data-stu-id="cad77-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="cad77-151">help</span><span class="sxs-lookup"><span data-stu-id="cad77-151">help</span></span> |`%%help` |<span data-ttu-id="cad77-152">Genera una tabella di tutti i magics disponibili hello con l'esempio e la descrizione</span><span class="sxs-lookup"><span data-stu-id="cad77-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="cad77-153">info</span><span class="sxs-lookup"><span data-stu-id="cad77-153">info</span></span> |`%%info` |<span data-ttu-id="cad77-154">Informazioni sulla sessione di output per l'endpoint di inserire il corrente hello</span><span class="sxs-lookup"><span data-stu-id="cad77-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="cad77-155">CONFIGURA</span><span class="sxs-lookup"><span data-stu-id="cad77-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="cad77-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="cad77-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="cad77-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="cad77-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="cad77-158">Configura parametri hello per la creazione di una sessione.</span><span class="sxs-lookup"><span data-stu-id="cad77-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="cad77-159">Hello flag di forzatura (-f) è obbligatorio se una sessione è già stata creata, che garantisce la sessione di hello viene eliminato e ricreato.</span><span class="sxs-lookup"><span data-stu-id="cad77-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="cad77-160">Visitare la pagina relativa al [corpo della richiesta POST/sessions di Livy](https://github.com/cloudera/livy#request-body) per un elenco dei parametri validi.</span><span class="sxs-lookup"><span data-stu-id="cad77-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="cad77-161">Parametri devono essere passati come una stringa JSON e devono essere nella riga successiva hello dopo magic hello, come illustrato nell'esempio la colonna hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="cad77-162">sql</span><span class="sxs-lookup"><span data-stu-id="cad77-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="cad77-163">Esegue una query Hive sqlContext hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="cad77-164">Se hello `-o` parametro viene passato, il risultato di hello di hello query è persistente nel hello % % contesto Python locale come una [Pandas](http://pandas.pydata.org/) frame di dati.</span><span class="sxs-lookup"><span data-stu-id="cad77-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="cad77-165">local</span><span class="sxs-lookup"><span data-stu-id="cad77-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="cad77-166">Tutto il codice hello nelle righe successive viene eseguito localmente.</span><span class="sxs-lookup"><span data-stu-id="cad77-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="cad77-167">Codice deve essere valido codice Python2 anche indipendentemente dal kernel hello in uso.</span><span class="sxs-lookup"><span data-stu-id="cad77-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="cad77-168">In questo caso, anche se si seleziona **PySpark3** o **Spark** kernel durante la creazione di notebook hello, se si utilizza hello `%%local` magic in una cella, quella cella deve avere solo codice Python2 valido...</span><span class="sxs-lookup"><span data-stu-id="cad77-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="cad77-169">logs</span><span class="sxs-lookup"><span data-stu-id="cad77-169">logs</span></span> |`%%logs` |<span data-ttu-id="cad77-170">Output di hello log per la sessione corrente di inserire il hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="cad77-171">delete</span><span class="sxs-lookup"><span data-stu-id="cad77-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="cad77-172">Elimina una sessione specifica dell'endpoint di inserire il corrente hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="cad77-173">Si noti che non è possibile eliminare sessione hello viene avviata per kernel hello stesso.</span><span class="sxs-lookup"><span data-stu-id="cad77-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="cad77-174">cleanup</span><span class="sxs-lookup"><span data-stu-id="cad77-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="cad77-175">Elimina tutte le sessioni di hello per endpoint inserire il corrente hello, tra cui la sessione del blocco appunti.</span><span class="sxs-lookup"><span data-stu-id="cad77-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="cad77-176">Hello force flag -f è obbligatorio.</span><span class="sxs-lookup"><span data-stu-id="cad77-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="cad77-177">Inoltre toohello magics aggiunte dal kernel PySpark hello, è inoltre possibile utilizzare hello [incorporato IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), tra cui `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="cad77-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="cad77-178">È possibile utilizzare hello `%%sh` particolare toorun script e blocco di codice nel nodo head del cluster di hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="cad77-179">**Visualizzazione automatica**.</span><span class="sxs-lookup"><span data-stu-id="cad77-179">**Auto visualization**.</span></span> <span data-ttu-id="cad77-180">Hello **Pyspark** kernel Visualizza automaticamente l'output di hello di Hive e query SQL.</span><span class="sxs-lookup"><span data-stu-id="cad77-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="cad77-181">È possibile scegliere tra diversi tipi di visualizzazione, inclusi Table, Pie, Line, Area e Bar.</span><span class="sxs-lookup"><span data-stu-id="cad77-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="cad77-182">Parametri supportati con hello % % magic sql</span><span class="sxs-lookup"><span data-stu-id="cad77-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="cad77-183">Hello `%%sql` magic supporta diversi parametri che è possibile utilizzare il tipo hello toocontrol dell'output visualizzato quando si eseguono query.</span><span class="sxs-lookup"><span data-stu-id="cad77-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="cad77-184">Hello nella tabella seguente elenca l'output di hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="cad77-185">.</span><span class="sxs-lookup"><span data-stu-id="cad77-185">Parameter</span></span> | <span data-ttu-id="cad77-186">Esempio</span><span class="sxs-lookup"><span data-stu-id="cad77-186">Example</span></span> | <span data-ttu-id="cad77-187">Descrizione</span><span class="sxs-lookup"><span data-stu-id="cad77-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="cad77-188">-o</span><span class="sxs-lookup"><span data-stu-id="cad77-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="cad77-189">Utilizzare questo parametro toopersist hello di risultati di query hello, hello % % contesto Python locale, come un [Pandas](http://pandas.pydata.org/) frame di dati.</span><span class="sxs-lookup"><span data-stu-id="cad77-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="cad77-190">nome Hello della variabile di frame di dati di hello è hello di nome di variabile specificato.</span><span class="sxs-lookup"><span data-stu-id="cad77-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="cad77-191">-q</span><span class="sxs-lookup"><span data-stu-id="cad77-191">-q</span></span> |`-q` |<span data-ttu-id="cad77-192">Utilizzare questo tooturn off visualizzazioni per la cella hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="cad77-193">Se non si desidera tooauto-visualizzare il contenuto di hello di una cella e si desidera toocapture come un frame di dati, quindi utilizzare `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="cad77-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="cad77-194">Se si desidera tooturn off visualizzazioni senza acquisire i risultati di hello (ad esempio, per l'esecuzione di una query SQL, ad esempio un `CREATE TABLE` istruzione), utilizzare `-q` senza specificare un `-o` argomento.</span><span class="sxs-lookup"><span data-stu-id="cad77-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="cad77-195">-m</span><span class="sxs-lookup"><span data-stu-id="cad77-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="cad77-196">Dove **METHOD** è **take** o **sample**. L'impostazione predefinita è **take**.</span><span class="sxs-lookup"><span data-stu-id="cad77-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="cad77-197">Se il metodo hello **richiedere**, kernel hello seleziona gli elementi dall'inizio di hello del set di dati di risultati hello specificato da MAXROWS (descritta più avanti in questa tabella).</span><span class="sxs-lookup"><span data-stu-id="cad77-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="cad77-198">Se il metodo hello **esempio**, kernel hello un campionamento casuale gli elementi del set di dati hello in base troppo`-r` parametro, descritto di seguito in questa tabella.</span><span class="sxs-lookup"><span data-stu-id="cad77-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="cad77-199">-r</span><span class="sxs-lookup"><span data-stu-id="cad77-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="cad77-200">Qui **FRACTION** è un numero a virgola mobile compreso tra 0,0 e 1,0.</span><span class="sxs-lookup"><span data-stu-id="cad77-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="cad77-201">Se il metodo di esempio hello per query SQL hello `sample`, quindi kernel hello frazione specificata di hello elementi hello di hello set di risultati per è un campionamento casuale.</span><span class="sxs-lookup"><span data-stu-id="cad77-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="cad77-202">Ad esempio, se si esegue una query SQL con argomenti hello `-m sample -r 0.01`, % 1 hello di righe di risultati vengono campionati in modo casuale.</span><span class="sxs-lookup"><span data-stu-id="cad77-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="cad77-203">**MAXROWS** è un valore intero.</span><span class="sxs-lookup"><span data-stu-id="cad77-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="cad77-204">kernel Hello limita il numero di hello di righe di output troppo**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="cad77-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="cad77-205">Se **MAXROWS** è un numero negativo, ad esempio **-1**, quindi hello numero di righe nel set di risultati hello non è limitato.</span><span class="sxs-lookup"><span data-stu-id="cad77-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="cad77-206">**Esempio:**</span><span class="sxs-lookup"><span data-stu-id="cad77-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="cad77-207">istruzione Hello hello seguenti:</span><span class="sxs-lookup"><span data-stu-id="cad77-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="cad77-208">Seleziona tutti i record da **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="cad77-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="cad77-209">Dal momento che viene usato -q, disattiva la visualizzazione automatica.</span><span class="sxs-lookup"><span data-stu-id="cad77-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="cad77-210">Poiché si utilizzano `-m sample -r 0.1 -n 500` eseguito un campionamento casuale 10% delle righe hello hivesampletable hello e limiti hello dimensioni hello set too500 di righe di risultati.</span><span class="sxs-lookup"><span data-stu-id="cad77-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="cad77-211">Infine, poiché è utilizzato `-o query2` salva anche una serie di output di hello in un frame di dati denominato **nella query 2**.</span><span class="sxs-lookup"><span data-stu-id="cad77-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="cad77-212">Considerazioni durante l'utilizzo di hello nuovo kernel</span><span class="sxs-lookup"><span data-stu-id="cad77-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="cad77-213">A seconda del valore kernel si utilizza, lasciando notebook hello in esecuzione utilizza le risorse cluster hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="cad77-214">Con questi kernel, perché sono stati definiti i contesti di hello, semplicemente uscire notebook hello non terminare il contesto di hello e pertanto le risorse cluster hello continuano toobe in uso.</span><span class="sxs-lookup"><span data-stu-id="cad77-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="cad77-215">Una procedura consigliata è hello toouse **chiudere e interrompere** opzione notebook hello **File** menu quando si ha terminato di utilizzare Blocco note hello, che termina il contesto di hello e quindi viene chiusa hello notebook.</span><span class="sxs-lookup"><span data-stu-id="cad77-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="cad77-216">Di seguito sono riportati alcuni esempi</span><span class="sxs-lookup"><span data-stu-id="cad77-216">Show me some examples</span></span>

<span data-ttu-id="cad77-217">Quando si apre un server Jupyter notebook, vengono visualizzati due cartelle a livello di radice hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="cad77-218">Hello **PySpark** cartella contiene esempi di blocchi appunti hello che usa new **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="cad77-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="cad77-219">Hello **Scala** cartella contiene esempi di blocchi appunti hello che usa new **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="cad77-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="cad77-220">È possibile aprire hello **00 - [leggere per primo] Spark Magic Kernel funzionalità** notebook da hello **PySpark** o **Spark** cartella toolearn su magics diversi hello disponibili.</span><span class="sxs-lookup"><span data-stu-id="cad77-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="cad77-221">È inoltre possibile utilizzare hello come altri blocchi appunti di esempio disponibile in hello due cartelle toolearn tooachieve diversi scenari di utilizzo di server Jupyter notebook con i cluster HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="cad77-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="cad77-222">In cui sono archiviati i notebook hello?</span><span class="sxs-lookup"><span data-stu-id="cad77-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="cad77-223">Server Jupyter notebook vengono salvati toohello account di archiviazione associato al cluster di hello hello **/HdiNotebooks** cartella.</span><span class="sxs-lookup"><span data-stu-id="cad77-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="cad77-224">Cartelle create all'interno di Jupyter notebook e i file di testo sono accessibili dall'account di archiviazione hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="cad77-225">Ad esempio, se si utilizza Jupyter toocreate una cartella **cartella** e un blocco per Appunti **myfolder/mynotebook.ipynb**, è possibile accedere a tale notebook `/HdiNotebooks/myfolder/mynotebook.ipynb` nell'account di archiviazione hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="cad77-226">Hello inversa è anche true, vale a dire, se si carica un blocco per Appunti direttamente l'account di archiviazione tooyour in `/HdiNotebooks/mynotebook1.ipynb`, notebook hello è visibile dal server Jupyter anche.</span><span class="sxs-lookup"><span data-stu-id="cad77-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="cad77-227">Notebook rimangono nell'account di archiviazione hello anche dopo l'eliminazione di cluster hello.</span><span class="sxs-lookup"><span data-stu-id="cad77-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="cad77-228">modalità di Hello notebook salvataggio toohello account di archiviazione è compatibile con HDFS.</span><span class="sxs-lookup"><span data-stu-id="cad77-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="cad77-229">Pertanto, se si SSH in cluster hello che è possibile utilizzare i comandi di gestione di file come illustrato nel seguente frammento di codice hello:</span><span class="sxs-lookup"><span data-stu-id="cad77-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="cad77-230">Nel caso in cui sono presenti problemi di accesso di account di archiviazione hello per cluster hello, notebook hello vengono salvate anche nel nodo head hello `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="cad77-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="cad77-231">Browser supportati</span><span class="sxs-lookup"><span data-stu-id="cad77-231">Supported browser</span></span>

<span data-ttu-id="cad77-232">I notebook di Jupyter nei cluster HDInsight Spark sono supportati solo su Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="cad77-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="cad77-233">Commenti e suggerimenti</span><span class="sxs-lookup"><span data-stu-id="cad77-233">Feedback</span></span>
<span data-ttu-id="cad77-234">kernel nuovo Hello sono in continua evoluzione fase e verrà maturo nel tempo.</span><span class="sxs-lookup"><span data-stu-id="cad77-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="cad77-235">Questo potrebbe comportare un cambiamento delle API con l'evoluzione dei kernel.</span><span class="sxs-lookup"><span data-stu-id="cad77-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="cad77-236">Sono graditi commenti e suggerimenti in merito all'uso di questi nuovi kernel.</span><span class="sxs-lookup"><span data-stu-id="cad77-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="cad77-237">Ciò è utile nella determinazione versione finale di hello di questi kernel.</span><span class="sxs-lookup"><span data-stu-id="cad77-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="cad77-238">È possibile lasciare commenti/commenti e suggerimenti in hello **commenti** hello ultima sezione di questo articolo.</span><span class="sxs-lookup"><span data-stu-id="cad77-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="cad77-239"><a name="seealso"></a>Vedere anche</span><span class="sxs-lookup"><span data-stu-id="cad77-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="cad77-240">Panoramica: Apache Spark su Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="cad77-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="cad77-241">Scenari</span><span class="sxs-lookup"><span data-stu-id="cad77-241">Scenarios</span></span>
* [<span data-ttu-id="cad77-242">Spark con Business Intelligence: eseguire l'analisi interattiva dei dati con strumenti di Business Intelligence mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="cad77-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="cad77-243">Spark con Machine Learning: utilizzare Spark in HDInsight per l'analisi della temperatura di compilazione utilizzando dati HVAC</span><span class="sxs-lookup"><span data-stu-id="cad77-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="cad77-244">Spark con Machine Learning: usare Spark in HDInsight risultati dell'ispezione alimentare toopredict</span><span class="sxs-lookup"><span data-stu-id="cad77-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="cad77-245">Streaming Spark: usare Spark in HDInsight per la creazione di applicazioni di streaming in tempo reale</span><span class="sxs-lookup"><span data-stu-id="cad77-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="cad77-246">Analisi dei log del sito Web mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="cad77-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="cad77-247">Creare ed eseguire applicazioni</span><span class="sxs-lookup"><span data-stu-id="cad77-247">Create and run applications</span></span>
* [<span data-ttu-id="cad77-248">Creare un'applicazione autonoma con Scala</span><span class="sxs-lookup"><span data-stu-id="cad77-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="cad77-249">Eseguire processi in modalità remota in un cluster Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="cad77-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="cad77-250">Strumenti ed estensioni</span><span class="sxs-lookup"><span data-stu-id="cad77-250">Tools and extensions</span></span>
* [<span data-ttu-id="cad77-251">Utilizzare i plug-in strumenti di HDInsight per toocreate IntelliJ IDEA e inviare applicazioni Spark Scala</span><span class="sxs-lookup"><span data-stu-id="cad77-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="cad77-252">Utilizzare i plug-in strumenti di HDInsight per le applicazioni di Spark toodebug IntelliJ IDEA in modalità remota</span><span class="sxs-lookup"><span data-stu-id="cad77-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="cad77-253">Usare i notebook di Zeppelin con un cluster Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="cad77-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="cad77-254">Usare pacchetti esterni con i notebook Jupyter</span><span class="sxs-lookup"><span data-stu-id="cad77-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="cad77-255">Installare Jupyter nel computer e connettere il cluster HDInsight Spark tooan</span><span class="sxs-lookup"><span data-stu-id="cad77-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="cad77-256">Gestire risorse</span><span class="sxs-lookup"><span data-stu-id="cad77-256">Manage resources</span></span>
* [<span data-ttu-id="cad77-257">Gestire le risorse di cluster di hello Apache Spark in HDInsight di Azure</span><span class="sxs-lookup"><span data-stu-id="cad77-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="cad77-258">Tenere traccia ed eseguire il debug di processi in esecuzione nel cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="cad77-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
