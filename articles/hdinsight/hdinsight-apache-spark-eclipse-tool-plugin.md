---
title: 'Azure Toolkit for Eclipse: Creare applicazioni Scala per HDInsight Spark | Microsoft Docs'
description: Usare gli strumenti HDInsight in Azure Toolkit for Eclipse per creare applicazioni Spark scritte in Scala e inoltrarle a un cluster HDInsight Spark direttamente dall'IDE di Eclipse.
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: f6c79550-5803-4e13-b541-e86c4abb420b
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/24/2017
ms.author: nitinme
ms.openlocfilehash: 4bcb1987a62c0b7f4965e6fd257315e820004238
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/29/2017
---
# <a name="use-azure-toolkit-for-eclipse-to-create-spark-applications-for-an-hdinsight-cluster"></a><span data-ttu-id="02c80-103">Usare Azure Toolkit for Eclipse per creare applicazioni Spark per un cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-103">Use Azure Toolkit for Eclipse to create Spark applications for an HDInsight cluster</span></span>

<span data-ttu-id="02c80-104">Usare gli strumenti HDInsight in Azure Toolkit for Eclipse per sviluppare applicazioni Spark scritte in Scala e inoltrarle a un cluster Azure HDInsight Spark direttamente dall'IDE Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-104">Use HDInsight Tools in Azure Toolkit for Eclipse to develop Spark applications written in Scala and submit them to an Azure HDInsight Spark cluster, directly from the Eclipse IDE.</span></span> <span data-ttu-id="02c80-105">È possibile usare gli strumenti di HDInsight in diversi modi:</span><span class="sxs-lookup"><span data-stu-id="02c80-105">You can use the HDInsight Tools plug-in in a few different ways:</span></span>

* <span data-ttu-id="02c80-106">Per sviluppare e inviare un'applicazione Spark in Scala in un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="02c80-106">To develop and submit a Scala Spark application on an HDInsight Spark cluster</span></span>
* <span data-ttu-id="02c80-107">Per accedere alle risorse cluster HDInsight Spark di Azure</span><span class="sxs-lookup"><span data-stu-id="02c80-107">To access your Azure HDInsight Spark cluster resources</span></span>
* <span data-ttu-id="02c80-108">Per sviluppare ed eseguire un'applicazione Spark in Scala localmente</span><span class="sxs-lookup"><span data-stu-id="02c80-108">To develop and run a Scala Spark application locally</span></span>

> [!IMPORTANT]
> <span data-ttu-id="02c80-109">Questo strumento può essere usato per creare e inviare applicazioni solo per un cluster HDInsight Spark in Linux.</span><span class="sxs-lookup"><span data-stu-id="02c80-109">This tool can be used to create and submit applications only for an HDInsight Spark cluster on Linux.</span></span>
> 
> 

## <a name="prerequisites"></a><span data-ttu-id="02c80-110">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="02c80-110">Prerequisites</span></span>

* <span data-ttu-id="02c80-111">Un cluster Apache Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="02c80-111">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="02c80-112">Per istruzioni, vedere l'articolo relativo alla [creazione di cluster Apache Spark in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="02c80-112">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>
* <span data-ttu-id="02c80-113">Oracle Java Development Kit versione 8, usato per il runtime IDE Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-113">Oracle Java Development Kit version 8, which is used for the Eclipse IDE runtime.</span></span> <span data-ttu-id="02c80-114">È possibile scaricarlo dal [sito Web di Oracle](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).</span><span class="sxs-lookup"><span data-stu-id="02c80-114">You can download it from the [Oracle website](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).</span></span>
* <span data-ttu-id="02c80-115">Ambiente IDE Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-115">Eclipse IDE.</span></span> <span data-ttu-id="02c80-116">Questo articolo usa Eclipse Neon.</span><span class="sxs-lookup"><span data-stu-id="02c80-116">This article uses Eclipse Neon.</span></span> <span data-ttu-id="02c80-117">È possibile installarlo dal [sito Web di Eclipse](https://www.eclipse.org/downloads/).</span><span class="sxs-lookup"><span data-stu-id="02c80-117">You can install it from the [Eclipse website](https://www.eclipse.org/downloads/).</span></span>   
* <span data-ttu-id="02c80-118">Spark SDK.</span><span class="sxs-lookup"><span data-stu-id="02c80-118">Spark SDK.</span></span> <span data-ttu-id="02c80-119">È possibile scaricarlo da [GitHub](http://go.microsoft.com/fwlink/?LinkID=723585&clcid=0x409).</span><span class="sxs-lookup"><span data-stu-id="02c80-119">You can download it from [GitHub](http://go.microsoft.com/fwlink/?LinkID=723585&clcid=0x409).</span></span>


## <a name="install-hdinsight-tools-in-azure-toolkit-for-eclipse-and-scala-plugin"></a><span data-ttu-id="02c80-120">Installare gli strumenti di HDInsight in Azure Toolkit per Eclipse e plug-in Scala</span><span class="sxs-lookup"><span data-stu-id="02c80-120">Install HDInsight Tools in Azure Toolkit for Eclipse and Scala Plugin</span></span>
### <a name="install-hdinsight-tools"></a><span data-ttu-id="02c80-121">Installare gli strumenti di HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-121">Install HDInsight Tools</span></span>
<span data-ttu-id="02c80-122">Gli strumenti HDInsight per Eclipse sono disponibili come parte di Azure Toolkit for Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-122">HDInsight Tools for Eclipse is available as part of Azure Toolkit for Eclipse.</span></span> <span data-ttu-id="02c80-123">Le istruzioni di installazione sono disponibili in [Installazione di Azure Toolkit for Eclipse](../azure-toolkit-for-eclipse-installation.md).</span><span class="sxs-lookup"><span data-stu-id="02c80-123">For installation instructions, see [Installing Azure Toolkit for Eclipse](../azure-toolkit-for-eclipse-installation.md).</span></span>
### <a name="install-scala-plugin"></a><span data-ttu-id="02c80-124">Installazione di plug-in Scala</span><span class="sxs-lookup"><span data-stu-id="02c80-124">Install Scala Plugin</span></span>
<span data-ttu-id="02c80-125">Quando si apre il Intellij, strumenti di HDInsight automatica rileva se plug-in di Scala non è installato o non.</span><span class="sxs-lookup"><span data-stu-id="02c80-125">When you open the Intellij, the HDInsight Tools auto detects whether you installed Scala plugin or not.</span></span> <span data-ttu-id="02c80-126">Fare clic su **OK** per continuare e seguire le istruzioni per installare da Marketplace Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-126">Click **OK** to continue and follow the instructions to install by the Eclipse Marketplace.</span></span>

 ![Plug-in Scala di installazione automatica](./media/hdinsight-apache-spark-eclipse-tool-plugin/auto-install-scala.png)

## <a name="sign-in-to-your-azure-subscription"></a><span data-ttu-id="02c80-128">Accedere alla sottoscrizione di Azure.</span><span class="sxs-lookup"><span data-stu-id="02c80-128">Sign in to your Azure subscription</span></span>
1. <span data-ttu-id="02c80-129">Avviare l'IDE di Eclipse e aprire Azure Explorer.</span><span class="sxs-lookup"><span data-stu-id="02c80-129">Start the Eclipse IDE and open Azure Explorer.</span></span> <span data-ttu-id="02c80-130">Nel menu **Window** (Finestra) fare clic su **Show View** (Mostra visualizzazione) e quindi su **Other** (Altro).</span><span class="sxs-lookup"><span data-stu-id="02c80-130">On the **Window** menu, click **Show View**, and then click **Other**.</span></span> <span data-ttu-id="02c80-131">Nella finestra di dialogo visualizzata espandere **Azure**, fare clic su **Azure Explorer** e quindi su **OK**.</span><span class="sxs-lookup"><span data-stu-id="02c80-131">In the dialog box that opens, expand **Azure**, click **Azure Explorer**, and then click **OK**.</span></span>

    ![Finestra di dialogo Show View (Mostra visualizzazione)](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-1.png)
2. <span data-ttu-id="02c80-133">Fare clic con il pulsante destro del mouse sul nodo **Azure** e quindi su **Sign in** (Accedi).</span><span class="sxs-lookup"><span data-stu-id="02c80-133">Right-click the **Azure** node, and then click **Sign in**.</span></span>
3. <span data-ttu-id="02c80-134">Nella finestra di dialogo di **accesso ad Azure** scegliere il metodo di autenticazione, fare clic su **Sign in** (Accedi) e immettere le credenziali di Azure.</span><span class="sxs-lookup"><span data-stu-id="02c80-134">In the **Azure Sign In** dialog box, choose the authentication method, click **Sign in**, and enter your Azure credentials.</span></span>
   
    ![Finestra di dialogo di accesso di Azure](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-2.png)
4. <span data-ttu-id="02c80-136">Dopo l'accesso, la finestra di dialogo **Selezionare le sottoscrizioni** elenca tutte le sottoscrizioni di Azure associate alle credenziali.</span><span class="sxs-lookup"><span data-stu-id="02c80-136">After you're signed in, the **Select Subscriptions** dialog box lists all the Azure subscriptions associated with the credentials.</span></span> <span data-ttu-id="02c80-137">Fare clic su **Seleziona** per chiudere la finestra di dialogo.</span><span class="sxs-lookup"><span data-stu-id="02c80-137">Click **Select** to close the dialog box.</span></span>

    ![Finestra di dialogo Selezionare le sottoscrizioni](./media/hdinsight-apache-spark-eclipse-tool-plugin/Select-Subscriptions.png)
5. <span data-ttu-id="02c80-139">Nella scheda **Azure Explorer** espandere **HDInsight** per visualizzare i cluster HDInsight Spark nella sottoscrizione.</span><span class="sxs-lookup"><span data-stu-id="02c80-139">On the **Azure Explorer** tab, expand **HDInsight** to see the HDInsight Spark clusters under your subscription.</span></span>
   
    ![Cluster HDInsight Spark in Azure Explorer](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-3.png)
6. <span data-ttu-id="02c80-141">È possibile espandere ancora un nodo del nome cluster per vedere le risorse, ad esempio gli account di archiviazione, associate al cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-141">You can further expand a cluster name node to see the resources (for example, storage accounts) associated with the cluster.</span></span>
   
    ![Espansione di un nome cluster per vedere le risorse](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-4.png)



## <a name="set-up-a-spark-scala-project-for-an-hdinsight-spark-cluster"></a><span data-ttu-id="02c80-143">Configurare un progetto Spark in Scala per un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="02c80-143">Set up a Spark Scala project for an HDInsight Spark cluster</span></span>

1. <span data-ttu-id="02c80-144">Nell'area di lavoro dell'ambiente IDE Eclipse fare clic su **File**, quindi su **New** (Nuovo) e infine su **Project** (Progetto).</span><span class="sxs-lookup"><span data-stu-id="02c80-144">In the Eclipse IDE workspace, click **File**, click **New**, and then click **Project**.</span></span> 
2. <span data-ttu-id="02c80-145">Nella procedura guidata New Project (Nuovo progetto) espandere **HDInsight**, selezionare **Spark on HDInsight (Scala)** (Spark in HDInsight - Scala) e quindi fare clic su **Next** (Avanti).</span><span class="sxs-lookup"><span data-stu-id="02c80-145">In the New Project wizard, expand **HDInsight**, select **Spark on HDInsight (Scala)**, and then click **Next**.</span></span>

    ![Selezione del progetto Spark on HDInsight (Scala)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-hdi-scala-app-2.png)
3. <span data-ttu-id="02c80-147">La creazione guidata del progetto Scala rileva automaticamente se è installato il plug-in Scala.</span><span class="sxs-lookup"><span data-stu-id="02c80-147">The Scala project creation wizard auto detects whether you installed Scala plugin or not.</span></span> <span data-ttu-id="02c80-148">Fare clic su **OK** per continuare a scaricare il plug-in di Scala, quindi seguire le istruzioni di riavviare Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-148">Click **OK** to continue downloading the Scala plugin, then follow the instructions to restart Eclipse.</span></span>

    ![Controllo di Scala](./media/hdinsight-apache-spark-eclipse-tool-plugin/auto-install-scala-2.png)
4. <span data-ttu-id="02c80-150">Nella finestra di dialogo **New HDInsight Scala Project** (Nuovo progetto HDInsight Scala) specificare i valori seguenti e fare clic su **Next** (Avanti):</span><span class="sxs-lookup"><span data-stu-id="02c80-150">In the **New HDInsight Scala Project** dialog box, provide the following values, and then click **Next**:</span></span>
   * <span data-ttu-id="02c80-151">Immettere un nome per il progetto.</span><span class="sxs-lookup"><span data-stu-id="02c80-151">Enter a name for the project.</span></span>
   * <span data-ttu-id="02c80-152">Nell'area **JRE** verificare che l'opzione **Use an execution environment JRE** (Usa un ambiente di esecuzione JRE) sia impostata su **JavaSE-1.7** o versioni successive.</span><span class="sxs-lookup"><span data-stu-id="02c80-152">In the **JRE** area, make sure that **Use an execution environment JRE** is set to **JavaSE-1.7** or later.</span></span>
   * <span data-ttu-id="02c80-153">Assicurarsi che Spark SDK sia impostato sul percorso in cui è stato scaricato l'SDK.</span><span class="sxs-lookup"><span data-stu-id="02c80-153">Make sure that Spark SDK is set to the location where you downloaded the SDK.</span></span> <span data-ttu-id="02c80-154">Il collegamento al percorso di download è incluso nella sezione [Prerequisiti](#prerequisites) illustrata in precedenza in questo articolo.</span><span class="sxs-lookup"><span data-stu-id="02c80-154">The link to the download location is included in the [prerequisites](#prerequisites) earlier in this article.</span></span> <span data-ttu-id="02c80-155">È anche possibile scaricare l'SDK dal collegamento incluso nella finestra di dialogo.</span><span class="sxs-lookup"><span data-stu-id="02c80-155">You can also download the SDK from the link included in the dialog box.</span></span>

    ![Finestra di dialogo New HDInsight Scala Project (Nuovo progetto HDInsight Scala)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-hdi-scala-app-3.png)
5.  <span data-ttu-id="02c80-157">Nella finestra di dialogo successiva fare clic sulla scheda **Libraries (Librerie)**, mantenere i valori predefiniti e quindi fare clic su **Finish** (Fine).</span><span class="sxs-lookup"><span data-stu-id="02c80-157">In the next dialog box, click the **Libraries** tab and keep the defaults, and then click **Finish**.</span></span> 
   
    ![Scheda Libraries (Librerie)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-hdi-scala-app-4.png)
  
## <a name="create-a-scala-application-for-an-hdinsight-spark-cluster"></a><span data-ttu-id="02c80-159">Creare un'applicazione Scala per un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="02c80-159">Create a Scala application for an HDInsight Spark cluster</span></span>

1. <span data-ttu-id="02c80-160">Nell'ambiente IDE Eclipse in Package Explorer (Esplora pacchetti) espandere il progetto creato in precedenza, fare clic con il pulsante destro del mouse su **src**, scegliere **New** (Nuovo) e quindi fare clic su **Other** (Altro).</span><span class="sxs-lookup"><span data-stu-id="02c80-160">In the Eclipse IDE, from Package Explorer, expand the project that you created earlier, right-click **src**, point to **New**, and then click **Other**.</span></span>
2. <span data-ttu-id="02c80-161">Nella finestra di dialogo **Select a wizard** (Seleziona una procedura guidata) espandere **Scala Wizards** (Procedure guidate Scala) e fare clic su **Scala Object** (Oggetto Scala) e quindi su **Next** (Avanti).</span><span class="sxs-lookup"><span data-stu-id="02c80-161">In the **Select a wizard** dialog box, expand **Scala Wizards**, click **Scala Object**, and then click **Next**.</span></span>
   
    ![Finestra di dialogo Select a wizard (Seleziona una procedura guidata)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-1.png)
3. <span data-ttu-id="02c80-163">Nella finestra di dialogo **Create New File** (Crea nuovo file) immettere un nome per l'oggetto e quindi fare clic su **Finish** (Fine).</span><span class="sxs-lookup"><span data-stu-id="02c80-163">In the **Create New File** dialog box, enter a name for the object, and then click **Finish**.</span></span>
   
    ![Finestra di dialogo Create New File (Crea nuovo file)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-2.png)
4. <span data-ttu-id="02c80-165">Incollare il codice seguente nell'editor di testo:</span><span class="sxs-lookup"><span data-stu-id="02c80-165">Paste the following code in the text editor:</span></span>
   
        import org.apache.spark.SparkConf
        import org.apache.spark.SparkContext
   
        object MyClusterApp{
          def main (arg: Array[String]): Unit = {
            val conf = new SparkConf().setAppName("MyClusterApp")
            val sc = new SparkContext(conf)
   
            val rdd = sc.textFile("wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv")
   
            //find the rows that have only one digit in the seventh column in the CSV
            val rdd1 =  rdd.filter(s => s.split(",")(6).length() == 1)
   
            rdd1.saveAsTextFile("wasb:///HVACOut")
          }        
        }
5. <span data-ttu-id="02c80-166">Eseguire l'applicazione in un cluster HDInsight Spark:</span><span class="sxs-lookup"><span data-stu-id="02c80-166">Run the application on an HDInsight Spark cluster:</span></span>
   
   1. <span data-ttu-id="02c80-167">In Package Explorer (Esplora pacchetti) fare clic con il pulsante destro del mouse sul nome del progetto e quindi scegliere **Submit Spark Application to HDInsight** (Invia applicazione Spark a HDInsight).</span><span class="sxs-lookup"><span data-stu-id="02c80-167">From Package Explorer, right-click the project name, and then select **Submit Spark Application to HDInsight**.</span></span>        
   2. <span data-ttu-id="02c80-168">Nella finestra di dialogo **Spark Submission** (Invio Spark) specificare i valori seguenti e fare clic su **Submit** (Invia):</span><span class="sxs-lookup"><span data-stu-id="02c80-168">In the **Spark Submission** dialog box, provide the following values, and then click **Submit**:</span></span>
      
      * <span data-ttu-id="02c80-169">Per **Cluster Name**(Nome cluster) selezionare il cluster HDInsight Spark in cui eseguire l'applicazione.</span><span class="sxs-lookup"><span data-stu-id="02c80-169">For **Cluster Name**, select the HDInsight Spark cluster on which you want to run your application.</span></span>
      * <span data-ttu-id="02c80-170">Selezionare un elemento nel progetto Eclipse oppure nel disco rigido.</span><span class="sxs-lookup"><span data-stu-id="02c80-170">Select an artifact from the Eclipse project, or select one from a hard drive.</span></span> <span data-ttu-id="02c80-171">Il valore predefinito dipende dall'elemento su cui si fa clic con il pulsante destro del mouse da Package Explorer (Esplora pacchetti).</span><span class="sxs-lookup"><span data-stu-id="02c80-171">The default value depends on the item you right-click from package explorer.</span></span>
      * <span data-ttu-id="02c80-172">Nell'elenco a discesa **Main class name** (Nome classe principale) l'invio guidato visualizza tutti i nomi di oggetto del progetto selezionato.</span><span class="sxs-lookup"><span data-stu-id="02c80-172">In the **Main class name** dropdownlist, submission wizard displays all object names from your selected project.</span></span> <span data-ttu-id="02c80-173">Selezionare o inserire quello che si vuole eseguire.</span><span class="sxs-lookup"><span data-stu-id="02c80-173">Select or input one that you want to run.</span></span> <span data-ttu-id="02c80-174">Se si seleziona l'elemento dal disco rigido, è necessario inserire il nome della classe principale manualmente.</span><span class="sxs-lookup"><span data-stu-id="02c80-174">If you select artifact from hard disk, you need input main class name by yourself.</span></span> 
      * <span data-ttu-id="02c80-175">Poiché il codice dell'applicazione in questo esempio non richiede argomenti della riga di comando e non fa riferimento a JAR o file, è possibile lasciare vuote le rimanenti caselle di testo.</span><span class="sxs-lookup"><span data-stu-id="02c80-175">Because the application code in this example does not require any command-line arguments or reference JARs or files, you can leave the remaining text boxes empty.</span></span>
        
       ![Finestra di dialogo Spark Submission (Invio Spark)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-3.png)
   3. <span data-ttu-id="02c80-177">Nella scheda **Spark Submission** (Invio Spark) verrà visualizzato lo stato di avanzamento.</span><span class="sxs-lookup"><span data-stu-id="02c80-177">The **Spark Submission** tab should start displaying the progress.</span></span> <span data-ttu-id="02c80-178">È possibile arrestare l'applicazione facendo clic sul pulsante rosso nella finestra **Spark Submission** (Invio Spark).</span><span class="sxs-lookup"><span data-stu-id="02c80-178">You can stop the application by clicking the red button in the **Spark Submission** window.</span></span> <span data-ttu-id="02c80-179">È inoltre possibile visualizzare i log per questa esecuzione dell'applicazione specifica facendo clic sull'icona del mondo (indicata dalla casella blu nell'immagine).</span><span class="sxs-lookup"><span data-stu-id="02c80-179">You can also view the logs for this specific application run by clicking the globe icon (denoted by the blue box in the image).</span></span>
      
       ![Finestra Spark Submission (Invio Spark)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-4.png)

## <a name="access-and-manage-hdinsight-spark-clusters-by-using-hdinsight-tools-in-azure-toolkit-for-eclipse"></a><span data-ttu-id="02c80-181">Accedere e gestire i cluster HDInsight Spark con gli strumenti HDInsight in Azure Toolkit for Eclipse</span><span class="sxs-lookup"><span data-stu-id="02c80-181">Access and manage HDInsight Spark clusters by using HDInsight Tools in Azure Toolkit for Eclipse</span></span>
<span data-ttu-id="02c80-182">È possibile eseguire varie operazioni con gli strumenti HDInsight, tra cui accedere all'output dei processi.</span><span class="sxs-lookup"><span data-stu-id="02c80-182">You can perform various operations by using HDInsight Tools, including accessing the job output.</span></span>

### <a name="access-the-job-view"></a><span data-ttu-id="02c80-183">Accedere alla visualizzazione del processo</span><span class="sxs-lookup"><span data-stu-id="02c80-183">Access the job view</span></span>
1. <span data-ttu-id="02c80-184">In Azure Explorer espandere **HDInsight**, espandere il nome del cluster Spark e quindi fare clic su **Processi**.</span><span class="sxs-lookup"><span data-stu-id="02c80-184">In Azure Explorer, expand **HDInsight**, expand the Spark cluster name, and then click **Jobs**.</span></span> 

    ![Nodo di visualizzazione dei processi](./media/hdinsight-apache-spark-intellij-tool-plugin/job-view-node.png)

2. <span data-ttu-id="02c80-186">Fare clic su di **processi** nodo.</span><span class="sxs-lookup"><span data-stu-id="02c80-186">Click on the **Jobs** node.</span></span> <span data-ttu-id="02c80-187">Gli strumenti di HDInsight consente di rilevare automaticamente se il plug-in clipse (fx) E non è installato o non.</span><span class="sxs-lookup"><span data-stu-id="02c80-187">The HDInsight Tools auto-detects whether you installed the E(fx)clipse plugin or not.</span></span> <span data-ttu-id="02c80-188">Fare clic su **OK** per continuare e seguire le istruzioni per installare il Marketplace di Eclipse e riavviare Eclipse.</span><span class="sxs-lookup"><span data-stu-id="02c80-188">Click **OK** to continue and follow the instructions to install the Eclipse Marketplace and restart Eclipse.</span></span>

    ![Installare E(fx)clipse](./media/hdinsight-apache-spark-eclipse-tool-plugin/auto-install-efxclipse.png)

3. <span data-ttu-id="02c80-190">Aprire la visualizzazione del processo dal nodo **Processi**.</span><span class="sxs-lookup"><span data-stu-id="02c80-190">Open the Job View from the **Jobs** node.</span></span> <span data-ttu-id="02c80-191">Nel riquadro destro la scheda **Spark Job View** (Visualizzazione processi Spark) visualizza tutte le applicazioni eseguite nel cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-191">In the right pane, the **Spark Job View** tab displays all the applications that were run on the cluster.</span></span> <span data-ttu-id="02c80-192">Fare clic sul nome dell'applicazione per cui si desidera visualizzare altri dettagli.</span><span class="sxs-lookup"><span data-stu-id="02c80-192">Click the name of the application for which you want to see more details.</span></span>

    ![Dettagli applicazione](./media/hdinsight-apache-spark-intellij-tool-plugin/view-job-logs.png)
4. <span data-ttu-id="02c80-194">Se si passa il mouse sul grafico di processo, vengono visualizzate informazioni di base per processo in esecuzione.</span><span class="sxs-lookup"><span data-stu-id="02c80-194">If you hover on the job graph, it displays basic running job info.</span></span> <span data-ttu-id="02c80-195">Facendo clic sul grafico processo Mostra il grafico delle fasi e informazioni che ogni processo viene generato l'errore.</span><span class="sxs-lookup"><span data-stu-id="02c80-195">Clicking on the job graph shows the stages graph and info that every job generates.</span></span>

    ![Dettagli delle fasi dei processi](./media/hdinsight-apache-spark-intellij-tool-plugin/Job-graph-stage-info.png)

5. <span data-ttu-id="02c80-197">Registri usati di frequente, tra cui Stderr Driver, Driver Stdout e informazioni di Directory, sono elencati nel **Log** scheda.</span><span class="sxs-lookup"><span data-stu-id="02c80-197">Frequently used logs, including Driver Stderr, Driver Stdout, and Directory Info, are listed in the **Log** tab.</span></span>

    ![Dettagli del log](./media/hdinsight-apache-spark-intellij-tool-plugin/Job-log-info.png)
6. <span data-ttu-id="02c80-199">È anche possibile aprire l'interfaccia utente della cronologia di Spark e l'interfaccia utente di YARN, a livello di applicazione, facendo clic sui rispettivi collegamenti ipertestuali nella parte superiore della finestra.</span><span class="sxs-lookup"><span data-stu-id="02c80-199">You can also open the Spark history UI and the YARN UI (at the application level) by clicking the respective hyperlink at the top of the window.</span></span>

### <a name="access-the-storage-container-for-the-cluster"></a><span data-ttu-id="02c80-200">Accedere al contenitore di archiviazione per il cluster</span><span class="sxs-lookup"><span data-stu-id="02c80-200">Access the storage container for the cluster</span></span>
1. <span data-ttu-id="02c80-201">In Azure Explorer espandere il nodo radice **HDInsight** per visualizzare un elenco di cluster HDInsight Spark disponibili.</span><span class="sxs-lookup"><span data-stu-id="02c80-201">In Azure Explorer, expand the **HDInsight** root node to see a list of HDInsight Spark clusters that are available.</span></span>
2. <span data-ttu-id="02c80-202">Espandere il nome del cluster per visualizzare l'account di archiviazione e il contenitore di archiviazione predefinito per il cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-202">Expand the cluster name to see the storage account and the default storage container for the cluster.</span></span>
   
    ![Account di archiviazione e contenitore di archiviazione predefinito](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-5.png)
3. <span data-ttu-id="02c80-204">Fare clic sul nome del contenitore di archiviazione associato al cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-204">Click the storage container name associated with the cluster.</span></span> <span data-ttu-id="02c80-205">Nel riquadro destro fare doppio clic sulla cartella **HVACOut**.</span><span class="sxs-lookup"><span data-stu-id="02c80-205">In the right pane, double-click the **HVACOut** folder.</span></span> <span data-ttu-id="02c80-206">Aprire uno dei file **part-** per visualizzare l'output dell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="02c80-206">Open one of the **part-** files to see the output of the application.</span></span>

### <a name="access-the-spark-history-server"></a><span data-ttu-id="02c80-207">Accedere al Server cronologia Spark</span><span class="sxs-lookup"><span data-stu-id="02c80-207">Access the Spark history server</span></span>
1. <span data-ttu-id="02c80-208">In Azure Explorer fare clic con il pulsante destro del mouse sul nome del cluster Spark e quindi scegliere **Open Spark History UI** (Apri UI cronologia Spark).</span><span class="sxs-lookup"><span data-stu-id="02c80-208">In Azure Explorer, right-click your Spark cluster name, and then select **Open Spark History UI**.</span></span> <span data-ttu-id="02c80-209">Quando richiesto, immettere le credenziali dell'amministratore per il cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-209">When you're prompted, enter the admin credentials for the cluster.</span></span> <span data-ttu-id="02c80-210">È necessario specificare le credenziali durante il provisioning del cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-210">You must have specified these while provisioning the cluster.</span></span>
2. <span data-ttu-id="02c80-211">Nel dashboard del Server cronologia Spark è possibile usare il nome dell'applicazione per cercare l'applicazione di cui è appena stata completata l'esecuzione.</span><span class="sxs-lookup"><span data-stu-id="02c80-211">In the Spark history server dashboard, you use the application name to look for the application that you just finished running.</span></span> <span data-ttu-id="02c80-212">Nel codice precedente impostare il nome dell'applicazione usando `val conf = new SparkConf().setAppName("MyClusterApp")`.</span><span class="sxs-lookup"><span data-stu-id="02c80-212">In the preceding code, you set the application name by using `val conf = new SparkConf().setAppName("MyClusterApp")`.</span></span> <span data-ttu-id="02c80-213">Il nome dell'applicazione Spark è **MyClusterApp**.</span><span class="sxs-lookup"><span data-stu-id="02c80-213">Hence, your Spark application name was **MyClusterApp**.</span></span>

### <a name="start-the-ambari-portal"></a><span data-ttu-id="02c80-214">Avviare il portale di Ambari</span><span class="sxs-lookup"><span data-stu-id="02c80-214">Start the Ambari portal</span></span>
1. <span data-ttu-id="02c80-215">In Azure Explorer fare clic con il pulsante destro del mouse sul nome del cluster Spark e quindi scegliere **Open Cluster Management Portal (Ambari)** (Apri portale di gestione cluster - Ambari).</span><span class="sxs-lookup"><span data-stu-id="02c80-215">In Azure Explorer, right-click your Spark cluster name, and then select **Open Cluster Management Portal (Ambari)**.</span></span> 
2. <span data-ttu-id="02c80-216">Quando richiesto, immettere le credenziali dell'amministratore per il cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-216">When you're prompted, enter the admin credentials for the cluster.</span></span> <span data-ttu-id="02c80-217">È necessario specificare le credenziali durante il provisioning del cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-217">You must have specified these while provisioning the cluster.</span></span>

### <a name="manage-azure-subscriptions"></a><span data-ttu-id="02c80-218">Gestire le sottoscrizioni di Azure</span><span class="sxs-lookup"><span data-stu-id="02c80-218">Manage Azure subscriptions</span></span>
<span data-ttu-id="02c80-219">Per impostazione predefinita, gli strumenti HDInsight in Azure Toolkit for Eclipse elencano i cluster Spark di tutte le sottoscrizioni di Azure.</span><span class="sxs-lookup"><span data-stu-id="02c80-219">By default, HDInsight Tools in Azure Toolkit for Eclipse lists the Spark clusters from all your Azure subscriptions.</span></span> <span data-ttu-id="02c80-220">Se necessario, è possibile specificare le sottoscrizioni per cui si vuole accedere al cluster.</span><span class="sxs-lookup"><span data-stu-id="02c80-220">If necessary, you can specify the subscriptions for which you want to access the cluster.</span></span> 

1. <span data-ttu-id="02c80-221">In Azure Explorer fare clic con il pulsante destro del mouse sul nodo radice **Azure** e quindi scegliere **Gestisci sottoscrizioni**.</span><span class="sxs-lookup"><span data-stu-id="02c80-221">In Azure Explorer, right-click the **Azure** root node, and then click **Manage Subscriptions**.</span></span> 
2. <span data-ttu-id="02c80-222">Nella finestra di dialogo deselezionare le caselle di controllo della sottoscrizione alla quale non si vuole accedere e quindi fare clic su **Chiudi**.</span><span class="sxs-lookup"><span data-stu-id="02c80-222">In the dialog box, clear the check boxes for the subscription that you don't want to access, and then click **Close**.</span></span> <span data-ttu-id="02c80-223">È anche possibile fare clic su **Esci** per uscire dalla sessione di sottoscrizione di Azure.</span><span class="sxs-lookup"><span data-stu-id="02c80-223">You can also click **Sign Out** if you want to sign out of your Azure subscription.</span></span>

## <a name="run-a-spark-scala-application-locally"></a><span data-ttu-id="02c80-224">Eseguire un'applicazione Spark in Scala localmente</span><span class="sxs-lookup"><span data-stu-id="02c80-224">Run a Spark Scala application locally</span></span>
<span data-ttu-id="02c80-225">È possibile usare gli strumenti HDInsight in Azure Toolkit for Eclipse per eseguire applicazioni Spark in Scala localmente nella workstation.</span><span class="sxs-lookup"><span data-stu-id="02c80-225">You can use HDInsight Tools in Azure Toolkit for Eclipse to run Spark Scala applications locally on your workstation.</span></span> <span data-ttu-id="02c80-226">Tali applicazioni in genere non richiedono l'accesso a risorse del cluster quali il contenitore di archiviazione e possono essere eseguite e testate localmente.</span><span class="sxs-lookup"><span data-stu-id="02c80-226">Typically, these applications don't need access to cluster resources such as a storage container, and you can run and test them locally.</span></span>

### <a name="prerequisite"></a><span data-ttu-id="02c80-227">Prerequisito</span><span class="sxs-lookup"><span data-stu-id="02c80-227">Prerequisite</span></span>
<span data-ttu-id="02c80-228">Quando si esegue l'applicazione Spark Scala locale in un computer Windows, potrebbe essere restituita un'eccezione, come spiegato in [SPARK-2356](https://issues.apache.org/jira/browse/SPARK-2356),</span><span class="sxs-lookup"><span data-stu-id="02c80-228">While you're running the local Spark Scala application on a Windows computer, you might get an exception as explained in [SPARK-2356](https://issues.apache.org/jira/browse/SPARK-2356).</span></span> <span data-ttu-id="02c80-229">che si verifica a causa di un file **WinUtils.exe** mancante in Windows.</span><span class="sxs-lookup"><span data-stu-id="02c80-229">This exception occurs because **WinUtils.exe** is missing in Windows.</span></span> 

<span data-ttu-id="02c80-230">Per risolvere questo errore è necessario [scaricare il file eseguibile](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe) in un percorso come **C:\WinUtils\bin**.</span><span class="sxs-lookup"><span data-stu-id="02c80-230">To resolve this error, you must [download the executable](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe) to a location like **C:\WinUtils\bin**.</span></span> <span data-ttu-id="02c80-231">È quindi necessario aggiungere una variabile di ambiente **HADOOP_HOME** e impostare il valore della variabile su **C\WinUtils**.</span><span class="sxs-lookup"><span data-stu-id="02c80-231">You must then add the environment variable **HADOOP_HOME** and set the value of the variable to **C\WinUtils**.</span></span>

### <a name="run-a-local-spark-scala-application"></a><span data-ttu-id="02c80-232">Eseguire un'applicazione Spark in Scala locale</span><span class="sxs-lookup"><span data-stu-id="02c80-232">Run a local Spark Scala application</span></span>
1. <span data-ttu-id="02c80-233">Avviare Eclipse e creare un progetto.</span><span class="sxs-lookup"><span data-stu-id="02c80-233">Start Eclipse and create a project.</span></span> <span data-ttu-id="02c80-234">Nella finestra di dialogo **New Project** (Nuovo progetto) selezionare le opzioni seguenti e quindi fare clic su **Next** (Avanti).</span><span class="sxs-lookup"><span data-stu-id="02c80-234">In the **New Project** dialog box, make the following choices, and then click **Next**.</span></span>
   
   * <span data-ttu-id="02c80-235">Selezionare **HDInsight** nel riquadro sinistro.</span><span class="sxs-lookup"><span data-stu-id="02c80-235">In the left pane, select **HDInsight**.</span></span>
   * <span data-ttu-id="02c80-236">Selezionare **Spark on HDInsight Local Run Sample (Scala)** (Esecuzione locale di esempio Spark in HDInsight - Scala) nel riquadro destro.</span><span class="sxs-lookup"><span data-stu-id="02c80-236">In the right pane, select **Spark on HDInsight Local Run Sample (Scala)**.</span></span>

    ![Finestra di dialogo Nuovo progetto](./media/hdinsight-apache-spark-eclipse-tool-plugin/hdi-spark-app-local-run.png)
2. <span data-ttu-id="02c80-238">Per specificare i dettagli del progetto, seguire i passaggi da 3 a 6 illustrati nella sezione precedente [Configurare un progetto Spark in Scala per un cluster HDInsight Spark](#set-up-a-spark-scala-project-for-an-hdinsight-spark cluster).</span><span class="sxs-lookup"><span data-stu-id="02c80-238">To provide the project details, follow steps 3 through 6 from the earlier section [Set up a Spark Scala project for an HDInsight Spark cluster](#set-up-a-spark-scala-project-for-an-hdinsight-spark cluster).</span></span>
3. <span data-ttu-id="02c80-239">Il modello aggiunge un codice di esempio (**LogQuery**) sotto la cartella **src** eseguibile in locale nel computer in uso.</span><span class="sxs-lookup"><span data-stu-id="02c80-239">The template adds a sample code (**LogQuery**) under the **src** folder that you can run locally on your computer.</span></span>
   
    ![Percorso di LogQuery](./media/hdinsight-apache-spark-eclipse-tool-plugin/local-app.png)
4. <span data-ttu-id="02c80-241">Fare clic con il pulsante destro del mouse sull'applicazione **LogQuery**, scegliere **Run As** (Esegui come) e quindi fare clic su **1 Scala Application** (1 applicazione Scala).</span><span class="sxs-lookup"><span data-stu-id="02c80-241">Right-click the **LogQuery** application, point to **Run As**, and then click **1 Scala Application**.</span></span> <span data-ttu-id="02c80-242">Verrà visualizzato un output simile al seguente nella scheda **Console** in basso:</span><span class="sxs-lookup"><span data-stu-id="02c80-242">You will see an output like this in the **Console** tab at the bottom:</span></span>
   
   ![Risultato dell'esecuzione locale dell'applicazione Spark](./media/hdinsight-apache-spark-eclipse-tool-plugin/hdi-spark-app-local-run-result.png)

## <a name="faq"></a><span data-ttu-id="02c80-244">domande frequenti</span><span class="sxs-lookup"><span data-stu-id="02c80-244">FAQ</span></span>
<span data-ttu-id="02c80-245">Per inviare un'applicazione ad Azure Data Lake Store, selezionare la modalità **Interactive** (Interattivo) durante l'accesso ad Azure.</span><span class="sxs-lookup"><span data-stu-id="02c80-245">To submit an application to Azure Data Lake Store, choose **Interactive** mode during the Azure sign-in process.</span></span> <span data-ttu-id="02c80-246">Se si seleziona la modalità **Automated** (Automatico), viene visualizzato un errore.</span><span class="sxs-lookup"><span data-stu-id="02c80-246">If you select **Automated** mode, you can get an error.</span></span>

![interative-signin](./media/hdinsight-apache-spark-eclipse-tool-plugin/interactive-authentication.png)

<span data-ttu-id="02c80-248">A questo punto, il problema è risolto.</span><span class="sxs-lookup"><span data-stu-id="02c80-248">Now, we resolved it.</span></span> <span data-ttu-id="02c80-249">È possibile scegliere un cluster di Azure Data Lake per inviare l'applicazione con qualsiasi metodo di accesso.</span><span class="sxs-lookup"><span data-stu-id="02c80-249">You can choose an Azure Data Lake Cluster to submit your application with any sign-in method.</span></span>

## <a name="feedback-and-known-issues"></a><span data-ttu-id="02c80-250">Commenti, suggerimenti e problemi noti</span><span class="sxs-lookup"><span data-stu-id="02c80-250">Feedback and known issues</span></span>
<span data-ttu-id="02c80-251">Il supporto della visualizzazione diretta degli output di Spark non è al momento disponibile.</span><span class="sxs-lookup"><span data-stu-id="02c80-251">Currently, viewing Spark outputs directly is not supported.</span></span>

<span data-ttu-id="02c80-252">Per eventuali commenti o suggerimenti oppure se si riscontrano problemi nell'uso di questo strumento, inviare un messaggio di posta elettronica all'indirizzo hdivstool@microsoft.com.</span><span class="sxs-lookup"><span data-stu-id="02c80-252">If you have any suggestions or feedback, or if you encounter any problems when using this tool, feel free to send us an email at hdivstool@microsoft.com.</span></span>

## <span data-ttu-id="02c80-253"><a name="seealso"></a>Vedere anche</span><span class="sxs-lookup"><span data-stu-id="02c80-253"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="02c80-254">Panoramica: Apache Spark su Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-254">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="02c80-255">Scenari</span><span class="sxs-lookup"><span data-stu-id="02c80-255">Scenarios</span></span>
* [<span data-ttu-id="02c80-256">Spark con Business Intelligence: eseguire l'analisi interattiva dei dati con strumenti di Business Intelligence mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-256">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="02c80-257">Spark con Machine Learning: utilizzare Spark in HDInsight per l'analisi della temperatura di compilazione utilizzando dati HVAC</span><span class="sxs-lookup"><span data-stu-id="02c80-257">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="02c80-258">Spark con Machine Learning: usare Spark in HDInsight per prevedere i risultati del controllo degli alimenti</span><span class="sxs-lookup"><span data-stu-id="02c80-258">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="02c80-259">Streaming Spark: usare Spark in HDInsight per la creazione di applicazioni di streaming in tempo reale</span><span class="sxs-lookup"><span data-stu-id="02c80-259">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="02c80-260">Analisi dei log del sito Web mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-260">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="creating-and-running-applications"></a><span data-ttu-id="02c80-261">Creazione ed esecuzione di applicazioni</span><span class="sxs-lookup"><span data-stu-id="02c80-261">Creating and running applications</span></span>
* [<span data-ttu-id="02c80-262">Creare un'applicazione autonoma con Scala</span><span class="sxs-lookup"><span data-stu-id="02c80-262">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="02c80-263">Eseguire processi in modalità remota in un cluster Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="02c80-263">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="02c80-264">Strumenti ed estensioni</span><span class="sxs-lookup"><span data-stu-id="02c80-264">Tools and extensions</span></span>
* [<span data-ttu-id="02c80-265">Usare Azure Toolkit for IntelliJ per creare e inviare applicazioni Spark in Scala</span><span class="sxs-lookup"><span data-stu-id="02c80-265">Use Azure Toolkit for IntelliJ to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="02c80-266">Usare Azure Toolkit per IntelliJ per il debug remoto di applicazioni Spark tramite VPN</span><span class="sxs-lookup"><span data-stu-id="02c80-266">Use Azure Toolkit for IntelliJ to debug Spark applications remotely through VPN</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="02c80-267">Usare Azure Toolkit per IntelliJ per il debug remoto di applicazioni Spark tramite SSH</span><span class="sxs-lookup"><span data-stu-id="02c80-267">Use Azure Toolkit for IntelliJ to debug Spark applications remotely through SSH</span></span>](hdinsight-apache-spark-intellij-tool-debug-remotely-through-ssh.md)
* [<span data-ttu-id="02c80-268">Usare gli strumenti HDInsight per IntelliJ con Hortonworks Sandbox</span><span class="sxs-lookup"><span data-stu-id="02c80-268">Use HDInsight Tools for IntelliJ with Hortonworks Sandbox</span></span>](hdinsight-tools-for-intellij-with-hortonworks-sandbox.md)
* [<span data-ttu-id="02c80-269">Usare i notebook di Zeppelin con un cluster Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-269">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="02c80-270">Kernel disponibili per notebook di Jupyter nel cluster Spark per HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-270">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="02c80-271">Usare pacchetti esterni con i notebook Jupyter</span><span class="sxs-lookup"><span data-stu-id="02c80-271">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="02c80-272">Installare Jupyter Notebook nel computer e connetterlo a un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="02c80-272">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="managing-resources"></a><span data-ttu-id="02c80-273">Gestione delle risorse</span><span class="sxs-lookup"><span data-stu-id="02c80-273">Managing resources</span></span>
* [<span data-ttu-id="02c80-274">Gestire le risorse del cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-274">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="02c80-275">Tenere traccia ed eseguire il debug di processi in esecuzione nel cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="02c80-275">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

