---
title: 'Esercitazione: Creare una pipeline di Azure Data Factory per copiare dati (portale di Azure) | Microsoft Docs'
description: "In questa esercitazione si usa il portale di Azure per creare una pipeline di Azure Data Factory con un'attività di copia per copiare i dati da un archivio BLOB di Azure a un database SQL di Azure."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: d9317652-0170-4fd3-b9b2-37711272162b
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 8072a863fab0b304ccbbba639aa56b403e8f37c7
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/03/2017
---
# <a name="tutorial-use-azure-portal-to-create-a-data-factory-pipeline-to-copy-data"></a><span data-ttu-id="35fbc-103">Esercitazione: Usare il portale di Azure per creare una pipeline di Data Factory pipeline per copiare dati</span><span class="sxs-lookup"><span data-stu-id="35fbc-103">Tutorial: Use Azure portal to create a Data Factory pipeline to copy data</span></span> 
> [!div class="op_single_selector"]
> * [<span data-ttu-id="35fbc-104">Panoramica e prerequisiti</span><span class="sxs-lookup"><span data-stu-id="35fbc-104">Overview and prerequisites</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)
> * [<span data-ttu-id="35fbc-105">Copia guidata</span><span class="sxs-lookup"><span data-stu-id="35fbc-105">Copy Wizard</span></span>](data-factory-copy-data-wizard-tutorial.md)
> * [<span data-ttu-id="35fbc-106">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="35fbc-106">Azure portal</span></span>](data-factory-copy-activity-tutorial-using-azure-portal.md)
> * [<span data-ttu-id="35fbc-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="35fbc-107">Visual Studio</span></span>](data-factory-copy-activity-tutorial-using-visual-studio.md)
> * [<span data-ttu-id="35fbc-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="35fbc-108">PowerShell</span></span>](data-factory-copy-activity-tutorial-using-powershell.md)
> * [<span data-ttu-id="35fbc-109">Modello di Azure Resource Manager</span><span class="sxs-lookup"><span data-stu-id="35fbc-109">Azure Resource Manager template</span></span>](data-factory-copy-activity-tutorial-using-azure-resource-manager-template.md)
> * [<span data-ttu-id="35fbc-110">API REST</span><span class="sxs-lookup"><span data-stu-id="35fbc-110">REST API</span></span>](data-factory-copy-activity-tutorial-using-rest-api.md)
> * [<span data-ttu-id="35fbc-111">API .NET</span><span class="sxs-lookup"><span data-stu-id="35fbc-111">.NET API</span></span>](data-factory-copy-activity-tutorial-using-dotnet-api.md)
> 
> 

<span data-ttu-id="35fbc-112">In questo articolo viene illustrato come usare il [portale di Azure](https://portal.azure.com) per creare una data factory con una pipeline che copia dati da un archivio BLOB di Azure a un database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-112">In this article, you learn how to use [Azure portal](https://portal.azure.com) to create a data factory with a pipeline that copies data from an Azure blob storage to an Azure SQL database.</span></span> <span data-ttu-id="35fbc-113">Se non si ha familiarità con Azure Data Factory, prima di eseguire questa esercitazione vedere l'articolo [Introduzione ad Azure Data Factory](data-factory-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-113">If you are new to Azure Data Factory, read through the [Introduction to Azure Data Factory](data-factory-introduction.md) article before doing this tutorial.</span></span>   

<span data-ttu-id="35fbc-114">In questa esercitazione si crea una pipeline contenente una sola attività: un'attività di copia</span><span class="sxs-lookup"><span data-stu-id="35fbc-114">In this tutorial, you create a pipeline with one activity in it: Copy Activity.</span></span> <span data-ttu-id="35fbc-115">che copia i dati da un archivio dati supportato a un archivio dati sink supportato.</span><span class="sxs-lookup"><span data-stu-id="35fbc-115">The copy activity copies data from a supported data store to a supported sink data store.</span></span> <span data-ttu-id="35fbc-116">Per un elenco degli archivi dati supportati come origini e sink, vedere gli [archivi dati supportati](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="35fbc-116">For a list of data stores supported as sources and sinks, see [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span></span> <span data-ttu-id="35fbc-117">e si basa su un servizio disponibile a livello globale che può copiare dati tra diversi archivi dati in modo sicuro, affidabile e scalabile.</span><span class="sxs-lookup"><span data-stu-id="35fbc-117">The activity is powered by a globally available service that can copy data between various data stores in a secure, reliable, and scalable way.</span></span> <span data-ttu-id="35fbc-118">Per altre informazioni sull'attività di copia, vedere le [attività di spostamento dei dati](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-118">For more information about the Copy Activity, see [Data Movement Activities](data-factory-data-movement-activities.md).</span></span>

<span data-ttu-id="35fbc-119">Una pipeline può includere più attività</span><span class="sxs-lookup"><span data-stu-id="35fbc-119">A pipeline can have more than one activity.</span></span> <span data-ttu-id="35fbc-120">ed è possibile concatenarne due, ovvero eseguire un'attività dopo l'altra, impostando il set di dati di output di un'attività come set di dati di input dell'altra.</span><span class="sxs-lookup"><span data-stu-id="35fbc-120">And, you can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="35fbc-121">Per altre informazioni, vedere [Attività multiple in una pipeline](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span><span class="sxs-lookup"><span data-stu-id="35fbc-121">For more information, see [multiple activities in a pipeline](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span></span> 

> [!NOTE] 
> <span data-ttu-id="35fbc-122">La pipeline di dati in questa esercitazione copia i dati da un archivio dati di origine a un archivio dati di destinazione.</span><span class="sxs-lookup"><span data-stu-id="35fbc-122">The data pipeline in this tutorial copies data from a source data store to a destination data store.</span></span> <span data-ttu-id="35fbc-123">Per un'esercitazione su come trasformare i dati usando Azure Data Factory, vedere [Esercitazione: Creare una pipeline per trasformare i dati usando un cluster Hadoop](data-factory-build-your-first-pipeline.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-123">For a tutorial on how to transform data using Azure Data Factory, see [Tutorial: Build a pipeline to transform data using Hadoop cluster](data-factory-build-your-first-pipeline.md).</span></span>

## <a name="prerequisites"></a><span data-ttu-id="35fbc-124">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="35fbc-124">Prerequisites</span></span>
<span data-ttu-id="35fbc-125">Prima di eseguire questa esercitazione, completare i prerequisiti indicati nell'articolo sui [prerequisiti dell'esercitazione](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) .</span><span class="sxs-lookup"><span data-stu-id="35fbc-125">Complete prerequisites listed in the [tutorial prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) article before performing this tutorial.</span></span>

## <a name="steps"></a><span data-ttu-id="35fbc-126">Passi</span><span class="sxs-lookup"><span data-stu-id="35fbc-126">Steps</span></span>
<span data-ttu-id="35fbc-127">Di seguito sono elencati i passaggi da eseguire in questa esercitazione:</span><span class="sxs-lookup"><span data-stu-id="35fbc-127">Here are the steps you perform as part of this tutorial:</span></span>

1. <span data-ttu-id="35fbc-128">Creare una **data factory** di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-128">Create an Azure **data factory**.</span></span> <span data-ttu-id="35fbc-129">In questo passaggio viene creata una data factory denominata ADFTutorialDataFactory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-129">In this step, you create a data factory named ADFTutorialDataFactory.</span></span> 
2. <span data-ttu-id="35fbc-130">Creare **servizi collegati** nella data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-130">Create **linked services** in the data factory.</span></span> <span data-ttu-id="35fbc-131">In questo passaggio si creano due servizi collegati di tipo Archiviazione di Azure e database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-131">In this step, you create two linked services of types: Azure Storage and Azure SQL Database.</span></span> 
    
    <span data-ttu-id="35fbc-132">AzureStorageLinkedService collega l'account di archiviazione di Azure alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-132">The AzureStorageLinkedService links your Azure storage account to the data factory.</span></span> <span data-ttu-id="35fbc-133">Come parte dei [prerequisiti](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) è stato creato un contenitore e sono stati caricati i dati in questo account di archiviazione.</span><span class="sxs-lookup"><span data-stu-id="35fbc-133">You created a container and uploaded data to this storage account as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   

    <span data-ttu-id="35fbc-134">AzureSqlLinkedService collega il database SQL di Azure alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-134">AzureSqlLinkedService links your Azure SQL database to the data factory.</span></span> <span data-ttu-id="35fbc-135">I dati copiati dall'archivio BLOB vengono archiviati in questo database.</span><span class="sxs-lookup"><span data-stu-id="35fbc-135">The data that is copied from the blob storage is stored in this database.</span></span> <span data-ttu-id="35fbc-136">Come parte dei [prerequisiti](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) è stata creata una tabella SQL in questo database.</span><span class="sxs-lookup"><span data-stu-id="35fbc-136">You created a SQL table in this database as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   
3. <span data-ttu-id="35fbc-137">Creare **set di dati** di input e di output nella data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-137">Create input and output **datasets** in the data factory.</span></span>  
    
    <span data-ttu-id="35fbc-138">Il servizio collegato Archiviazione di Azure specifica la stringa di connessione usata dal servizio Data Factory in fase di esecuzione per connettersi all'account di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-138">The Azure storage linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure storage account.</span></span> <span data-ttu-id="35fbc-139">Il set di dati del BLOB di input specifica il contenitore e la cartella che contiene i dati di input.</span><span class="sxs-lookup"><span data-stu-id="35fbc-139">And, the input blob dataset specifies the container and the folder that contains the input data.</span></span>  

    <span data-ttu-id="35fbc-140">Analogamente, il servizio collegato per il database SQL di Azure specifica la stringa di connessione usata dal servizio Data Factory in fase di esecuzione per connettersi al database SQL di Azure</span><span class="sxs-lookup"><span data-stu-id="35fbc-140">Similarly, the Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="35fbc-141">e il set di dati della tabella SQL di output specifica la tabella del database in cui vengono copiati i dati dell'archivio BLOB.</span><span class="sxs-lookup"><span data-stu-id="35fbc-141">And, the output SQL table dataset specifies the table in the database to which the data from the blob storage is copied.</span></span>
4. <span data-ttu-id="35fbc-142">Creare una **pipeline** nella data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-142">Create a **pipeline** in the data factory.</span></span> <span data-ttu-id="35fbc-143">In questo passaggio viene creata una pipeline con un'attività di copia.</span><span class="sxs-lookup"><span data-stu-id="35fbc-143">In this step, you create a pipeline with a copy activity.</span></span>   
    
    <span data-ttu-id="35fbc-144">L'attività di copia esegue la copia dei dati da un BLOB nell'archivio BLOB di Azure a una tabella nel database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-144">The copy activity copies data from a blob in the Azure blob storage to a table in the Azure SQL database.</span></span> <span data-ttu-id="35fbc-145">È possibile usare un'attività di copia in una pipeline per copiare i dati da qualsiasi origine supportata a qualsiasi destinazione supportata.</span><span class="sxs-lookup"><span data-stu-id="35fbc-145">You can use a copy activity in a pipeline to copy data from any supported source to any supported destination.</span></span> <span data-ttu-id="35fbc-146">Per un elenco degli archivi dati supportati, vedere l'articolo sulle [attività di spostamento dei dati](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="35fbc-146">For a list of supported data stores, see [data movement activities](data-factory-data-movement-activities.md#supported-data-stores-and-formats) article.</span></span> 
5. <span data-ttu-id="35fbc-147">Monitorare la pipeline.</span><span class="sxs-lookup"><span data-stu-id="35fbc-147">Monitor the pipeline.</span></span> <span data-ttu-id="35fbc-148">In questo passaggio vengono **monitorate** le sezioni dei set di dati di input e di output usando il portale di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-148">In this step, you **monitor** the slices of input and output datasets by using Azure portal.</span></span> 

## <a name="create-data-factory"></a><span data-ttu-id="35fbc-149">Creare un'istanza di Data Factory</span><span class="sxs-lookup"><span data-stu-id="35fbc-149">Create data factory</span></span>
> [!IMPORTANT]
> <span data-ttu-id="35fbc-150">Completare i [prerequisiti per l'esercitazione](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) se non è già stato fatto.</span><span class="sxs-lookup"><span data-stu-id="35fbc-150">Complete [prerequisites for the tutorial](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) if you haven't already done so.</span></span>   

<span data-ttu-id="35fbc-151">Una data factory può comprendere una o più pipeline.</span><span class="sxs-lookup"><span data-stu-id="35fbc-151">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="35fbc-152">Una pipeline può comprendere una o più attività.</span><span class="sxs-lookup"><span data-stu-id="35fbc-152">A pipeline can have one or more activities in it.</span></span> <span data-ttu-id="35fbc-153">Ad esempio, un'attività di copia per copiare dati da un archivio dati di origine a uno di destinazione e un'attività Hive HDInsight per eseguire uno script Hive e trasformare i dati di input in dati di output di prodotto.</span><span class="sxs-lookup"><span data-stu-id="35fbc-153">For example, a Copy Activity to copy data from a source to a destination data store and a HDInsight Hive activity to run a Hive script to transform input data to product output data.</span></span> <span data-ttu-id="35fbc-154">In questo passaggio iniziale viene creata la data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-154">Let's start with creating the data factory in this step.</span></span>

1. <span data-ttu-id="35fbc-155">Dopo aver eseguito l'accesso al [portale di Azure](https://portal.azure.com/), scegliere **Nuovo** dal menu a sinistra, fare clic su **Dati e analisi** e fare clic su **Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-155">After logging in to the [Azure portal](https://portal.azure.com/), click **New** on the left menu, click **Data + Analytics**, and click **Data Factory**.</span></span> 
   
   ![Nuovo->DataFactory](./media/data-factory-copy-activity-tutorial-using-azure-portal/NewDataFactoryMenu.png)    
2. <span data-ttu-id="35fbc-157">Nel pannello **Nuova data factory** :</span><span class="sxs-lookup"><span data-stu-id="35fbc-157">In the **New data factory** blade:</span></span>
   
   1. <span data-ttu-id="35fbc-158">Immettere **ADFTutorialDataFactory** come **nome**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-158">Enter **ADFTutorialDataFactory** for the **name**.</span></span> 
      
         ![Pannello Nuova data factory](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-new-data-factory.png)
      
       <span data-ttu-id="35fbc-160">Il nome della data factory di Azure deve essere **univoco a livello globale**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-160">The name of the Azure data factory must be **globally unique**.</span></span> <span data-ttu-id="35fbc-161">Se viene visualizzato l'errore seguente, modificare il nome della data factory, ad esempio, nomeutenteADFTutorialDataFactory, e provare di nuovo a crearla.</span><span class="sxs-lookup"><span data-stu-id="35fbc-161">If you receive the following error, change the name of the data factory (for example, yournameADFTutorialDataFactory) and try creating again.</span></span> <span data-ttu-id="35fbc-162">Per informazioni sulle regole di denominazione per gli elementi di Data Factory, vedere l'argomento [Azure Data Factory - Regole di denominazione](data-factory-naming-rules.md) .</span><span class="sxs-lookup"><span data-stu-id="35fbc-162">See [Data Factory - Naming Rules](data-factory-naming-rules.md) topic for naming rules for Data Factory artifacts.</span></span>
      
           Data factory name “ADFTutorialDataFactory” is not available  
      
       ![Nome di data factory non disponibile](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-not-available.png)
   2. <span data-ttu-id="35fbc-164">Selezionare la **sottoscrizione** di Azure in cui creare la data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-164">Select your Azure **subscription** in which you want to create the data factory.</span></span> 
   3. <span data-ttu-id="35fbc-165">Per il **gruppo di risorse**, eseguire una di queste operazioni:</span><span class="sxs-lookup"><span data-stu-id="35fbc-165">For the **Resource Group**, do one of the following steps:</span></span>
      
      - <span data-ttu-id="35fbc-166">Selezionare **Usa esistente**e scegliere un gruppo di risorse esistente dall'elenco a discesa.</span><span class="sxs-lookup"><span data-stu-id="35fbc-166">Select **Use existing**, and select an existing resource group from the drop-down list.</span></span> 
      - <span data-ttu-id="35fbc-167">Selezionare **Crea nuovo**e immettere un nome per il gruppo di risorse.</span><span class="sxs-lookup"><span data-stu-id="35fbc-167">Select **Create new**, and enter the name of a resource group.</span></span>   
         
          <span data-ttu-id="35fbc-168">Alcuni dei passaggi di questa esercitazione presuppongono l'uso del nome **ADFTutorialResourceGroup** per il gruppo di risorse.</span><span class="sxs-lookup"><span data-stu-id="35fbc-168">Some of the steps in this tutorial assume that you use the name: **ADFTutorialResourceGroup** for the resource group.</span></span> <span data-ttu-id="35fbc-169">Per informazioni sui gruppi di risorse, vedere l'articolo relativo all' [uso di gruppi di risorse per la gestione delle risorse di Azure](../azure-resource-manager/resource-group-overview.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-169">To learn about resource groups, see [Using resource groups to manage your Azure resources](../azure-resource-manager/resource-group-overview.md).</span></span>  
   4. <span data-ttu-id="35fbc-170">Selezionare la **località** per la data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-170">Select the **location** for the data factory.</span></span> <span data-ttu-id="35fbc-171">Nell'elenco a discesa vengono visualizzate solo le aree supportate dal servizio Data Factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-171">Only regions supported by the Data Factory service are shown in the drop-down list.</span></span>
   5. <span data-ttu-id="35fbc-172">Selezionare **Aggiungi al dashboard**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-172">Select **Pin to dashboard**.</span></span>     
   6. <span data-ttu-id="35fbc-173">Fare clic su **Crea**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-173">Click **Create**.</span></span>
      
      > [!IMPORTANT]
      > <span data-ttu-id="35fbc-174">Per creare istanze di data factory, è necessario essere membri del ruolo [Collaboratore Data factory](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) a livello di sottoscrizione/gruppo di risorse.</span><span class="sxs-lookup"><span data-stu-id="35fbc-174">To create Data Factory instances, you must be a member of the [Data Factory Contributor](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) role at the subscription/resource group level.</span></span>
      > 
      > <span data-ttu-id="35fbc-175">Il nome di Data Factory può essere registrato come un nome DNS in futuro e pertanto divenire visibile pubblicamente.</span><span class="sxs-lookup"><span data-stu-id="35fbc-175">The name of the data factory may be registered as a DNS name in the future and hence become publically visible.</span></span>                
      > 
      > 
3. <span data-ttu-id="35fbc-176">Nel dashboard viene visualizzato il riquadro seguente con lo stato: **Deploying data factory** (Distribuzione della data factory).</span><span class="sxs-lookup"><span data-stu-id="35fbc-176">On the dashboard, you see the following tile with status: **Deploying data factory**.</span></span> 

    ![Riquadro Deploying data factory (Distribuzione della data factory)](media/data-factory-copy-activity-tutorial-using-azure-portal/deploying-data-factory.png)
4. <span data-ttu-id="35fbc-178">Al termine della creazione verrà visualizzato il pannello **Data Factory** , come illustrato nell'immagine.</span><span class="sxs-lookup"><span data-stu-id="35fbc-178">After the creation is complete, you see the **Data Factory** blade as shown in the image.</span></span>
   
   ![Home page di Data factory](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-home-page.png)

## <a name="create-linked-services"></a><span data-ttu-id="35fbc-180">Creazione di servizi collegati</span><span class="sxs-lookup"><span data-stu-id="35fbc-180">Create linked services</span></span>
<span data-ttu-id="35fbc-181">Si creano servizi collegati in una data factory per collegare gli archivi dati e i servizi di calcolo alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-181">You create linked services in a data factory to link your data stores and compute services to the data factory.</span></span> <span data-ttu-id="35fbc-182">In questa esercitazione non si usano servizi di calcolo come Azure HDInsight o Azure Data Lake Analytics,</span><span class="sxs-lookup"><span data-stu-id="35fbc-182">In this tutorial, you don't use any compute service such as Azure HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="35fbc-183">ma due archivi dati di tipo Archiviazione di Azure (origine) e database SQL di Azure (destinazione).</span><span class="sxs-lookup"><span data-stu-id="35fbc-183">You use two data stores of type Azure Storage (source) and Azure SQL Database (destination).</span></span> 

<span data-ttu-id="35fbc-184">Si creano quindi due servizi collegati denominati AzureStorageLinkedService e AzureSqlLinkedService di tipo AzureStorage e AzureSqlDatabase.</span><span class="sxs-lookup"><span data-stu-id="35fbc-184">Therefore, you create two linked services named AzureStorageLinkedService and AzureSqlLinkedService of types: AzureStorage and AzureSqlDatabase.</span></span>  

<span data-ttu-id="35fbc-185">AzureStorageLinkedService collega l'account di archiviazione di Azure alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-185">The AzureStorageLinkedService links your Azure storage account to the data factory.</span></span> <span data-ttu-id="35fbc-186">L'account di archiviazione è quello in cui, come parte dei [prerequisiti](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md), è stato creato un contenitore e sono stati caricati i dati.</span><span class="sxs-lookup"><span data-stu-id="35fbc-186">This storage account is the one in which you created a container and uploaded the data as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   

<span data-ttu-id="35fbc-187">AzureSqlLinkedService collega il database SQL di Azure alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-187">AzureSqlLinkedService links your Azure SQL database to the data factory.</span></span> <span data-ttu-id="35fbc-188">I dati copiati dall'archivio BLOB vengono archiviati in questo database.</span><span class="sxs-lookup"><span data-stu-id="35fbc-188">The data that is copied from the blob storage is stored in this database.</span></span> <span data-ttu-id="35fbc-189">Come parte dei [prerequisiti](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) è stata creata la tabella emp in questo database.</span><span class="sxs-lookup"><span data-stu-id="35fbc-189">You created the emp table in this database as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>  

### <a name="create-azure-storage-linked-service"></a><span data-ttu-id="35fbc-190">Creare il servizio collegato Archiviazione di Azure</span><span class="sxs-lookup"><span data-stu-id="35fbc-190">Create Azure Storage linked service</span></span>
<span data-ttu-id="35fbc-191">In questo passaggio l'account di archiviazione di Azure viene collegato alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-191">In this step, you link your Azure storage account to your data factory.</span></span> <span data-ttu-id="35fbc-192">In questa sezione si specificano il nome e la chiave dell'account di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-192">You specify the name and key of your Azure storage account in this section.</span></span>  

1. <span data-ttu-id="35fbc-193">Nel pannello **Data Factory** fare clic sul riquadro **Creare e distribuire**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-193">In the **Data Factory** blade, click **Author and deploy** tile.</span></span>
   
   ![Riquadro Creare e distribuire](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-author-deploy-tile.png) 
2. <span data-ttu-id="35fbc-195">L'**editor di Data factory** viene visualizzato come nella figura seguente:</span><span class="sxs-lookup"><span data-stu-id="35fbc-195">You see the **Data Factory Editor** as shown in the following image:</span></span> 

    ![Editor di Data factory](./media/data-factory-copy-activity-tutorial-using-azure-portal/data-factory-editor.png)
3. <span data-ttu-id="35fbc-197">Nell'editor fare clic sul pulsante **Nuovo archivio dati** sulla barra degli strumenti, quindi scegliere **Archiviazione di Azure** dal menu a discesa.</span><span class="sxs-lookup"><span data-stu-id="35fbc-197">In the editor, click **New data store** button on the toolbar and select **Azure storage** from the drop-down menu.</span></span> <span data-ttu-id="35fbc-198">Nel riquadro a destra verrà visualizzato il modello JSON per la creazione di un servizio collegato di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-198">You should see the JSON template for creating an Azure storage linked service in the right pane.</span></span> 
   
    ![Pulsante Nuovo archivio dati dell'editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-newdatastore-button.png)    
3. <span data-ttu-id="35fbc-200">Sostituire `<accountname>` e `<accountkey>` con i valori del nome e della chiave dell'account di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-200">Replace `<accountname>` and `<accountkey>` with the account name and account key values for your Azure storage account.</span></span> 
   
    ![JSON dell'archivio BLOB dell'editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-json.png)    
4. <span data-ttu-id="35fbc-202">Fare clic su **Distribuisci** sulla barra degli strumenti.</span><span class="sxs-lookup"><span data-stu-id="35fbc-202">Click **Deploy** on the toolbar.</span></span> <span data-ttu-id="35fbc-203">Nella visualizzazione albero dovrebbe essere visibile il servizio **AzureStorageLinkedService** distribuito.</span><span class="sxs-lookup"><span data-stu-id="35fbc-203">You should see the deployed **AzureStorageLinkedService** in the tree view now.</span></span> 
   
    ![Distribuzione dell'archivio BLOB dell'editor](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-deploy.png)

    <span data-ttu-id="35fbc-205">Per altre informazioni sulle proprietà JSON nella definizione dei servizi collegati, vedere l'articolo relativo al [connettore di Archiviazione BLOB di Azure](data-factory-azure-blob-connector.md#linked-service-properties).</span><span class="sxs-lookup"><span data-stu-id="35fbc-205">For more information about JSON properties in the linked service definition, see [Azure Blob Storage connector](data-factory-azure-blob-connector.md#linked-service-properties) article.</span></span>

### <a name="create-a-linked-service-for-the-azure-sql-database"></a><span data-ttu-id="35fbc-206">Creare un servizio collegato per il database SQL di Azure</span><span class="sxs-lookup"><span data-stu-id="35fbc-206">Create a linked service for the Azure SQL Database</span></span>
<span data-ttu-id="35fbc-207">In questo passaggio il database SQL di Azure viene collegato alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-207">In this step, you link your Azure SQL database to your data factory.</span></span> <span data-ttu-id="35fbc-208">In questa sezione si specificano il nome del server di Azure SQL, il nome del database, il nome utente e la password utente.</span><span class="sxs-lookup"><span data-stu-id="35fbc-208">You specify the Azure SQL server name, database name, user name, and user password in this section.</span></span> 

1. <span data-ttu-id="35fbc-209">Nell'**editor di Data Factory** fare clic sul pulsante **Nuovo archivio dati** sulla barra degli strumenti e scegliere **Database SQL di Azure** dal menu a discesa.</span><span class="sxs-lookup"><span data-stu-id="35fbc-209">In the **Data Factory Editor**, click **New data store** button on the toolbar and select **Azure SQL Database** from the drop-down menu.</span></span> <span data-ttu-id="35fbc-210">Nel riquadro a destra verrà visualizzato il modello JSON per la creazione di un servizio collegato SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-210">You should see the JSON template for creating the Azure SQL linked service in the right pane.</span></span>
2. <span data-ttu-id="35fbc-211">Sostituire `<servername>`, `<databasename>`, `<username>@<servername>` e `<password>` con i nomi del server di Azure SQL e del database, l'account utente e la password.</span><span class="sxs-lookup"><span data-stu-id="35fbc-211">Replace `<servername>`, `<databasename>`, `<username>@<servername>`, and `<password>` with names of your Azure SQL server, database, user account, and password.</span></span> 
3. <span data-ttu-id="35fbc-212">Fare clic su **Distribuisci** sulla barra degli strumenti per creare e distribuire **AzureSqlLinkedService**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-212">Click **Deploy** on the toolbar to create and deploy the **AzureSqlLinkedService**.</span></span>
4. <span data-ttu-id="35fbc-213">Assicurarsi che **AzureSqlLinkedService** sia visibile nella visualizzazione albero in **Servizi collegati**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-213">Confirm that you see **AzureSqlLinkedService** in the tree view under **Linked services**.</span></span>  

    <span data-ttu-id="35fbc-214">Per altre informazioni su queste proprietà JSON, vedere l'articolo relativo al [connettore del database SQL di Azure](data-factory-azure-sql-connector.md#linked-service-properties).</span><span class="sxs-lookup"><span data-stu-id="35fbc-214">For more information about these JSON properties, see [Azure SQL Database connector](data-factory-azure-sql-connector.md#linked-service-properties).</span></span>

## <a name="create-datasets"></a><span data-ttu-id="35fbc-215">Creare set di dati</span><span class="sxs-lookup"><span data-stu-id="35fbc-215">Create datasets</span></span>
<span data-ttu-id="35fbc-216">Nel passaggio precedente sono stati creati servizi collegati per collegare l'account di archiviazione di Azure e un database SQL di Azure alla data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-216">In the previous step, you created linked services to link your Azure Storage account and Azure SQL database to your data factory.</span></span> <span data-ttu-id="35fbc-217">In questo passaggio vengono definiti due set di dati denominati InputDataset e OutputDataset, che rappresentano i dati di input e di output memorizzati negli archivi dati a cui fanno riferimento rispettivamente AzureStorageLinkedService e AzureSqlLinkedService.</span><span class="sxs-lookup"><span data-stu-id="35fbc-217">In this step, you define two datasets named InputDataset and OutputDataset that represent input and output data that is stored in the data stores referred by AzureStorageLinkedService and AzureSqlLinkedService respectively.</span></span>

<span data-ttu-id="35fbc-218">Il servizio collegato Archiviazione di Azure specifica la stringa di connessione usata dal servizio Data Factory in fase di esecuzione per connettersi all'account di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-218">The Azure storage linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure storage account.</span></span> <span data-ttu-id="35fbc-219">Il set di dati del BLOB di input (InputDataset) specifica il contenitore e la cartella che contiene i dati di input.</span><span class="sxs-lookup"><span data-stu-id="35fbc-219">And, the input blob dataset (InputDataset) specifies the container and the folder that contains the input data.</span></span>  

<span data-ttu-id="35fbc-220">Analogamente, il servizio collegato per il database SQL di Azure specifica la stringa di connessione usata dal servizio Data Factory in fase di esecuzione per connettersi al database SQL di Azure</span><span class="sxs-lookup"><span data-stu-id="35fbc-220">Similarly, the Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="35fbc-221">e il set di dati della tabella SQL di output (OututDataset) specifica la tabella del database in cui vengono copiati i dati dell'archivio BLOB.</span><span class="sxs-lookup"><span data-stu-id="35fbc-221">And, the output SQL table dataset (OututDataset) specifies the table in the database to which the data from the blob storage is copied.</span></span> 

### <a name="create-input-dataset"></a><span data-ttu-id="35fbc-222">Creare set di dati di input</span><span class="sxs-lookup"><span data-stu-id="35fbc-222">Create input dataset</span></span>
<span data-ttu-id="35fbc-223">In questo passaggio viene creato un set di dati denominato InputDataset che punta a un file BLOB (emp.txt) nella cartella radice di un contenitore BLOB (adftutorial) nella risorsa di archiviazione di Azure rappresentata dal servizio collegato AzureStorageLinkedService.</span><span class="sxs-lookup"><span data-stu-id="35fbc-223">In this step, you create a dataset named InputDataset that points to a blob file (emp.txt) in the root folder of a blob container (adftutorial) in the Azure Storage represented by the AzureStorageLinkedService linked service.</span></span> <span data-ttu-id="35fbc-224">Se non si specifica un valore per fileName (o lo si ignora), i dati di tutti i BLOB della cartella di input vengono copiati nella destinazione.</span><span class="sxs-lookup"><span data-stu-id="35fbc-224">If you don't specify a value for the fileName (or skip it), data from all blobs in the input folder are copied to the destination.</span></span> <span data-ttu-id="35fbc-225">In questa esercitazione si specifica un valore per fileName.</span><span class="sxs-lookup"><span data-stu-id="35fbc-225">In this tutorial, you specify a value for the fileName.</span></span> 

1. <span data-ttu-id="35fbc-226">Nell'**editor** della data factory fare clic su **... Altro**, fare clic su **Nuovo set di dati** e quindi scegliere **Archivio BLOB di Azure** dal menu a discesa.</span><span class="sxs-lookup"><span data-stu-id="35fbc-226">In the **Editor** for the Data Factory, click **... More**, click **New dataset**, and click **Azure Blob storage** from the drop-down menu.</span></span> 
   
    ![Menu Nuovo set di dati](./media/data-factory-copy-activity-tutorial-using-azure-portal/new-dataset-menu.png)
2. <span data-ttu-id="35fbc-228">Sostituire il codice JSON nel riquadro a destra con il frammento di codice JSON seguente:</span><span class="sxs-lookup"><span data-stu-id="35fbc-228">Replace JSON in the right pane with the following JSON snippet:</span></span> 
   
    ```json
    {
      "name": "InputDataset",
      "properties": {
        "structure": [
          {
            "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
          }
        ],
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService",
        "typeProperties": {
          "folderPath": "adftutorial/",
          "fileName": "emp.txt",
          "format": {
            "type": "TextFormat",
            "columnDelimiter": ","
          }
        },
        "external": true,
        "availability": {
          "frequency": "Hour",
          "interval": 1
        }
      }
    }
    ```   

    <span data-ttu-id="35fbc-229">La tabella seguente fornisce le descrizioni delle proprietà JSON usate nel frammento di codice:</span><span class="sxs-lookup"><span data-stu-id="35fbc-229">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    | <span data-ttu-id="35fbc-230">Proprietà</span><span class="sxs-lookup"><span data-stu-id="35fbc-230">Property</span></span> | <span data-ttu-id="35fbc-231">Descrizione</span><span class="sxs-lookup"><span data-stu-id="35fbc-231">Description</span></span> |
    |:--- |:--- |
    | <span data-ttu-id="35fbc-232">type</span><span class="sxs-lookup"><span data-stu-id="35fbc-232">type</span></span> | <span data-ttu-id="35fbc-233">La proprietà type è impostata su **AzureBlob** perché i dati risiedono in un archivio BLOB di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-233">The type property is set to **AzureBlob** because data resides in an Azure blob storage.</span></span> |
    | <span data-ttu-id="35fbc-234">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="35fbc-234">linkedServiceName</span></span> | <span data-ttu-id="35fbc-235">Fa riferimento all'oggetto **AzureStorageLinkedService** creato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="35fbc-235">Refers to the **AzureStorageLinkedService** that you created earlier.</span></span> |
    | <span data-ttu-id="35fbc-236">folderPath</span><span class="sxs-lookup"><span data-stu-id="35fbc-236">folderPath</span></span> | <span data-ttu-id="35fbc-237">Specifica il **contenitore** BLOB e la **cartella** che contiene i BLOB di input.</span><span class="sxs-lookup"><span data-stu-id="35fbc-237">Specifies the blob **container** and the **folder** that contains input blobs.</span></span> <span data-ttu-id="35fbc-238">In questa esercitazione adftutorial è il contenitore BLOB e la cartella è la cartella radice.</span><span class="sxs-lookup"><span data-stu-id="35fbc-238">In this tutorial, adftutorial is the blob container and folder is the root folder.</span></span> | 
    | <span data-ttu-id="35fbc-239">fileName</span><span class="sxs-lookup"><span data-stu-id="35fbc-239">fileName</span></span> | <span data-ttu-id="35fbc-240">Questa proprietà è facoltativa.</span><span class="sxs-lookup"><span data-stu-id="35fbc-240">This property is optional.</span></span> <span data-ttu-id="35fbc-241">Se si omette questa proprietà, vengono selezionati tutti i file da folderPath.</span><span class="sxs-lookup"><span data-stu-id="35fbc-241">If you omit this property, all files from the folderPath are picked.</span></span> <span data-ttu-id="35fbc-242">In questa esercitazione come fileName si specifica **emp.txt** e viene quindi selezionato per l'elaborazione solo tale file.</span><span class="sxs-lookup"><span data-stu-id="35fbc-242">In this tutorial, **emp.txt** is specified for the fileName, so only that file is picked up for processing.</span></span> |
    | <span data-ttu-id="35fbc-243">format -> type</span><span class="sxs-lookup"><span data-stu-id="35fbc-243">format -> type</span></span> |<span data-ttu-id="35fbc-244">Il file di input è in formato testo, quindi viene usato **TextFormat**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-244">The input file is in the text format, so we use **TextFormat**.</span></span> |
    | <span data-ttu-id="35fbc-245">columnDelimiter</span><span class="sxs-lookup"><span data-stu-id="35fbc-245">columnDelimiter</span></span> | <span data-ttu-id="35fbc-246">Le colonne nel file di input sono delimitate da **virgola (`,`)**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-246">The columns in the input file are delimited by **comma character (`,`)**.</span></span> |
    | <span data-ttu-id="35fbc-247">frequenza/intervallo</span><span class="sxs-lookup"><span data-stu-id="35fbc-247">frequency/interval</span></span> | <span data-ttu-id="35fbc-248">La frequenza è impostata su **Hour** e l'intervallo è impostato su **1**, quindi le sezioni di input sono disponibili con cadenza **oraria**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-248">The frequency is set to **Hour** and interval is  set to **1**, which means that the input slices are available **hourly**.</span></span> <span data-ttu-id="35fbc-249">In altre parole, il servizio Data Factory cerca i dati di input ogni ora nella cartella radice del contenitore BLOB specificato (**adftutorial**).</span><span class="sxs-lookup"><span data-stu-id="35fbc-249">In other words, the Data Factory service looks for input data every hour in the root folder of blob container (**adftutorial**) you specified.</span></span> <span data-ttu-id="35fbc-250">Cerca i dati compresi tra l'ora di inizio e di fine della pipeline e non prima o dopo queste ore.</span><span class="sxs-lookup"><span data-stu-id="35fbc-250">It looks for the data within the pipeline start and end times, not before or after these times.</span></span>  |
    | <span data-ttu-id="35fbc-251">external</span><span class="sxs-lookup"><span data-stu-id="35fbc-251">external</span></span> | <span data-ttu-id="35fbc-252">Questa proprietà è impostata su **true** se i dati non vengono generati da questa pipeline.</span><span class="sxs-lookup"><span data-stu-id="35fbc-252">This property is set to **true** if the data is not generated by this pipeline.</span></span> <span data-ttu-id="35fbc-253">I dati di input in questa esercitazione sono nel file emp.txt, che non viene generato da questa pipeline, quindi questa proprietà viene impostata su true.</span><span class="sxs-lookup"><span data-stu-id="35fbc-253">The input data in this tutorial is in the emp.txt file, which is not generated by this pipeline, so we set this property to true.</span></span> |

    <span data-ttu-id="35fbc-254">Per altre informazioni su queste proprietà JSON, vedere l'articolo relativo al [connettore BLOB di Azure](data-factory-azure-blob-connector.md#dataset-properties).</span><span class="sxs-lookup"><span data-stu-id="35fbc-254">For more information about these JSON properties, see [Azure Blob connector article](data-factory-azure-blob-connector.md#dataset-properties).</span></span>      
3. <span data-ttu-id="35fbc-255">Fare clic su **Distribuisci** sulla barra degli strumenti per creare e distribuire il set di dati **InputDataset**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-255">Click **Deploy** on the toolbar to create and deploy the **InputDataset** dataset.</span></span> <span data-ttu-id="35fbc-256">Assicurarsi che **InputDataset** sia visibile nella visualizzazione albero.</span><span class="sxs-lookup"><span data-stu-id="35fbc-256">Confirm that you see the **InputDataset** in the tree view.</span></span>

### <a name="create-output-dataset"></a><span data-ttu-id="35fbc-257">Creare il set di dati di output</span><span class="sxs-lookup"><span data-stu-id="35fbc-257">Create output dataset</span></span>
<span data-ttu-id="35fbc-258">Il servizio collegato per il database SQL di Azure specifica la stringa di connessione usata dal servizio Data Factory in fase di esecuzione per connettersi al database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-258">The Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="35fbc-259">Il set di dati della tabella SQL di output (OututDataset) creato in questo passaggio specifica la tabella del database in cui vengono copiati i dati dell'archivio BLOB.</span><span class="sxs-lookup"><span data-stu-id="35fbc-259">The output SQL table dataset (OututDataset) you create in this step specifies the table in the database to which the data from the blob storage is copied.</span></span>

1. <span data-ttu-id="35fbc-260">Nell'**editor** della data factory fare clic su **... Altro**, fare clic su **Nuovo set di dati** e quindi scegliere **Azure SQL** dal menu a discesa.</span><span class="sxs-lookup"><span data-stu-id="35fbc-260">In the **Editor** for the Data Factory, click **... More**, click **New dataset**, and click **Azure SQL** from the drop-down menu.</span></span> 
2. <span data-ttu-id="35fbc-261">Sostituire il codice JSON nel riquadro a destra con il frammento di codice JSON seguente:</span><span class="sxs-lookup"><span data-stu-id="35fbc-261">Replace JSON in the right pane with the following JSON snippet:</span></span>

    ```json   
    {
      "name": "OutputDataset",
      "properties": {
        "structure": [
          {
            "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
          }
        ],
        "type": "AzureSqlTable",
        "linkedServiceName": "AzureSqlLinkedService",
        "typeProperties": {
          "tableName": "emp"
        },
        "availability": {
          "frequency": "Hour",
          "interval": 1
        }
      }
    }
    ```     

    <span data-ttu-id="35fbc-262">La tabella seguente fornisce le descrizioni delle proprietà JSON usate nel frammento di codice:</span><span class="sxs-lookup"><span data-stu-id="35fbc-262">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    | <span data-ttu-id="35fbc-263">Proprietà</span><span class="sxs-lookup"><span data-stu-id="35fbc-263">Property</span></span> | <span data-ttu-id="35fbc-264">Descrizione</span><span class="sxs-lookup"><span data-stu-id="35fbc-264">Description</span></span> |
    |:--- |:--- |
    | <span data-ttu-id="35fbc-265">type</span><span class="sxs-lookup"><span data-stu-id="35fbc-265">type</span></span> | <span data-ttu-id="35fbc-266">La proprietà type viene impostata su **AzureSqlTable** perché i dati vengono copiati in una tabella in un database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-266">The type property is set to **AzureSqlTable** because data is copied to a table in an Azure SQL database.</span></span> |
    | <span data-ttu-id="35fbc-267">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="35fbc-267">linkedServiceName</span></span> | <span data-ttu-id="35fbc-268">Fa riferimento all'oggetto **AzureSqlLinkedService** creato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="35fbc-268">Refers to the **AzureSqlLinkedService** that you created earlier.</span></span> |
    | <span data-ttu-id="35fbc-269">tableName</span><span class="sxs-lookup"><span data-stu-id="35fbc-269">tableName</span></span> | <span data-ttu-id="35fbc-270">Specifica la **tabella** in cui i dati vengono copiati.</span><span class="sxs-lookup"><span data-stu-id="35fbc-270">Specified the **table** to which the data is copied.</span></span> | 
    | <span data-ttu-id="35fbc-271">frequenza/intervallo</span><span class="sxs-lookup"><span data-stu-id="35fbc-271">frequency/interval</span></span> | <span data-ttu-id="35fbc-272">La frequenza viene impostata su **Hour** e l'intervallo è **1**, quindi le sezioni di output vengono generate **ogni ora** tra l'ora di inizio e di fine della pipeline e non prima o dopo queste ore.</span><span class="sxs-lookup"><span data-stu-id="35fbc-272">The frequency is set to **Hour** and interval is **1**, which means that the output slices are produced **hourly** between the pipeline start and end times, not before or after these times.</span></span>  |

    <span data-ttu-id="35fbc-273">La tabella emp del database include tre colonne: **ID**, **FirstName** e **LastName**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-273">There are three columns – **ID**, **FirstName**, and **LastName** – in the emp table in the database.</span></span> <span data-ttu-id="35fbc-274">ID è una colonna Identity, quindi in questo caso è necessario specificare solo **FirstName** e **LastName**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-274">ID is an identity column, so you need to specify only **FirstName** and **LastName** here.</span></span>

    <span data-ttu-id="35fbc-275">Per altre informazioni su queste proprietà JSON, vedere l'articolo relativo al [connettore SQL di Azure](data-factory-azure-sql-connector.md#dataset-properties).</span><span class="sxs-lookup"><span data-stu-id="35fbc-275">For more information about these JSON properties, see [Azure SQL connector article](data-factory-azure-sql-connector.md#dataset-properties).</span></span>
3. <span data-ttu-id="35fbc-276">Fare clic su **Distribuisci** sulla barra degli strumenti per creare e distribuire il set di dati **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-276">Click **Deploy** on the toolbar to create and deploy the **OutputDataset** dataset.</span></span> <span data-ttu-id="35fbc-277">Assicurarsi che **OutputDataset** sia visibile nella visualizzazione albero in **Datasets**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-277">Confirm that you see the **OutputDataset** in the tree view under **Datasets**.</span></span> 

## <a name="create-pipeline"></a><span data-ttu-id="35fbc-278">Creare una pipeline</span><span class="sxs-lookup"><span data-stu-id="35fbc-278">Create pipeline</span></span>
<span data-ttu-id="35fbc-279">In questo passaggio viene creata una pipeline con un'**attività di copia** che usa **InputDataset** come input e **OutputDataset** come output.</span><span class="sxs-lookup"><span data-stu-id="35fbc-279">In this step, you create a pipeline with a **copy activity** that uses **InputDataset** as an input and **OutputDataset** as an output.</span></span>

<span data-ttu-id="35fbc-280">Attualmente, è il set di dati di output a determinare la pianificazione.</span><span class="sxs-lookup"><span data-stu-id="35fbc-280">Currently, output dataset is what drives the schedule.</span></span> <span data-ttu-id="35fbc-281">In questa esercitazione il set di dati di output viene configurato per generare una sezione una volta ogni ora.</span><span class="sxs-lookup"><span data-stu-id="35fbc-281">In this tutorial, output dataset is configured to produce a slice once an hour.</span></span> <span data-ttu-id="35fbc-282">La pipeline ha un'ora di inizio e un'ora di fine intervallate da un giorno, ovvero 24 ore.</span><span class="sxs-lookup"><span data-stu-id="35fbc-282">The pipeline has a start time and end time that are one day apart, which is 24 hours.</span></span> <span data-ttu-id="35fbc-283">Vengono quindi generate dalla pipeline 24 sezioni di set di dati di output.</span><span class="sxs-lookup"><span data-stu-id="35fbc-283">Therefore, 24 slices of output dataset are produced by the pipeline.</span></span> 

1. <span data-ttu-id="35fbc-284">Nell'**editor** della data factory fare clic su **... Altro** e quindi su **Nuova pipeline**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-284">In the **Editor** for the Data Factory, click **... More**, and click **New pipeline**.</span></span> <span data-ttu-id="35fbc-285">In alternativa, è possibile fare clic con il pulsante destro del mouse su **Pipeline** nella visualizzazione ad albero e fare clic su **Nuova pipeline**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-285">Alternatively, you can right-click **Pipelines** in the tree view and click **New pipeline**.</span></span>
2. <span data-ttu-id="35fbc-286">Sostituire il codice JSON nel riquadro a destra con il frammento di codice JSON seguente:</span><span class="sxs-lookup"><span data-stu-id="35fbc-286">Replace JSON in the right pane with the following JSON snippet:</span></span> 

    ```json   
    {
      "name": "ADFTutorialPipeline",
      "properties": {
        "description": "Copy data from a blob to Azure SQL table",
        "activities": [
          {
            "name": "CopyFromBlobToSQL",
            "type": "Copy",
            "inputs": [
              {
                "name": "InputDataset"
              }
            ],
            "outputs": [
              {
                "name": "OutputDataset"
              }
            ],
            "typeProperties": {
              "source": {
                "type": "BlobSource"
              },
              "sink": {
                "type": "SqlSink",
                "writeBatchSize": 10000,
                "writeBatchTimeout": "60:00:00"
              }
            },
            "Policy": {
              "concurrency": 1,
              "executionPriorityOrder": "NewestFirst",
              "retry": 0,
              "timeout": "01:00:00"
            }
          }
        ],
        "start": "2017-05-11T00:00:00Z",
        "end": "2017-05-12T00:00:00Z"
      }
    } 
    ```   
    
    <span data-ttu-id="35fbc-287">Tenere presente quanto segue:</span><span class="sxs-lookup"><span data-stu-id="35fbc-287">Note the following points:</span></span>
   
    - <span data-ttu-id="35fbc-288">Nella sezione delle attività esiste una sola attività con l'oggetto **type** impostato su **Copy**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-288">In the activities section, there is only one activity whose **type** is set to **Copy**.</span></span> <span data-ttu-id="35fbc-289">Per altre informazioni sull'attività di copia, vedere le [attività di spostamento dei dati](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-289">For more information about the copy activity, see [data movement activities](data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="35fbc-290">Nelle soluzioni Data Factory è anche possibile usare le [attività di trasformazione dei dati](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-290">In Data Factory solutions, you can also use [data transformation activities](data-factory-data-transformation-activities.md).</span></span>
    - <span data-ttu-id="35fbc-291">L'input per l'attività è impostato su **InputDataset** e l'output è impostato su **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-291">Input for the activity is set to **InputDataset** and output for the activity is set to **OutputDataset**.</span></span> 
    - <span data-ttu-id="35fbc-292">Nella sezione **typeProperties** vengono specificati **BlobSource** come tipo di origine e **SqlSink** come tipo di sink.</span><span class="sxs-lookup"><span data-stu-id="35fbc-292">In the **typeProperties** section, **BlobSource** is specified as the source type and **SqlSink** is specified as the sink type.</span></span> <span data-ttu-id="35fbc-293">Per un elenco completo degli archivi dati supportati dall'attività di copia come origini e sink, vedere gli [archivi dati supportati](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="35fbc-293">For a complete list of data stores supported by the copy activity as sources and sinks, see [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span></span> <span data-ttu-id="35fbc-294">Per informazioni su come usare uno specifico archivio dati supportato come origine/sink, fare clic sul collegamento nella tabella.</span><span class="sxs-lookup"><span data-stu-id="35fbc-294">To learn how to use a specific supported data store as a source/sink, click the link in the table.</span></span>
    - <span data-ttu-id="35fbc-295">Per la data e ora di inizio è necessario usare il [formato ISO](http://en.wikipedia.org/wiki/ISO_8601),</span><span class="sxs-lookup"><span data-stu-id="35fbc-295">Both start and end datetimes must be in [ISO format](http://en.wikipedia.org/wiki/ISO_8601).</span></span> <span data-ttu-id="35fbc-296">ad esempio 2016-10-14T16:32:41Z.</span><span class="sxs-lookup"><span data-stu-id="35fbc-296">For example: 2016-10-14T16:32:41Z.</span></span> <span data-ttu-id="35fbc-297">Il valore di **end** è facoltativo, ma in questa esercitazione viene usato.</span><span class="sxs-lookup"><span data-stu-id="35fbc-297">The **end** time is optional, but we use it in this tutorial.</span></span> <span data-ttu-id="35fbc-298">Se non si specifica alcun valore per la proprietà **end**, il valore verrà calcolato come "**start + 48 hours**".</span><span class="sxs-lookup"><span data-stu-id="35fbc-298">If you do not specify value for the **end** property, it is calculated as "**start + 48 hours**".</span></span> <span data-ttu-id="35fbc-299">Per eseguire la pipeline illimitatamente, specificare **9999-09-09** come valore per la proprietà **end**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-299">To run the pipeline indefinitely, specify **9999-09-09** as the value for the **end** property.</span></span>
     
    <span data-ttu-id="35fbc-300">Nell'esempio precedente sono visualizzate 24 sezioni di dati, perché viene generata una sezione di dati ogni ora.</span><span class="sxs-lookup"><span data-stu-id="35fbc-300">In the preceding example, there are 24 data slices as each data slice is produced hourly.</span></span>

    <span data-ttu-id="35fbc-301">Per le descrizioni delle proprietà JSON nella definizione di una pipeline, vedere l'articolo su come [creare pipeline](data-factory-create-pipelines.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-301">For descriptions of JSON properties in a pipeline definition, see [create pipelines](data-factory-create-pipelines.md) article.</span></span> <span data-ttu-id="35fbc-302">Per le descrizioni delle proprietà JSON nella definizione di un'attività di copia, vedere le [attività di spostamento dei dati](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-302">For descriptions of JSON properties in a copy activity definition, see [data movement activities](data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="35fbc-303">Per le descrizioni delle proprietà JSON supportate da BlobSource, vedere l'articolo relativo al [connettore BLOB di Azure](data-factory-azure-blob-connector.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-303">For descriptions of JSON properties supported by BlobSource, see [Azure Blob connector article](data-factory-azure-blob-connector.md).</span></span> <span data-ttu-id="35fbc-304">Per le descrizioni delle proprietà JSON supportate da SqlSink, vedere l'articolo relativo al [connettore del database SQL di Azure](data-factory-azure-sql-connector.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-304">For descriptions of JSON properties supported by SqlSink, see [Azure SQL Database connector article](data-factory-azure-sql-connector.md).</span></span>
3. <span data-ttu-id="35fbc-305">Fare clic su **Distribuisci** sulla barra degli strumenti per creare e distribuire **ADFTutorialPipeline**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-305">Click **Deploy** on the toolbar to create and deploy the **ADFTutorialPipeline**.</span></span> <span data-ttu-id="35fbc-306">Verificare che la pipeline sia visibile nella visualizzazione albero.</span><span class="sxs-lookup"><span data-stu-id="35fbc-306">Confirm that you see the pipeline in the tree view.</span></span> 
4. <span data-ttu-id="35fbc-307">Chiudere quindi il pannello dell'**editor** facendo clic su **X**. Fare clic di nuovo su **X** per visualizzare la home page di **Data Factory** per **ADFTutorialDataFactory**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-307">Now, close the **Editor** blade by clicking **X**. Click **X** again to see the **Data Factory** home page for the **ADFTutorialDataFactory**.</span></span>

<span data-ttu-id="35fbc-308">**Congratulazioni.**</span><span class="sxs-lookup"><span data-stu-id="35fbc-308">**Congratulations!**</span></span> <span data-ttu-id="35fbc-309">È stata creata una data factory di Azure con una pipeline per copiare dati da un archivio BLOB di Azure a un database SQL di Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-309">You have successfully created an Azure data factory with a pipeline to copy data from an Azure blob storage to an Azure SQL database.</span></span> 


## <a name="monitor-pipeline"></a><span data-ttu-id="35fbc-310">Monitorare la pipeline</span><span class="sxs-lookup"><span data-stu-id="35fbc-310">Monitor pipeline</span></span>
<span data-ttu-id="35fbc-311">In questo passaggio viene usato il portale di Azure per monitorare le attività in un'istanza di Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-311">In this step, you use the Azure portal to monitor what’s going on in an Azure data factory.</span></span>    

### <a name="monitor-pipeline-using-monitor--manage-app"></a><span data-ttu-id="35fbc-312">Monitorare la pipeline con l'app Monitoraggio e gestione</span><span class="sxs-lookup"><span data-stu-id="35fbc-312">Monitor pipeline using Monitor & Manage App</span></span>
<span data-ttu-id="35fbc-313">La procedura seguente illustra come monitorare le pipeline nella data factory usando l'applicazione Monitoraggio e gestione:</span><span class="sxs-lookup"><span data-stu-id="35fbc-313">The following steps show you how to monitor pipelines in your data factory by using the Monitor & Manage application:</span></span> 

1. <span data-ttu-id="35fbc-314">Fare clic sul riquadro **Monitoraggio e gestione** nella home page della data factory.</span><span class="sxs-lookup"><span data-stu-id="35fbc-314">Click **Monitor & Manage** tile on the home page for your data factory.</span></span>
   
    ![Riquadro Monitoraggio e gestione](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-manage-tile.png) 
2. <span data-ttu-id="35fbc-316">L'**applicazione Monitoraggio e gestione** verrà visualizzata in una scheda separata.</span><span class="sxs-lookup"><span data-stu-id="35fbc-316">You should see **Monitor & Manage application** in a separate tab.</span></span> 

    > [!NOTE]
    > <span data-ttu-id="35fbc-317">Se il Web browser è bloccato su "Concessione autorizzazioni in corso...", eseguire una di queste operazioni: deselezionare la casella di controllo **Block third-party cookies and site data** (Blocco dei cookie di terze parti e dei dati dei siti) oppure creare un'eccezione per **login.microsoftonline.com** e quindi provare di nuovo ad aprire l'app.</span><span class="sxs-lookup"><span data-stu-id="35fbc-317">If you see that the web browser is stuck at "Authorizing...", do one of the following: clear the **Block third-party cookies and site data** check box (or) create an exception for **login.microsoftonline.com**, and then try to open the app again.</span></span>

    ![App Monitoraggio e gestione](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-and-manage-app.png)
3. <span data-ttu-id="35fbc-319">Modificare l'**Ora di inizio** e l'**Ora di fine** in modo da includere l'inizio (11/05/2017) e la fine (12/05/2017) della pipeline e fare clic su **Applica**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-319">Change the **Start time** and **End time** to include start (2017-05-11) and end times (2017-05-12) of your pipeline, and click **Apply**.</span></span>       
3. <span data-ttu-id="35fbc-320">Vengono visualizzate le **finestre attività** associate a ogni ora compresa tra l'ora di inizio e l'ora di fine della pipeline nell'elenco del riquadro centrale.</span><span class="sxs-lookup"><span data-stu-id="35fbc-320">You see the **activity windows** associated with each hour between pipeline start and end times in the list in the middle pane.</span></span> 
4. <span data-ttu-id="35fbc-321">Per visualizzare i dettagli di una finestra attività, selezionarla nell'elenco **Activity Windows** (Finestre attività).</span><span class="sxs-lookup"><span data-stu-id="35fbc-321">To see details about an activity window, select the activity window in the **Activity Windows** list.</span></span> 
    <span data-ttu-id="35fbc-322">![Dettagli finestra attività](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)</span><span class="sxs-lookup"><span data-stu-id="35fbc-322">![Activity window details](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)</span></span>

    <span data-ttu-id="35fbc-323">In Activity Window Explorer (Esplora finestre attività) sulla destra è possibile osservare che le sezioni fino all'ora UTC corrente (20:12) sono state tutte elaborate (in verde).</span><span class="sxs-lookup"><span data-stu-id="35fbc-323">In Activity Window Explorer on the right, you see that the slices up to the current UTC time (8:12 PM) are all processed (in green color).</span></span> <span data-ttu-id="35fbc-324">Le sezioni 20-21, 21-22, 22-23, 23-00 non sono ancora state elaborate.</span><span class="sxs-lookup"><span data-stu-id="35fbc-324">The 8-9 PM, 9 - 10 PM, 10 - 11 PM, 11 PM - 12 AM slices are not processed yet.</span></span>

    <span data-ttu-id="35fbc-325">La sezione **Tentativi** nel riquadro a destra contiene informazioni sull'attività eseguita per la sezione dati.</span><span class="sxs-lookup"><span data-stu-id="35fbc-325">The **Attempts** section in the right pane provides information about the activity run for the data slice.</span></span> <span data-ttu-id="35fbc-326">Se si è verificato un errore, fornisce dettagli sull'errore.</span><span class="sxs-lookup"><span data-stu-id="35fbc-326">If there was an error, it provides details about the error.</span></span> <span data-ttu-id="35fbc-327">Se ad esempio la cartella o il contenitore di input non esiste e l'elaborazione della sezione non riesce, viene visualizzato un messaggio di errore che informa che il contenitore o la cartella non esiste.</span><span class="sxs-lookup"><span data-stu-id="35fbc-327">For example, if the input folder or container does not exist and the slice processing fails, you see an error message stating that the container or folder does not exist.</span></span>

    ![Tentativi di esecuzione dell'attività](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-run-attempts.png) 
4. <span data-ttu-id="35fbc-329">Avviare **SQL Server Management Studio**, connettersi al database SQL di Azure e verificare che le righe vengano inserite nella tabella **emp** nel database.</span><span class="sxs-lookup"><span data-stu-id="35fbc-329">Launch **SQL Server Management Studio**, connect to the Azure SQL Database, and verify that the rows are inserted in to the **emp** table in the database.</span></span>
    
    ![Risultati della query SQL](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)

<span data-ttu-id="35fbc-331">Per informazioni dettagliate sull'uso di questa applicazione, vedere [Monitorare e gestire le pipeline di Azure Data Factory con la nuova app di monitoraggio e gestione](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="35fbc-331">For detailed information about using this application, see [Monitor and manage Azure Data Factory pipelines using Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

### <a name="monitor-pipeline-using-diagram-view"></a><span data-ttu-id="35fbc-332">Monitorare la pipeline con la vista diagramma</span><span class="sxs-lookup"><span data-stu-id="35fbc-332">Monitor pipeline using Diagram View</span></span>
<span data-ttu-id="35fbc-333">È anche possibile monitorare le pipeline di dati usando la vista diagramma.</span><span class="sxs-lookup"><span data-stu-id="35fbc-333">You can also monitor data pipelines by using the diagram view.</span></span>  

1. <span data-ttu-id="35fbc-334">Nel pannello **Data Factory** fare clic su **Diagramma**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-334">In the **Data Factory** blade, click **Diagram**.</span></span>
   
    ![Pannello Data factory - Riquadro Diagramma](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-datafactoryblade-diagramtile.png)
2. <span data-ttu-id="35fbc-336">Verrà visualizzato un diagramma simile all'immagine seguente:</span><span class="sxs-lookup"><span data-stu-id="35fbc-336">You should see the diagram similar to the following image:</span></span> 
   
    ![Vista diagramma](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-diagram-blade.png)  
5. <span data-ttu-id="35fbc-338">Nella vista diagramma fare doppio clic su **InputDataset** per visualizzare le sezioni per il set di dati.</span><span class="sxs-lookup"><span data-stu-id="35fbc-338">In the diagram view, double-click **InputDataset** to see slices for the dataset.</span></span>  
   
    ![Set di dati con InputDataset selezionato](./media/data-factory-copy-activity-tutorial-using-azure-portal/DataSetsWithInputDatasetFromBlobSelected.png)   
5. <span data-ttu-id="35fbc-340">Fare clic sul collegamento **Altre informazioni** per visualizzare tutte le sezioni dati.</span><span class="sxs-lookup"><span data-stu-id="35fbc-340">Click **See more** link to see all the data slices.</span></span> <span data-ttu-id="35fbc-341">Vengono visualizzate 24 sezioni orarie tra l'ora di inizio e di fine della pipeline.</span><span class="sxs-lookup"><span data-stu-id="35fbc-341">You see 24 hourly slices between pipeline start and end times.</span></span> 
   
    ![Tutte le sezioni dati di input](./media/data-factory-copy-activity-tutorial-using-azure-portal/all-input-slices.png)  
   
    <span data-ttu-id="35fbc-343">Si noti che le sezioni di dati fino all'ora UTC corrente sono nello stato **Pronto**, perché il file **emp.txt** è sempre presente nel contenitore BLOB **adftutorial\input**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-343">Notice that all the data slices up to the current UTC time are **Ready** because the **emp.txt** file exists all the time in the blob container: **adftutorial\input**.</span></span> <span data-ttu-id="35fbc-344">Le sezioni per le ore successive non sono ancora nello stato Pronto.</span><span class="sxs-lookup"><span data-stu-id="35fbc-344">The slices for the future times are not in ready state yet.</span></span> <span data-ttu-id="35fbc-345">Verificare che non sia visualizzata alcuna sezione in **Sezioni non riuscite di recente** nella parte inferiore della pagina.</span><span class="sxs-lookup"><span data-stu-id="35fbc-345">Confirm that no slices show up in the **Recently failed slices** section at the bottom.</span></span>
6. <span data-ttu-id="35fbc-346">Chiudere i pannelli fino a visualizzare la vista diagramma oppure scorrere verso sinistra per visualizzare la vista diagramma,</span><span class="sxs-lookup"><span data-stu-id="35fbc-346">Close the blades until you see the diagram view (or) scroll left to see the diagram view.</span></span> <span data-ttu-id="35fbc-347">quindi fare doppio clic su **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-347">Then, double-click **OutputDataset**.</span></span> 
8. <span data-ttu-id="35fbc-348">Fare clic sul collegamento **Altre informazioni** nel pannello **Tabella** per **OutputDataset** per visualizzare tutte le sezioni.</span><span class="sxs-lookup"><span data-stu-id="35fbc-348">Click **See more** link on the **Table** blade for **OutputDataset** to see all the slices.</span></span>

    ![Pannello Sezioni dati](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslices-blade.png) 
9. <span data-ttu-id="35fbc-350">Si noti che tutte le sezioni fino all'ora UTC corrente passano dallo stato **L'esecuzione è in sospeso** allo stato => **In corso** ==> **Pronto**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-350">Notice that all the slices up to the current UTC time move from **pending execution** state => **In progress** ==> **Ready** state.</span></span> <span data-ttu-id="35fbc-351">Per impostazione predefinita, le sezioni precedenti (prima dell'ora corrente) vengono elaborate dalla più recente alla meno recente.</span><span class="sxs-lookup"><span data-stu-id="35fbc-351">The slices from the past (before current time) are processed from latest to oldest by default.</span></span> <span data-ttu-id="35fbc-352">Se ad esempio l'ora corrente è 20:12 UTC, la sezione 19 - 20 viene elaborata prima della sezione 18 - 19.</span><span class="sxs-lookup"><span data-stu-id="35fbc-352">For example, if the current time is 8:12 PM UTC, the slice for 7 PM - 8 PM is processed ahead of the 6 PM - 7 PM slice.</span></span> <span data-ttu-id="35fbc-353">Per impostazione predefinita, la sezione 20 - 21 viene elaborata alla fine dell'intervallo di tempo, ovvero dopo le 21.</span><span class="sxs-lookup"><span data-stu-id="35fbc-353">The 8 PM - 9 PM slice is processed at the end of the time interval by default, that is after 9 PM.</span></span>  
10. <span data-ttu-id="35fbc-354">Fare clic su una qualsiasi sezione dati dell'elenco per visualizzare il pannello **Sezione dati** .</span><span class="sxs-lookup"><span data-stu-id="35fbc-354">Click any data slice from the list and you should see the **Data slice** blade.</span></span> <span data-ttu-id="35fbc-355">I dati associati a una finestra attività vengono chiamati sezione.</span><span class="sxs-lookup"><span data-stu-id="35fbc-355">A piece of data associated with an activity window is called a slice.</span></span> <span data-ttu-id="35fbc-356">Una sezione può essere costituita da uno o più file.</span><span class="sxs-lookup"><span data-stu-id="35fbc-356">A slice can be one file or multiple files.</span></span>  
    
     ![Pannello Sezione di dati](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslice-blade.png)
    
     <span data-ttu-id="35fbc-358">Se lo stato della sezione non è **Pronto**, sarà possibile visualizzare le sezioni upstream che non sono pronte e bloccano l'esecuzione della sezione corrente nell'elenco **Sezioni upstream non pronte**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-358">If the slice is not in the **Ready** state, you can see the upstream slices that are not Ready and are blocking the current slice from executing in the **Upstream slices that are not ready** list.</span></span>
11. <span data-ttu-id="35fbc-359">Nel pannello **SEZIONE DI DATI** è possibile visualizzare tutte le esecuzioni di attività nell'elenco in basso.</span><span class="sxs-lookup"><span data-stu-id="35fbc-359">In the **DATA SLICE** blade, you should see all activity runs in the list at the bottom.</span></span> <span data-ttu-id="35fbc-360">Fare clic su un'**esecuzione di attività** per visualizzare il pannello **Dettagli esecuzione attività**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-360">Click an **activity run** to see the **Activity run details** blade.</span></span> 
    
    ![Dettagli esecuzione attività](./media/data-factory-copy-activity-tutorial-using-azure-portal/ActivityRunDetails.png)

    <span data-ttu-id="35fbc-362">In questo pannello vengono visualizzati la durata dell'operazione di copia, la velocità effettiva, il numero di byte di dati letti e scritti, l'ora di inizio dell'esecuzione, l'ora di fine dell'esecuzione e così via.</span><span class="sxs-lookup"><span data-stu-id="35fbc-362">In this blade, you see how long the copy operation took, what throughput is, how many bytes of data were read and written, run start time, run end time etc.</span></span>  
12. <span data-ttu-id="35fbc-363">Fare clic su **X** per chiudere tutti i pannelli finché non viene visualizzato il pannello iniziale per **ADFTutorialDataFactory**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-363">Click **X** to close all the blades until you get back to the home blade for the **ADFTutorialDataFactory**.</span></span>
13. <span data-ttu-id="35fbc-364">(Facoltativo) Fare clic sul riquadro **Set di dati** o sul riquadro **Pipeline** per ottenere i pannelli visualizzati nei passaggi precedenti.</span><span class="sxs-lookup"><span data-stu-id="35fbc-364">(optional) click the **Datasets** tile or **Pipelines** tile to get the blades you have seen the preceding steps.</span></span> 
14. <span data-ttu-id="35fbc-365">Avviare **SQL Server Management Studio**, connettersi al database SQL di Azure e verificare che le righe vengano inserite nella tabella **emp** nel database.</span><span class="sxs-lookup"><span data-stu-id="35fbc-365">Launch **SQL Server Management Studio**, connect to the Azure SQL Database, and verify that the rows are inserted in to the **emp** table in the database.</span></span>
    
    ![Risultati della query SQL](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)


## <a name="summary"></a><span data-ttu-id="35fbc-367">Riepilogo</span><span class="sxs-lookup"><span data-stu-id="35fbc-367">Summary</span></span>
<span data-ttu-id="35fbc-368">In questa esercitazione è stata creata una data factory di Azure per copiare dati da un BLOB di Azure a un database SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="35fbc-368">In this tutorial, you created an Azure data factory to copy data from an Azure blob to an Azure SQL database.</span></span> <span data-ttu-id="35fbc-369">È stato usato il portale di Azure per creare la data factory, i servizi collegati, i set di dati e una pipeline.</span><span class="sxs-lookup"><span data-stu-id="35fbc-369">You used the Azure portal to create the data factory, linked services, datasets, and a pipeline.</span></span> <span data-ttu-id="35fbc-370">Ecco i passaggi generali eseguiti in questa esercitazione:</span><span class="sxs-lookup"><span data-stu-id="35fbc-370">Here are the high-level steps you performed in this tutorial:</span></span>  

1. <span data-ttu-id="35fbc-371">Creare un'istanza di Azure **Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="35fbc-371">Created an Azure **data factory**.</span></span>
2. <span data-ttu-id="35fbc-372">Creare **servizi collegati**:</span><span class="sxs-lookup"><span data-stu-id="35fbc-372">Created **linked services**:</span></span>
   1. <span data-ttu-id="35fbc-373">Un servizio collegato di **Archiviazione di Azure** per collegare l'account di archiviazione di Azure che include i dati di input.</span><span class="sxs-lookup"><span data-stu-id="35fbc-373">An **Azure Storage** linked service to link your Azure Storage account that holds input data.</span></span>     
   2. <span data-ttu-id="35fbc-374">Un servizio collegato di **Azure SQL** per collegare il database SQL di Azure che contiene i dati di output.</span><span class="sxs-lookup"><span data-stu-id="35fbc-374">An **Azure SQL** linked service to link your Azure SQL database that holds the output data.</span></span> 
3. <span data-ttu-id="35fbc-375">Creare **set di dati** che descrivono dati di input e di output per le pipeline.</span><span class="sxs-lookup"><span data-stu-id="35fbc-375">Created **datasets** that describe input data and output data for pipelines.</span></span>
4. <span data-ttu-id="35fbc-376">Creare una **pipeline** con un'**attività di copia** con **BlobSource** come origine e **SqlSink** come sink.</span><span class="sxs-lookup"><span data-stu-id="35fbc-376">Created a **pipeline** with a **Copy Activity** with **BlobSource** as source and **SqlSink** as sink.</span></span>  

## <a name="next-steps"></a><span data-ttu-id="35fbc-377">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="35fbc-377">Next steps</span></span>
<span data-ttu-id="35fbc-378">In questa esercitazione sono stati usati l'archivio BLOB di Azure come archivio dati di origine e un database SQL di Azure come archivio dati di destinazione in un'operazione di copia.</span><span class="sxs-lookup"><span data-stu-id="35fbc-378">In this tutorial, you used Azure blob storage as a source data store and an Azure SQL database as a destination data store in a copy operation.</span></span> <span data-ttu-id="35fbc-379">La tabella seguente contiene un elenco degli archivi dati supportati come origini e come destinazioni dall'attività di copia:</span><span class="sxs-lookup"><span data-stu-id="35fbc-379">The following table provides a list of data stores supported as sources and destinations by the copy activity:</span></span> 

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="35fbc-380">Per informazioni su come copiare dati da/in un archivio dati, fare clic sul collegamento relativo all'archivio dati nella tabella.</span><span class="sxs-lookup"><span data-stu-id="35fbc-380">To learn about how to copy data to/from a data store, click the link for the data store in the table.</span></span>