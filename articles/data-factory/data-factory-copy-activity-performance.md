---
title: "Guida alle prestazioni dell'attività di copia e all'ottimizzazione | Microsoft Docs"
description: "Informazioni sui fattori principali che influiscono sulle prestazioni dello spostamento di dati in Azure Data Factory quando si usa l'attività di copia."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="88a74-103">Guida alle prestazioni dell'attività di copia e all'ottimizzazione</span><span class="sxs-lookup"><span data-stu-id="88a74-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="88a74-104">L'attività di copia di Azure Data Factory offre una soluzione di caricamento dei dati di primo livello in quanto a sicurezza, affidabilità e prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="88a74-105">Consente di copiare decine di terabyte di dati ogni giorno in un'ampia gamma di archivi dati locali e cloud.</span><span class="sxs-lookup"><span data-stu-id="88a74-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="88a74-106">Prestazioni di caricamento dei dati velocissime sono fondamentali per garantire di potersi concentrare sul problema centrale dei "big data": realizzare soluzioni avanzate di analisi e ricevere informazioni approfondite da tutti i dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="88a74-107">Azure fornisce un set di soluzioni di archiviazione dei dati e data warehouse di livello aziendale, e l'attività di copia offre un'esperienza di caricamento dei dati altamente ottimizzata, facile da configurare e impostare.</span><span class="sxs-lookup"><span data-stu-id="88a74-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="88a74-108">Con un'unica attività di copia, è possibile ottenere:</span><span class="sxs-lookup"><span data-stu-id="88a74-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="88a74-109">Caricamento dei dati in **Azure SQL Data Warehouse** a **1,2 GBps**.</span><span class="sxs-lookup"><span data-stu-id="88a74-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="88a74-110">Per la procedura dettagliata con un caso d'uso, vedere [Caricare 1 TB di dati in Azure SQL Data Warehouse in meno di 15 minuti con Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="88a74-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="88a74-111">Caricamento dei dati nell'**Archiviazione BLOB di Azure** a **1 GBps**</span><span class="sxs-lookup"><span data-stu-id="88a74-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="88a74-112">Caricamento dei dati in **Azure Data Lake Store** a **1 GBps**</span><span class="sxs-lookup"><span data-stu-id="88a74-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="88a74-113">L'articolo illustra:</span><span class="sxs-lookup"><span data-stu-id="88a74-113">This article describes:</span></span>

* <span data-ttu-id="88a74-114">[I numeri di riferimento sulle prestazioni](#performance-reference) per gli archivi dati di origine e sink supportati per aiutare a pianificare il progetto;</span><span class="sxs-lookup"><span data-stu-id="88a74-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="88a74-115">Funzionalità in grado di incrementare la velocità effettiva di copia in diversi scenari, tra cui [unità di spostamento dei dati cloud](#cloud-data-movement-units), [copia parallela](#parallel-copy) e [copia di staging](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="88a74-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="88a74-116">[Indicazioni per l'ottimizzazione delle prestazioni](#performance-tuning-steps) che illustrano come ottimizzare le prestazioni e i fattori chiave che possono influire sulle prestazioni di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="88a74-117">Se non si ha familiarità con l'attività di copia in generale, vedere [Spostare dati con l'attività di copia](data-factory-data-movement-activities.md) prima di continuare a leggere l'articolo.</span><span class="sxs-lookup"><span data-stu-id="88a74-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="88a74-118">Informazioni di riferimento sulle prestazioni</span><span class="sxs-lookup"><span data-stu-id="88a74-118">Performance reference</span></span>

<span data-ttu-id="88a74-119">Come riferimento, la tabella sotto mostra la velocità effettiva di copia in MBps per le coppie di origine e sink specifiche in base a test interni.</span><span class="sxs-lookup"><span data-stu-id="88a74-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="88a74-120">A scopo di confronto, viene illustrato anche in che modo le diverse impostazioni di [unità di spostamento dati cloud](#cloud-data-movement-units) o la [scalabilità di Gateway di gestione dati](data-factory-data-management-gateway-high-availability-scalability.md) (nodi gateway multipli) possono favorire le prestazioni di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Matrice delle prestazioni](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="88a74-122">**Punti da notare:**</span><span class="sxs-lookup"><span data-stu-id="88a74-122">**Points to note:**</span></span>
* <span data-ttu-id="88a74-123">La velocità effettiva viene calcolata con la formula seguente: [dimensione dei dati letti dall'origine]/[durata dell'esecuzione dell'attività di copia].</span><span class="sxs-lookup"><span data-stu-id="88a74-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="88a74-124">I numeri di riferimento delle prestazioni nella tabella sono stati misurati usando il set di dati [TPC-H](http://www.tpc.org/tpch/) nell'esecuzione di una singola attività di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="88a74-125">Nel caso degli archivi dati di Azure, l'origine e il sink si trovano nella stessa area di Azure.</span><span class="sxs-lookup"><span data-stu-id="88a74-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="88a74-126">Per la copia ibrida tra archivi dati locali e cloud, ogni nodo del gateway è in esecuzione su un computer separato dall'archivio dati locale, con le specifiche indicate di seguito.</span><span class="sxs-lookup"><span data-stu-id="88a74-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="88a74-127">Durante l'esecuzione di una singola attività nel gateway, l'operazione di copia ha usato solo una piccola parte della CPU, della memoria o della larghezza di banda di rete del computer di test.</span><span class="sxs-lookup"><span data-stu-id="88a74-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="88a74-128">Vedere [Considerazioni su Gateway di gestione dati](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="88a74-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="88a74-129">CPU</span><span class="sxs-lookup"><span data-stu-id="88a74-129">CPU</span></span></td>
        <td><span data-ttu-id="88a74-130">Intel Xeon E5-2660 v2 da 32 core a 2,20 GHz</span><span class="sxs-lookup"><span data-stu-id="88a74-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="88a74-131">Memoria</span><span class="sxs-lookup"><span data-stu-id="88a74-131">Memory</span></span></td>
        <td><span data-ttu-id="88a74-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="88a74-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="88a74-133">Rete</span><span class="sxs-lookup"><span data-stu-id="88a74-133">Network</span></span></td>
        <td><span data-ttu-id="88a74-134">Interfaccia Internet: 10 Gbps, interfaccia Intranet: 40 Gbps</span><span class="sxs-lookup"><span data-stu-id="88a74-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="88a74-135">È possibile raggiungere una velocità effettiva più elevata sfruttando un numero maggiore di unità di spostamento dati di quello massimo predefinito, pari a 32 per l'esecuzione di un'attività di copia da cloud a cloud.</span><span class="sxs-lookup"><span data-stu-id="88a74-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="88a74-136">Ad esempio, con 100 unità di spostamento dati è possibile copiare i dati dal BLOB di Azure in Azure Data Lake Store a **1,0 GB al secondo**.</span><span class="sxs-lookup"><span data-stu-id="88a74-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="88a74-137">Vedere la sezione [Unità di spostamento dati cloud](#cloud-data-movement-units) per informazioni dettagliate su questa funzionalità e sullo scenario supportato.</span><span class="sxs-lookup"><span data-stu-id="88a74-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="88a74-138">Contattare il [Supporto tecnico di Azure](https://azure.microsoft.com/support/) per richiedere altre unità di spostamento dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="88a74-139">Copia parallela</span><span class="sxs-lookup"><span data-stu-id="88a74-139">Parallel copy</span></span>
<span data-ttu-id="88a74-140">È possibile leggere dati dall'origine o scrivere dati nella destinazione **in parallelo all'interno di un'esecuzione dell'attività di copia**.</span><span class="sxs-lookup"><span data-stu-id="88a74-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="88a74-141">Questa funzionalità migliora la velocità effettiva di un'operazione di copia e riduce il tempo necessario per spostare i dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="88a74-142">Questa impostazione è diversa dalla proprietà **concurrency** nella definizione dell'attività.</span><span class="sxs-lookup"><span data-stu-id="88a74-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="88a74-143">La proprietà **concurrency** determina il numero di **esecuzioni simultanee dell'attività di copia** per elaborare i dati da finestre attività diverse. Ad esempio, dall'1.00 alle 2.00, dalle 2.00 alle 3.00, dalle 3.00 alle 4.00 e così via.</span><span class="sxs-lookup"><span data-stu-id="88a74-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="88a74-144">Questa funzionalità è utile quando si esegue un caricamento cronologico.</span><span class="sxs-lookup"><span data-stu-id="88a74-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="88a74-145">La funzionalità di copia parallela si applica all'**esecuzione di una singola attività**.</span><span class="sxs-lookup"><span data-stu-id="88a74-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="88a74-146">Verrà ora esaminato uno scenario di esempio.</span><span class="sxs-lookup"><span data-stu-id="88a74-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="88a74-147">Nell'esempio seguente è necessario elaborare più sezioni trascorse.</span><span class="sxs-lookup"><span data-stu-id="88a74-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="88a74-148">Data Factory esegue un'istanza dell'attività di copia, ovvero un'esecuzione attività, per ogni sezione:</span><span class="sxs-lookup"><span data-stu-id="88a74-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="88a74-149">Sezione dati dalla prima finestra attività (dall'1.00 alle 2.00) = = > esecuzione attività 1</span><span class="sxs-lookup"><span data-stu-id="88a74-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="88a74-150">Sezione dati dalla seconda finestra attività (dalle 2.00 alle 3.00) = = > esecuzione attività 2</span><span class="sxs-lookup"><span data-stu-id="88a74-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="88a74-151">Sezione dati dalla terza finestra attività (dalle 3.00 alle 4.00) = = > esecuzione attività 3</span><span class="sxs-lookup"><span data-stu-id="88a74-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="88a74-152">e così via.</span><span class="sxs-lookup"><span data-stu-id="88a74-152">And so on.</span></span>

<span data-ttu-id="88a74-153">In questo esempio quando il valore **concurrency** è impostato su 2, l'**esecuzione attività 1** e l'**esecuzione attività 2** copiano i dati da due finestre attività **simultaneamente** per migliorare le prestazioni dello spostamento dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="88a74-154">Tuttavia, se all'esecuzione attività 1 sono associati più file, il servizio di spostamento dati copia un file alla volta dall'origine alla destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="88a74-155">Unità di spostamento dati cloud</span><span class="sxs-lookup"><span data-stu-id="88a74-155">Cloud data movement units</span></span>
<span data-ttu-id="88a74-156">L' **unità di spostamento dati cloud** è una misura che rappresenta la potenza, ossia la combinazione tra CPU, memoria e allocazione di risorse di rete, di una singola unità in Data Factory.</span><span class="sxs-lookup"><span data-stu-id="88a74-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="88a74-157">Una unità di spostamento dati può essere usata in un'operazione di copia da cloud a cloud, ma non in una copia ibrida.</span><span class="sxs-lookup"><span data-stu-id="88a74-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="88a74-158">Per impostazione predefinita, Data Factory usa una singola unità di spostamento dati cloud per una singola esecuzione dell'attività di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="88a74-159">Per ignorare l'impostazione predefinita, è possibile specificare un valore per la proprietà **cloudDataMovementUnits** procedendo come segue.</span><span class="sxs-lookup"><span data-stu-id="88a74-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="88a74-160">Per informazioni sul livello di miglioramento delle prestazioni che è possibile ottenere quando si configurano più unità per un sink e un'origine della copia specifici, vedere la sezione [Informazioni di riferimento sulle prestazioni](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="88a74-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="88a74-161">I **valori consentiti** per la proprietà **cloudDataMovementUnits** sono 1 (valore predefinito), 2, 4, 8, 16, 32.</span><span class="sxs-lookup"><span data-stu-id="88a74-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="88a74-162">Il **numero effettivo di unità di spostamento dati cloud** usate dall'operazione di copia in fase di esecuzione è minore o uguale al valore configurato, a seconda del modello di dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="88a74-163">Se sono necessarie più unità di spostamento dati cloud per aumentare la velocità effettiva, contattare il [supporto di Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="88a74-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="88a74-164">Attualmente è possibile impostare la proprietà su valori maggiori o uguali a 8 soltanto per la **copia di più file da Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP in Blob storage/Data Lake Store/Azure SQL Database**.</span><span class="sxs-lookup"><span data-stu-id="88a74-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="88a74-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="88a74-165">parallelCopies</span></span>
<span data-ttu-id="88a74-166">È possibile usare la proprietà **parallelCopies** per indicare il parallelismo che l'attività di copia deve usare.</span><span class="sxs-lookup"><span data-stu-id="88a74-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="88a74-167">Questa proprietà può essere considerata come il numero massimo di thread all'interno dell'attività di copia che possono leggere dall'origine o scrivere negli archivi dati sink in parallelo.</span><span class="sxs-lookup"><span data-stu-id="88a74-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="88a74-168">Per ogni esecuzione dell'attività di copia, Data Factory determina il numero di copie parallele da usare per copiare i dati dall'archivio dati di origine all'archivio dati di destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="88a74-169">Il numero predefinito di copie parallele usate dipende dal tipo di origine e dal tipo di sink usati.</span><span class="sxs-lookup"><span data-stu-id="88a74-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="88a74-170">Origine e sink</span><span class="sxs-lookup"><span data-stu-id="88a74-170">Source and sink</span></span> | <span data-ttu-id="88a74-171">Numero predefinito di copie parallele determinato dal servizio</span><span class="sxs-lookup"><span data-stu-id="88a74-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="88a74-172">Copia di dati tra archivi basati su file, come archiviazione BLOB, Data Lake Store, Amazon S3, un file system locale, un HDFS locale</span><span class="sxs-lookup"><span data-stu-id="88a74-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="88a74-173">Tra 1 e 32.</span><span class="sxs-lookup"><span data-stu-id="88a74-173">Between 1 and 32.</span></span> <span data-ttu-id="88a74-174">Dipende dalle dimensioni dei file e del numero di unità di spostamento dati cloud usate per copiare dati tra due archivi dati cloud oppure dalla configurazione fisica del computer gateway usato per una copia ibrida, ovvero la copia di dati da o in un archivio dati locale.</span><span class="sxs-lookup"><span data-stu-id="88a74-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="88a74-175">Copia di dati da **qualsiasi archivio dati di origine in un archivio tabelle di Azure**</span><span class="sxs-lookup"><span data-stu-id="88a74-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="88a74-176">4</span><span class="sxs-lookup"><span data-stu-id="88a74-176">4</span></span> |
| <span data-ttu-id="88a74-177">Tutte le altre coppie di origine e sink</span><span class="sxs-lookup"><span data-stu-id="88a74-177">All other source and sink pairs</span></span> |<span data-ttu-id="88a74-178">1</span><span class="sxs-lookup"><span data-stu-id="88a74-178">1</span></span> |

<span data-ttu-id="88a74-179">In genere, il comportamento predefinito dovrebbe garantire la velocità effettiva migliore.</span><span class="sxs-lookup"><span data-stu-id="88a74-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="88a74-180">Tuttavia, per controllare il carico sui computer che ospitano gli archivi dati o per ottimizzare le prestazioni di copia, è possibile scegliere di ignorare il valore predefinito e specificare un valore per la proprietà **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="88a74-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="88a74-181">Il valore deve essere compreso tra 1 e 32, estremi inclusi.</span><span class="sxs-lookup"><span data-stu-id="88a74-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="88a74-182">Per garantire prestazioni ottimali in fase di esecuzione, l'attività di copia usa un valore minore o uguale al valore configurato.</span><span class="sxs-lookup"><span data-stu-id="88a74-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="88a74-183">Punti da notare:</span><span class="sxs-lookup"><span data-stu-id="88a74-183">Points to note:</span></span>

* <span data-ttu-id="88a74-184">Quando si copiano i dati tra archivi basati su file, **parallelCopies** determina il parallelismo a livello di file.</span><span class="sxs-lookup"><span data-stu-id="88a74-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="88a74-185">La suddivisione in blocchi all'interno di un singolo file si verificherebbe sottotraccia in modo automatico e trasparente; tale operazione è pensata per usare la dimensione di blocco più appropriata per un tipo di archivio dati di origine specificato al fine di caricare i dati in maniera parallela e ortogonale a parallelCopies.</span><span class="sxs-lookup"><span data-stu-id="88a74-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="88a74-186">Il numero effettivo di copie parallele usate dal servizio di spostamento dati per l'operazione di copia in fase di esecuzione non è maggiore del numero di file disponibili.</span><span class="sxs-lookup"><span data-stu-id="88a74-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="88a74-187">Se il comportamento di copia è **mergeFile**, l'attività di copia non può usare il parallelismo a livello di file.</span><span class="sxs-lookup"><span data-stu-id="88a74-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="88a74-188">Quando si specifica un valore per la proprietà **parallelCopies** , prendere in considerazione l'aumento del carico per gli archivi dati sink e di origine e per il gateway, se si tratta di una copia ibrida.</span><span class="sxs-lookup"><span data-stu-id="88a74-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="88a74-189">Questo avviene soprattutto quando ci sono più attività o esecuzioni simultanee delle stesse attività che vengono eseguite con lo stesso archivio dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="88a74-190">Se si nota un sovraccarico dell'archivio dati o del gateway, diminuire il valore di **parallelCopies** per alleggerirlo.</span><span class="sxs-lookup"><span data-stu-id="88a74-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="88a74-191">Quando si copiano dati da archivi non basati su file in archivi basati su file, il servizio di spostamento dati ignora la proprietà **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="88a74-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="88a74-192">Anche se viene specificato, in questo caso il parallelismo non viene applicato.</span><span class="sxs-lookup"><span data-stu-id="88a74-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="88a74-193">Per poter usare la funzionalità **parallelCopies** durante una copia ibrida, è necessario usare Gateway di gestione dati 1.11 o versione successiva.</span><span class="sxs-lookup"><span data-stu-id="88a74-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="88a74-194">Per usare al meglio queste due proprietà e per migliorare la velocità effettiva dello spostamento dati, vedere i [casi d'uso di esempio](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="88a74-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="88a74-195">Per usare il comportamento predefinito non è necessario configurare **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="88a74-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="88a74-196">Se si esegue la configurazione e il valore di **parallelCopies** è troppo basso, è possibile che più unità di spostamento dati cloud non vengano utilizzate appieno.</span><span class="sxs-lookup"><span data-stu-id="88a74-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="88a74-197">Impatto della fatturazione</span><span class="sxs-lookup"><span data-stu-id="88a74-197">Billing impact</span></span>
<span data-ttu-id="88a74-198">È **importante** ricordare che l'addebito è basato sul tempo totale impiegato per l'operazione di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="88a74-199">Se un processo di copia impiegava un'ora con una unità cloud e ora richiede 15 minuti con quattro unità cloud, la fattura complessiva rimane pressoché identica.</span><span class="sxs-lookup"><span data-stu-id="88a74-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="88a74-200">Si prenda ad esempio un utilizzo di quattro unità cloud.</span><span class="sxs-lookup"><span data-stu-id="88a74-200">For example, you use four cloud units.</span></span> <span data-ttu-id="88a74-201">La prima unità cloud impiega 10 minuti, la seconda 10 minuti, la terza 5 minuti e la quarta 5 minuti, tutto in un'unica esecuzione dell'attività di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="88a74-202">Verrà addebitato il tempo totale dell'operazione di copia, ovvero di spostamento dei dati, che è pari a 10 + 10 + 5 + 5 = 30 minuti.</span><span class="sxs-lookup"><span data-stu-id="88a74-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="88a74-203">L'uso di **parallelCopies** non influisce sulla fatturazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="88a74-204">copia di staging</span><span class="sxs-lookup"><span data-stu-id="88a74-204">Staged copy</span></span>
<span data-ttu-id="88a74-205">Quando si copiano dati da un archivio dati di origine a un archivio dati sink, è possibile scegliere di usare un archivio BLOB come archivio di staging provvisorio.</span><span class="sxs-lookup"><span data-stu-id="88a74-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="88a74-206">La funzionalità di staging è particolarmente utile nei casi seguenti:</span><span class="sxs-lookup"><span data-stu-id="88a74-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="88a74-207">**Si inseriscono dati da vari archivi dati in SQL Data Warehouse tramite PolyBase**.</span><span class="sxs-lookup"><span data-stu-id="88a74-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="88a74-208">SQL Data Warehouse fa uso di PolyBase come meccanismo a velocità effettiva elevata per il caricamento di grandi quantità di dati in SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="88a74-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="88a74-209">Tuttavia, i dati di origine devono essere in un archivio BLOB e devono soddisfare criteri aggiuntivi.</span><span class="sxs-lookup"><span data-stu-id="88a74-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="88a74-210">Quando si caricano dati da un archivio dati non BLOB, è possibile attivare la copia di dati tramite un archivio BLOB di staging provvisorio.</span><span class="sxs-lookup"><span data-stu-id="88a74-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="88a74-211">In tal caso, Data Factory esegue le trasformazioni di dati necessarie per garantire che vengano soddisfatti i requisiti di PolyBase.</span><span class="sxs-lookup"><span data-stu-id="88a74-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="88a74-212">Quindi usa PolyBase per caricare i dati in SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="88a74-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="88a74-213">Per maggiori dettagli, vedere la sezione [Usare PolyBase per caricare dati in Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="88a74-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="88a74-214">Per la procedura dettagliata con un caso d'uso, vedere [Caricare 1 TB di dati in Azure SQL Data Warehouse in meno di 15 minuti con Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="88a74-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="88a74-215">**A volte occorre tempo per eseguire uno spostamento dati ibrido, ovvero la copia tra un archivio dati locale e un archivio dati cloud, su una connessione di rete lenta**.</span><span class="sxs-lookup"><span data-stu-id="88a74-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="88a74-216">Per migliorare le prestazioni, è possibile comprimere i dati in locale in modo che sia necessario meno tempo per spostare i dati nell'archivio dati di staging nel cloud.</span><span class="sxs-lookup"><span data-stu-id="88a74-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="88a74-217">È quindi possibile decomprimere i dati nell'archivio di staging prima di caricarli nell'archivio dati di destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="88a74-218">**Non si vuole aprire porte diverse dalla porta 80 e dalla porta 443 nel firewall, a causa dei criteri IT aziendali**.</span><span class="sxs-lookup"><span data-stu-id="88a74-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="88a74-219">Ad esempio, quando si copiano dati da un archivio dati locale a un sink del database SQL di Azure o un sink di Azure SQL Data Warehouse, è necessario attivare le comunicazioni TCP in uscita sulla porta 1433 per Windows Firewall e per il firewall aziendale.</span><span class="sxs-lookup"><span data-stu-id="88a74-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="88a74-220">In questo scenario, sfruttare il gateway prima di tutto per copiare i dati in un'istanza di staging dell'archivio BLOB tramite HTTP o HTTPS sulla porta 443.</span><span class="sxs-lookup"><span data-stu-id="88a74-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="88a74-221">Quindi, caricare i dati nel database SQL o in SQL Data Warehouse dall'archivio BLOB di staging.</span><span class="sxs-lookup"><span data-stu-id="88a74-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="88a74-222">In questo flusso non è necessario abilitare la porta 1433.</span><span class="sxs-lookup"><span data-stu-id="88a74-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="88a74-223">Come funziona la copia di staging</span><span class="sxs-lookup"><span data-stu-id="88a74-223">How staged copy works</span></span>
<span data-ttu-id="88a74-224">Quando si attiva la funzionalità di staging, i dati vengono prima copiati dall'archivio dati di origine nell'archivio dati di staging personale.</span><span class="sxs-lookup"><span data-stu-id="88a74-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="88a74-225">Successivamente, vengono copiati dall'archivio dati di staging nell'archivio dati sink.</span><span class="sxs-lookup"><span data-stu-id="88a74-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="88a74-226">Data Factory gestisce automaticamente il flusso in due fasi</span><span class="sxs-lookup"><span data-stu-id="88a74-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="88a74-227">ed elimina i dati temporanei dall'archivio di staging al termine dello spostamento dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="88a74-228">Nello scenario di copia cloud (entrambi gli archivi dati di origine e sink si trovano nel cloud), il gateway non viene usato.</span><span class="sxs-lookup"><span data-stu-id="88a74-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="88a74-229">Il servizio Data Factory esegue le operazioni di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-229">The Data Factory service performs the copy operations.</span></span>

![Copia di staging: scenario cloud](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="88a74-231">Nello scenario di copia ibrido (l'origine è in locale e il sink è nel cloud), il gateway sposta i dati dall'archivio dati di origine a un archivio dati di staging.</span><span class="sxs-lookup"><span data-stu-id="88a74-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="88a74-232">Il servizio di Data Factory sposta i dati dall'archivio dati di staging all'archivio dati sink.</span><span class="sxs-lookup"><span data-stu-id="88a74-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="88a74-233">La copia di dati da un archivio dati cloud in un archivio dati locale tramite la funzionalità di staging è supportata anche con un flusso invertito.</span><span class="sxs-lookup"><span data-stu-id="88a74-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Copia di staging: scenario ibrido](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="88a74-235">Quando si attiva lo spostamento dei dati usando un archivio di staging, è possibile specificare se i dati devono essere compressi prima dello spostamento dall'archivio dati di origine all'archivio dati provvisorio o di staging e poi decompressi prima dello spostamento dall'archivio dati provvisorio o di staging all'archivio dati sink.</span><span class="sxs-lookup"><span data-stu-id="88a74-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="88a74-236">Attualmente non è possibile copiare dati tra due archivi dati locali usando un archivio di staging.</span><span class="sxs-lookup"><span data-stu-id="88a74-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="88a74-237">Questa opzione sarà presto disponibile.</span><span class="sxs-lookup"><span data-stu-id="88a74-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="88a74-238">Configurazione</span><span class="sxs-lookup"><span data-stu-id="88a74-238">Configuration</span></span>
<span data-ttu-id="88a74-239">Configurare l'impostazione **enableStaging** nell'attività di copia per specificare se i dati devono essere inseriti in un archivio BLOB di Azure di staging prima del caricamento in un archivio dati di destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="88a74-240">Se si imposta **enableStaging** su TRUE, specificare le proprietà aggiuntive elencate nella tabella seguente.</span><span class="sxs-lookup"><span data-stu-id="88a74-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="88a74-241">Se non è già disponibile, è necessario creare un servizio collegato alla firma di accesso condiviso di archiviazione o di Archiviazione di Azure per lo staging.</span><span class="sxs-lookup"><span data-stu-id="88a74-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="88a74-242">Proprietà</span><span class="sxs-lookup"><span data-stu-id="88a74-242">Property</span></span> | <span data-ttu-id="88a74-243">Descrizione</span><span class="sxs-lookup"><span data-stu-id="88a74-243">Description</span></span> | <span data-ttu-id="88a74-244">Valore predefinito</span><span class="sxs-lookup"><span data-stu-id="88a74-244">Default value</span></span> | <span data-ttu-id="88a74-245">Obbligatorio</span><span class="sxs-lookup"><span data-stu-id="88a74-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="88a74-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="88a74-246">**enableStaging**</span></span> |<span data-ttu-id="88a74-247">Specificare se si vuole copiare i dati tramite un archivio di staging provvisorio.</span><span class="sxs-lookup"><span data-stu-id="88a74-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="88a74-248">False</span><span class="sxs-lookup"><span data-stu-id="88a74-248">False</span></span> |<span data-ttu-id="88a74-249">No</span><span class="sxs-lookup"><span data-stu-id="88a74-249">No</span></span> |
| <span data-ttu-id="88a74-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="88a74-250">**linkedServiceName**</span></span> |<span data-ttu-id="88a74-251">Specificare il nome di un servizio collegato [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) o [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) che fa riferimento all'istanza di archiviazione usata come archivio di staging provvisorio.</span><span class="sxs-lookup"><span data-stu-id="88a74-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="88a74-252">L'archiviazione non può essere usata con una firma di accesso condiviso per caricare dati in SQL Data Warehouse tramite PolyBase.</span><span class="sxs-lookup"><span data-stu-id="88a74-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="88a74-253">Può essere usata in tutti gli altri scenari.</span><span class="sxs-lookup"><span data-stu-id="88a74-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="88a74-254">N/D</span><span class="sxs-lookup"><span data-stu-id="88a74-254">N/A</span></span> |<span data-ttu-id="88a74-255">Sì, quando **enableStaging** è impostato su TRUE</span><span class="sxs-lookup"><span data-stu-id="88a74-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="88a74-256">**path**</span><span class="sxs-lookup"><span data-stu-id="88a74-256">**path**</span></span> |<span data-ttu-id="88a74-257">Specificare il percorso dell'archivio BLOB che deve contenere i dati di staging.</span><span class="sxs-lookup"><span data-stu-id="88a74-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="88a74-258">Se non si specifica un percorso, il servizio crea un contenitore in cui archiviare i dati temporanei.</span><span class="sxs-lookup"><span data-stu-id="88a74-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="88a74-259">Specificare un percorso solo se si usa l'archiviazione con una firma di accesso condiviso o se i dati temporanei devono trovarsi in un percorso specifico.</span><span class="sxs-lookup"><span data-stu-id="88a74-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="88a74-260">N/D</span><span class="sxs-lookup"><span data-stu-id="88a74-260">N/A</span></span> |<span data-ttu-id="88a74-261">No</span><span class="sxs-lookup"><span data-stu-id="88a74-261">No</span></span> |
| <span data-ttu-id="88a74-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="88a74-262">**enableCompression**</span></span> |<span data-ttu-id="88a74-263">Specifica se è necessario comprimere i dati prima di copiarli nella destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="88a74-264">Questa impostazione ridurre il volume dei dati da trasferire.</span><span class="sxs-lookup"><span data-stu-id="88a74-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="88a74-265">False</span><span class="sxs-lookup"><span data-stu-id="88a74-265">False</span></span> |<span data-ttu-id="88a74-266">No</span><span class="sxs-lookup"><span data-stu-id="88a74-266">No</span></span> |

<span data-ttu-id="88a74-267">Di seguito è riportata una definizione di esempio di attività di copia con le proprietà descritte nella tabella precedente:</span><span class="sxs-lookup"><span data-stu-id="88a74-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="88a74-268">Impatto della fatturazione</span><span class="sxs-lookup"><span data-stu-id="88a74-268">Billing impact</span></span>
<span data-ttu-id="88a74-269">I costi addebitati si basano su due passaggi: durata della copia e tipo di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="88a74-270">Quando si usa la funzionalità di staging durante una copia nel cloud, ovvero la copia di dati da un archivio dati cloud a un altro archivio dati cloud, il costo addebitato sarà [somma della durata della copia per i passaggi 1 e 2] x [prezzo unitario della copia nel cloud].</span><span class="sxs-lookup"><span data-stu-id="88a74-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="88a74-271">Quando si usa la funzionalità di staging durante una copia ibrida, ovvero la copia di dati da un archivio dati locale a un archivio dati cloud, il costo addebitato sarà [durata della copia ibrida] x [prezzo unitario della copia ibrida] + [durata della copia nel cloud] x [prezzo unitario della copia nel cloud].</span><span class="sxs-lookup"><span data-stu-id="88a74-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="88a74-272">Procedura di ottimizzazione delle prestazioni</span><span class="sxs-lookup"><span data-stu-id="88a74-272">Performance tuning steps</span></span>
<span data-ttu-id="88a74-273">Per ottimizzare le prestazioni del servizio Data Factory con l'attività di copia, è consigliabile seguire questa procedura:</span><span class="sxs-lookup"><span data-stu-id="88a74-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="88a74-274">**Stabilire una baseline**.</span><span class="sxs-lookup"><span data-stu-id="88a74-274">**Establish a baseline**.</span></span> <span data-ttu-id="88a74-275">Durante la fase di sviluppo, testare la pipeline usando l'attività di copia su un campione di dati rappresentativo.</span><span class="sxs-lookup"><span data-stu-id="88a74-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="88a74-276">È possibile usare il [modello di sezionamento](data-factory-scheduling-and-execution.md) di Data Factory per limitare la quantità di dati utilizzati.</span><span class="sxs-lookup"><span data-stu-id="88a74-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="88a74-277">Per raccogliere le caratteristiche relative a prestazioni e tempo di esecuzione è possibile usare l' **app di monitoraggio e gestione**.</span><span class="sxs-lookup"><span data-stu-id="88a74-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="88a74-278">Scegliere **Monitoraggio e gestione** nella home page di Data Factory.</span><span class="sxs-lookup"><span data-stu-id="88a74-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="88a74-279">Nella visualizzazione albero scegliere il **set di dati di output**.</span><span class="sxs-lookup"><span data-stu-id="88a74-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="88a74-280">Nell'elenco **Activity Windows** (Finestre attività) scegliere l'esecuzione dell'attività di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="88a74-281">**Activity Windows** (Finestre attività) riporta la durata dell'attività di copia e le dimensioni dei dati copiati.</span><span class="sxs-lookup"><span data-stu-id="88a74-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="88a74-282">La velocità effettiva è elencata in **Activity Window Explorer**(Esplora finestre attività).</span><span class="sxs-lookup"><span data-stu-id="88a74-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="88a74-283">Per altre informazioni sull'app, vedere [Monitorare e gestire le pipeline di Azure Data Factory con la nuova app di monitoraggio e gestione](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="88a74-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Dettagli esecuzione attività](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="88a74-285">È possibile confrontare le prestazioni e la configurazione dello scenario personalizzato con le [informazioni di riferimento sulle prestazioni](#performance-reference) dell'attività di copia ottenute dai test e pubblicate più avanti.</span><span class="sxs-lookup"><span data-stu-id="88a74-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="88a74-286">**Diagnosticare e ottimizzare le prestazioni**.</span><span class="sxs-lookup"><span data-stu-id="88a74-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="88a74-287">Se le prestazioni osservate non soddisfano le aspettative, è necessario identificare gli eventuali colli di bottiglia</span><span class="sxs-lookup"><span data-stu-id="88a74-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="88a74-288">e quindi ottimizzare le prestazioni per rimuovere o ridurre l'effetto dei colli di bottiglia.</span><span class="sxs-lookup"><span data-stu-id="88a74-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="88a74-289">Una descrizione completa della diagnosi delle prestazioni non rientra nell'ambito di questo articolo, ma di seguito sono riportate alcune considerazioni comuni:</span><span class="sxs-lookup"><span data-stu-id="88a74-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="88a74-290">Funzionalità per le prestazioni:</span><span class="sxs-lookup"><span data-stu-id="88a74-290">Performance features:</span></span>
     * [<span data-ttu-id="88a74-291">Copia parallela</span><span class="sxs-lookup"><span data-stu-id="88a74-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="88a74-292">Unità di spostamento dati cloud</span><span class="sxs-lookup"><span data-stu-id="88a74-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="88a74-293">Copia di staging</span><span class="sxs-lookup"><span data-stu-id="88a74-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="88a74-294">Scalabilità di Gateway di gestione dati</span><span class="sxs-lookup"><span data-stu-id="88a74-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="88a74-295">Gateway di gestione dati</span><span class="sxs-lookup"><span data-stu-id="88a74-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="88a74-296">Origine</span><span class="sxs-lookup"><span data-stu-id="88a74-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="88a74-297">Sink</span><span class="sxs-lookup"><span data-stu-id="88a74-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="88a74-298">Serializzazione e deserializzazione</span><span class="sxs-lookup"><span data-stu-id="88a74-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="88a74-299">Compressione</span><span class="sxs-lookup"><span data-stu-id="88a74-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="88a74-300">Mapping di colonne</span><span class="sxs-lookup"><span data-stu-id="88a74-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="88a74-301">Altre considerazioni</span><span class="sxs-lookup"><span data-stu-id="88a74-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="88a74-302">**Espandere la configurazione all'intero set di dati**.</span><span class="sxs-lookup"><span data-stu-id="88a74-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="88a74-303">Dopo aver ottenuto prestazioni e risultati di esecuzione soddisfacenti, è possibile espandere la definizione del set di dati e il periodo attivo della pipeline per coprire l'intero set di dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="88a74-304">Considerazioni su Gateway di gestione dati</span><span class="sxs-lookup"><span data-stu-id="88a74-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="88a74-305">**Configurazione del gateway**: è consigliabile usare un computer dedicato per ospitare Gateway di gestione dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="88a74-306">Vedere [Considerazioni sull'uso di Gateway di gestione dati](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="88a74-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="88a74-307">**Monitoraggio e scalabilità verticale/orizzontale del gateway**: un singolo gateway logico con uno o più nodi del gateway può consentire più esecuzioni di attività di copia contemporaneamente.</span><span class="sxs-lookup"><span data-stu-id="88a74-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="88a74-308">È possibile visualizzare lo snapshot quasi in tempo quasi reale dell'utilizzo delle risorse, ad esempio CPU, memoria, rete (ingresso/uscita) e così via, in un computer gateway oltre che il numero di processi simultanei in esecuzione rispetto ai limiti nel portale di Azure. Vedere [Monitorare il gateway nel portale](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="88a74-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="88a74-309">Se si hanno necessità complesse di spostamento di dati ibridi, con un numero elevato di esecuzioni di attività di copia simultanee o con un volume elevato di dati da copiare, prendere in considerazione la possibilità di [aumentare le prestazioni o sfruttare la scalabilità orizzontale del gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) in modo da utilizzare al meglio la risorsa o effettuare il provisioning di più risorse a supporto della copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="88a74-310">Considerazioni sull'origine</span><span class="sxs-lookup"><span data-stu-id="88a74-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="88a74-311">Generale</span><span class="sxs-lookup"><span data-stu-id="88a74-311">General</span></span>
<span data-ttu-id="88a74-312">Assicurarsi che l'archivio dati sottostante non sia sovraccarico a causa di altri carichi di lavoro in esecuzione in o su di esso.</span><span class="sxs-lookup"><span data-stu-id="88a74-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="88a74-313">Per gli archivi dati Microsoft, vedere gli [argomenti sul monitoraggio e l'ottimizzazione](#performance-reference) specifici degli archivi dati, per comprendere meglio le caratteristiche delle prestazioni degli archivi dati e come ridurre al minimo i tempi di risposta e ottimizzare la velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="88a74-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="88a74-314">Se si copiano dati da un archivio BLOB a SQL Data Warehouse, valutare l'uso di **PolyBase** per migliorare le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="88a74-315">Per altre informazioni, vedere la sezione [Usare PolyBase per caricare dati in Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) .</span><span class="sxs-lookup"><span data-stu-id="88a74-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="88a74-316">Per la procedura dettagliata con un caso d'uso, vedere [Caricare 1 TB di dati in Azure SQL Data Warehouse in meno di 15 minuti con Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="88a74-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="88a74-317">Archivi dati basati su file</span><span class="sxs-lookup"><span data-stu-id="88a74-317">File-based data stores</span></span>
<span data-ttu-id="88a74-318">*Inclusi archiviazione BLOB, Data Lake Store, Amazon S3, file system locali e HDFS locale*</span><span class="sxs-lookup"><span data-stu-id="88a74-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="88a74-319">**Dimensioni medie dei file e numero medio di file**: l'attività di copia trasferisce i dati procedendo un file alla volta.</span><span class="sxs-lookup"><span data-stu-id="88a74-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="88a74-320">Con la stessa quantità di dati da spostare, la velocità effettiva generale risulta inferiore se i dati sono costituiti da un numero elevato di file piccoli anziché da pochi file di grandi dimensioni. Ciò è dovuto alla fase di bootstrap necessaria per ogni file.</span><span class="sxs-lookup"><span data-stu-id="88a74-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="88a74-321">Se possibile, combinare quindi i file piccoli in file più grandi per raggiungere una maggiore velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="88a74-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="88a74-322">**Formato di file e compressione**: per altre informazioni su come migliorare le prestazioni, vedere le sezioni [Considerazioni sulla serializzazione e deserializzazione](#considerations-for-serialization-and-deserialization) e [Considerazioni sulla compressione](#considerations-for-compression).</span><span class="sxs-lookup"><span data-stu-id="88a74-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="88a74-323">Per scenari di **file system locali** in cui è necessario usare **Gateway di gestione dati**, vedere la sezione [Considerazioni su Gateway di gestione dati](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="88a74-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="88a74-324">Archivi dati relazionali</span><span class="sxs-lookup"><span data-stu-id="88a74-324">Relational data stores</span></span>
<span data-ttu-id="88a74-325">*Inclusi database SQL, SQL Data Warehouse, Amazon Redshift, database SQL Server e database Oracle, MySQL, DB2, Teradata, Sybase e PostgreSQL*</span><span class="sxs-lookup"><span data-stu-id="88a74-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="88a74-326">**Modello di dati**: lo schema di tabella influisce sulla velocità effettiva di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="88a74-327">Una riga di grandi dimensioni offre migliori prestazioni rispetto a una riga di piccole dimensioni per copiare la stessa quantità di dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="88a74-328">Questo perché il database è in grado di recuperare in modo più efficiente un minor numero di batch di dati che contengono meno righe.</span><span class="sxs-lookup"><span data-stu-id="88a74-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="88a74-329">**Query o stored procedure**: ottimizzare la logica della query o della stored procedure specificata nell'origine dell'attività di copia per recuperare i dati in modo più efficiente.</span><span class="sxs-lookup"><span data-stu-id="88a74-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="88a74-330">Per i **database relazionali locali** come SQL Server e Oracle, in cui è necessario usare **Gateway di gestione dati**, vedere la sezione [Considerazioni su Gateway di gestione dati](#considerations-on-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="88a74-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="88a74-331">Considerazioni sul sink</span><span class="sxs-lookup"><span data-stu-id="88a74-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="88a74-332">Generale</span><span class="sxs-lookup"><span data-stu-id="88a74-332">General</span></span>
<span data-ttu-id="88a74-333">Assicurarsi che l'archivio dati sottostante non sia sovraccarico a causa di altri carichi di lavoro in esecuzione in o su di esso.</span><span class="sxs-lookup"><span data-stu-id="88a74-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="88a74-334">Per gli archivi dati Microsoft, vedere gli [argomenti sul monitoraggio e l'ottimizzazione](#performance-reference) specifici per gli archivi dati,</span><span class="sxs-lookup"><span data-stu-id="88a74-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="88a74-335">per comprendere meglio le caratteristiche delle prestazioni degli archivi dati e come ridurre al minimo i tempi di risposta e ottimizzare la velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="88a74-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="88a74-336">Se si copiano dati da un **archivio BLOB** a **SQL Data Warehouse**, valutare l'uso di **PolyBase** per migliorare le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="88a74-337">Per altre informazioni, vedere la sezione [Usare PolyBase per caricare dati in Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) .</span><span class="sxs-lookup"><span data-stu-id="88a74-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="88a74-338">Per la procedura dettagliata con un caso d'uso, vedere [Caricare 1 TB di dati in Azure SQL Data Warehouse in meno di 15 minuti con Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="88a74-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="88a74-339">Archivi dati basati su file</span><span class="sxs-lookup"><span data-stu-id="88a74-339">File-based data stores</span></span>
<span data-ttu-id="88a74-340">*Inclusi archiviazione BLOB, Data Lake Store, Amazon S3, file system locali e HDFS locale*</span><span class="sxs-lookup"><span data-stu-id="88a74-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="88a74-341">**Comportamento di copia**: se si copiano dati da un diverso archivio dati basato su file, l'attività di copia fornisce tre tipi di comportamento tramite la proprietà **copyBehavior**,</span><span class="sxs-lookup"><span data-stu-id="88a74-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="88a74-342">mantenere la gerarchia, rendere flat la gerarchia e unire i file.</span><span class="sxs-lookup"><span data-stu-id="88a74-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="88a74-343">Conservare o rendere flat la gerarchia comporta un overhead delle prestazioni minimo, mentre unire i file provoca un aumento dell'overhead delle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="88a74-344">**Formato di file e compressione**: per altre informazioni su come migliorare le prestazioni, vedere le sezioni [Considerazioni sulla serializzazione e deserializzazione](#considerations-for-serialization-and-deserialization) e [Considerazioni sulla compressione](#considerations-for-compression).</span><span class="sxs-lookup"><span data-stu-id="88a74-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="88a74-345">**Archivio BLOB**: attualmente l'archivio BLOB supporta solo i BLOB in blocchi per l'ottimizzazione della velocità effettiva e del trasferimento dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="88a74-346">Per scenari di **file system locali** in cui è necessario usare **Gateway di gestione dati**, vedere la sezione [Considerazioni su Gateway di gestione dati](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="88a74-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="88a74-347">Archivi dati relazionali</span><span class="sxs-lookup"><span data-stu-id="88a74-347">Relational data stores</span></span>
<span data-ttu-id="88a74-348">*Inclusi database SQL, SQL Data Warehouse, database SQL Server e database Oracle*</span><span class="sxs-lookup"><span data-stu-id="88a74-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="88a74-349">**Comportamento di copia**: a seconda delle proprietà configurate per **sqlSink**, l'attività di copia scrive i dati nel database di destinazione in modi diversi.</span><span class="sxs-lookup"><span data-stu-id="88a74-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="88a74-350">Per impostazione predefinita, il servizio di spostamento dati usa l'API per la copia bulk per inserire i dati in modalità Append, che offre le prestazioni migliori.</span><span class="sxs-lookup"><span data-stu-id="88a74-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="88a74-351">Se si configura una stored procedure nel sink, il database applica i dati una riga alla volta anziché come caricamento bulk</span><span class="sxs-lookup"><span data-stu-id="88a74-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="88a74-352">e le prestazioni ne risentono notevolmente.</span><span class="sxs-lookup"><span data-stu-id="88a74-352">Performance drops significantly.</span></span> <span data-ttu-id="88a74-353">Se il set di dati è di grandi dimensioni, valutare l'opportunità di passare a usare la proprietà **sqlWriterCleanupScript**, se applicabile.</span><span class="sxs-lookup"><span data-stu-id="88a74-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="88a74-354">Se si configura la proprietà **sqlWriterCleanupScript** per ogni esecuzione dell'attività di copia, il servizio attiva lo script e quindi usa l'API per la copia bulk per inserire i dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="88a74-355">Ad esempio, per sovrascrivere l'intera tabella con i dati più recenti, è possibile specificare uno script per eliminare tutti i record prima del caricamento bulk dei nuovi dati dall'origine.</span><span class="sxs-lookup"><span data-stu-id="88a74-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="88a74-356">**Modello di dati e dimensioni batch**:</span><span class="sxs-lookup"><span data-stu-id="88a74-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="88a74-357">Lo schema di tabella influisce sulla velocità effettiva di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="88a74-358">Per copiare la stessa quantità di dati, dimensioni di riga grandi offrono prestazioni migliori rispetto a dimensioni di riga piccole, perché il database può eseguire in modo più efficiente il commit di un numero inferiore di batch di dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="88a74-359">L'attività di copia inserisce i dati in una serie di batch.</span><span class="sxs-lookup"><span data-stu-id="88a74-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="88a74-360">Per impostare il numero di righe in un batch è possibile usare la proprietà **writeBatchSize** .</span><span class="sxs-lookup"><span data-stu-id="88a74-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="88a74-361">Se le righe dei dati sono di piccole dimensioni, è possibile impostare la proprietà **writeBatchSize** con un valore più elevato per sfruttare l'overhead di un numero minore di batch e aumentare la velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="88a74-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="88a74-362">Se le righe sono di grandi dimensioni, prestare attenzione quando si aumenta il valore di **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="88a74-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="88a74-363">Un valore elevato può causare un errore di copia dovuto a un sovraccarico del database.</span><span class="sxs-lookup"><span data-stu-id="88a74-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="88a74-364">Per i **database relazionali locali** come SQL Server e Oracle, in cui è necessario usare **Gateway di gestione dati**, vedere la sezione [Considerazioni su Gateway di gestione dati](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="88a74-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="88a74-365">Archivi NoSQL</span><span class="sxs-lookup"><span data-stu-id="88a74-365">NoSQL stores</span></span>
<span data-ttu-id="88a74-366">*Inclusi gli archivi tabelle e Azure Cosmos DB*</span><span class="sxs-lookup"><span data-stu-id="88a74-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="88a74-367">Per gli **archivi tabelle**:</span><span class="sxs-lookup"><span data-stu-id="88a74-367">For **Table storage**:</span></span>
  * <span data-ttu-id="88a74-368">**Partizione**: scrivere i dati nelle partizioni con interleave riduce drasticamente le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="88a74-369">Ordinare i dati di origine per chiave di partizione in modo che i dati vengano inseriti in modo efficiente in una partizione dopo l'altra, oppure è possibile modificare la logica e scrivere i dati in una sola partizione.</span><span class="sxs-lookup"><span data-stu-id="88a74-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="88a74-370">Per **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="88a74-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="88a74-371">**Dimensioni batch**: la proprietà **writeBatchSize** permette di impostare il numero di richieste parallele per la creazione di documenti del servizio Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="88a74-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="88a74-372">Aumentando **writeBatchSize** è possibile prevedere prestazioni migliori, perché vengono inviate più richieste parallele ad Azure Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="88a74-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="88a74-373">Tuttavia, quando si scrive in Azure Cosmos DB è opportuno tenere sotto controllo le limitazioni. Il messaggio di errore è: "La frequenza delle richieste è troppo elevata".</span><span class="sxs-lookup"><span data-stu-id="88a74-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="88a74-374">Le limitazioni possono essere dovute a vari fattori, incluse le dimensioni dei documenti, il numero di termini nei documenti e i criteri di indicizzazione della raccolta di destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="88a74-375">Per ottenere una maggiore velocità effettiva di copia, valutare la possibilità di usare una raccolta più avanzata, ad esempio S3.</span><span class="sxs-lookup"><span data-stu-id="88a74-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="88a74-376">Considerazioni sulla serializzazione e deserializzazione</span><span class="sxs-lookup"><span data-stu-id="88a74-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="88a74-377">Serializzazione e deserializzazione possono verificarsi quando il set di dati di input o il set di dati di output è costituito da un file.</span><span class="sxs-lookup"><span data-stu-id="88a74-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="88a74-378">Per informazioni dettagliate sui formati di file supportati dall'attività di copia vedere [File supportati e formati di compressione](data-factory-supported-file-and-compression-formats.md).</span><span class="sxs-lookup"><span data-stu-id="88a74-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="88a74-379">**Comportamento di copia**:</span><span class="sxs-lookup"><span data-stu-id="88a74-379">**Copy behavior**:</span></span>

* <span data-ttu-id="88a74-380">Copia di file tra archivi dati basati su file:</span><span class="sxs-lookup"><span data-stu-id="88a74-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="88a74-381">Quando i set di dati di input e di output hanno le stesse impostazioni del formato di file o non hanno tali impostazioni, il servizio di spostamento dati esegue una copia binaria senza alcuna serializzazione o deserializzazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="88a74-382">La velocità effettiva è superiore rispetto allo scenario, in cui le impostazioni del formato di file di origine e del sink sono diverse tra loro.</span><span class="sxs-lookup"><span data-stu-id="88a74-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="88a74-383">Quando i set di dati di input e di output sono entrambi in formato testo e solo il tipo di codifica è diverso, il servizio di spostamento esegue solo la conversione della codifica.</span><span class="sxs-lookup"><span data-stu-id="88a74-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="88a74-384">Non esegue alcuna operazione di serializzazione o deserializzazione e questo dà luogo a un certo overhead delle prestazioni rispetto alla copia binaria.</span><span class="sxs-lookup"><span data-stu-id="88a74-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="88a74-385">Quando i set di dati di input e di output hanno entrambi formati di file diversi o configurazioni diverse, ad esempio i delimitatori, il servizio di spostamento dati deserializza i dati di origine per trasmetterli, trasformarli e quindi serializzarli nel formato di output indicato.</span><span class="sxs-lookup"><span data-stu-id="88a74-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="88a74-386">Questa operazione comporta un overhead delle prestazioni decisamente maggiore rispetto ad altri scenari.</span><span class="sxs-lookup"><span data-stu-id="88a74-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="88a74-387">Quando si copiano file da e in un archivio dati che non è basato su file, ad esempio da un archivio basato su file in un archivio relazionale, il passaggio di serializzazione o deserializzazione è necessario.</span><span class="sxs-lookup"><span data-stu-id="88a74-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="88a74-388">Questo passaggio comporta un notevole overhead delle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="88a74-389">**Formato di file**: il formato di file scelto può influire sulle prestazioni di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="88a74-390">Ad esempio, Avro è un formato binario compresso che archivia i metadati con i dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="88a74-391">È ampiamente supportato nell'ecosistema di Hadoop per l'elaborazione e l'esecuzione di query.</span><span class="sxs-lookup"><span data-stu-id="88a74-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="88a74-392">Avro è tuttavia più costoso a livello di serializzazione e deserializzazione e di conseguenza la velocità effettiva di copia risulta inferiore rispetto al formato testo.</span><span class="sxs-lookup"><span data-stu-id="88a74-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="88a74-393">Scegliere il formato di file per tutto il flusso di elaborazione a livello globale.</span><span class="sxs-lookup"><span data-stu-id="88a74-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="88a74-394">Considerare prima di tutto il formato in cui i dati vengono salvati nell'archivio dati di origine o devono essere estratti dai sistemi esterni, il formato migliore per l'archiviazione, l'elaborazione analitica e le query e il formato in cui i dati devono essere esportati nei data mart per gli strumenti di creazione di report e visualizzazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="88a74-395">A volte un formato di file non ottimale dal punto di vista delle prestazioni di lettura e scrittura può invece essere una buona scelta dal punto di vista del processo analitico generale.</span><span class="sxs-lookup"><span data-stu-id="88a74-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="88a74-396">Considerazioni sulla compressione</span><span class="sxs-lookup"><span data-stu-id="88a74-396">Considerations for compression</span></span>
<span data-ttu-id="88a74-397">Quando il set di dati di input o di output è un file, è possibile impostare l'attività di copia per l'esecuzione della compressione o decompressione durante la scrittura dei dati nella destinazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="88a74-398">La scelta della compressione comporta un compromesso tra input/output (I/O) e CPU.</span><span class="sxs-lookup"><span data-stu-id="88a74-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="88a74-399">La compressione dei dati ha un costo maggiore in termini di risorse di calcolo,</span><span class="sxs-lookup"><span data-stu-id="88a74-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="88a74-400">ma riduce l'I/O di rete e l'archiviazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="88a74-401">A seconda dei dati, si potrebbe riscontrare un aumento della velocità effettiva di copia complessiva.</span><span class="sxs-lookup"><span data-stu-id="88a74-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="88a74-402">**Codec**: l'attività di copia supporta i tipi di compressione gzip, bzip2 e Deflate.</span><span class="sxs-lookup"><span data-stu-id="88a74-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="88a74-403">Azure HDInsight può utilizzare tutti e tre i tipi per l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="88a74-404">Ogni codec di compressione presenta dei vantaggi.</span><span class="sxs-lookup"><span data-stu-id="88a74-404">Each compression codec has advantages.</span></span> <span data-ttu-id="88a74-405">Ad esempio, bzip2 ha la velocità effettiva copia più bassa, ma offre prestazioni di query Hive migliori perché permette di dividerle per l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="88a74-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="88a74-406">Gzip è l'opzione più bilanciata e quella usata più di frequente.</span><span class="sxs-lookup"><span data-stu-id="88a74-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="88a74-407">Scegliere il codec più adatto allo scenario end-to-end personalizzato.</span><span class="sxs-lookup"><span data-stu-id="88a74-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="88a74-408">**Livello**: per ogni codec di compressione è possibile scegliere tra due opzioni, la compressione più veloce e la compressione ottimale.</span><span class="sxs-lookup"><span data-stu-id="88a74-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="88a74-409">L'opzione di compressione più veloce comprime i dati il più rapidamente possibile, anche se il file risultante non viene compresso in modo ottimale.</span><span class="sxs-lookup"><span data-stu-id="88a74-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="88a74-410">L'opzione di compressione ottimale impiega più tempo per la compressione e restituisce una quantità minima di dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="88a74-411">È possibile testare entrambe le opzioni per verificare quale offra le migliori prestazioni complessive in base alle proprie esigenze.</span><span class="sxs-lookup"><span data-stu-id="88a74-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="88a74-412">**Una considerazione**: per copiare una grande quantità di dati tra un archivio locale e il cloud, è consigliabile usare un archivio BLOB provvisorio e la compressione.</span><span class="sxs-lookup"><span data-stu-id="88a74-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="88a74-413">L'uso di un archivio provvisorio risulta utile quando la larghezza di banda della rete aziendale e i servizi di Azure pongono dei limiti e i set di dati di input e di output devono essere in formato non compresso.</span><span class="sxs-lookup"><span data-stu-id="88a74-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="88a74-414">In particolare, è possibile dividere un'attività di copia singola in due attività di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="88a74-415">La prima copia dall'origine in un BLOB di staging o provvisorio in formato compresso.</span><span class="sxs-lookup"><span data-stu-id="88a74-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="88a74-416">La seconda copia i dati compressi dal BLOB di staging e li decomprime durante la scrittura nel sink.</span><span class="sxs-lookup"><span data-stu-id="88a74-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="88a74-417">Considerazioni sul mapping di colonne</span><span class="sxs-lookup"><span data-stu-id="88a74-417">Considerations for column mapping</span></span>
<span data-ttu-id="88a74-418">È possibile impostare la proprietà **columnMappings** nell'attività di copia perché venga eseguito il mapping di tutte o di un subset delle colonne di input alle colonne di output.</span><span class="sxs-lookup"><span data-stu-id="88a74-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="88a74-419">Dopo aver letto i dati dall'origine, il servizio di spostamento dati deve eseguire il mapping delle colonne sui dati prima di scriverli nel sink.</span><span class="sxs-lookup"><span data-stu-id="88a74-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="88a74-420">Questa ulteriore elaborazione riduce la velocità effettiva di copia.</span><span class="sxs-lookup"><span data-stu-id="88a74-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="88a74-421">Se l'archivio dati di origine è disponibile per query, ad esempio nel caso di un archivio relazionale come il database SQL o SQL Server, oppure nel caso di un archivio NoSQL come un archivio tabelle o Azure Cosmos DB, è consigliabile eseguire il push della logica di filtro e riordinamento colonne per la proprietà **query** anziché usare il mapping colonne.</span><span class="sxs-lookup"><span data-stu-id="88a74-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="88a74-422">In questo modo la proiezione si verifica quando il servizio di spostamento dati legge i dati dall'archivio dati di origine, in cui è molto più efficiente.</span><span class="sxs-lookup"><span data-stu-id="88a74-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="88a74-423">Altre considerazioni</span><span class="sxs-lookup"><span data-stu-id="88a74-423">Other considerations</span></span>
<span data-ttu-id="88a74-424">Se i dati da copiare sono di grandi dimensioni, è possibile modificare la logica di business per partizionare ulteriormente i dati usando il meccanismo di sezionamento in Data Factory.</span><span class="sxs-lookup"><span data-stu-id="88a74-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="88a74-425">Quindi, pianificare esecuzioni più frequenti dell'attività di copia per ridurre le dimensioni dei dati per ogni singola esecuzione.</span><span class="sxs-lookup"><span data-stu-id="88a74-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="88a74-426">Prestare attenzione al numero di set di dati e di attività di copia che richiedono la connessione di Data Factory allo stesso archivio dati nello stesso momento.</span><span class="sxs-lookup"><span data-stu-id="88a74-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="88a74-427">Molti processi di copia simultanei possono limitare un archivio dati e causare un peggioramento delle prestazioni, nuovi tentativi interni dei processi di copia e, in alcuni casi, errori di esecuzione.</span><span class="sxs-lookup"><span data-stu-id="88a74-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="88a74-428">Scenario di esempio: copiare da un'istanza locale di SQL Server in un archivio BLOB</span><span class="sxs-lookup"><span data-stu-id="88a74-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="88a74-429">**Scenario**: viene compilata una pipeline per copiare dati da un'istanza locale di SQL Server in un archivio BLOB in formato CSV.</span><span class="sxs-lookup"><span data-stu-id="88a74-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="88a74-430">Per velocizzare il processo di copia, i file CSV devono essere compressi in formato bzip2.</span><span class="sxs-lookup"><span data-stu-id="88a74-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="88a74-431">**Test e analisi**: la velocità effettiva dell'attività di copia è inferiore a 2 Mbps ed è molto inferiore al benchmark delle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="88a74-432">**Analisi e ottimizzazione delle prestazioni**: per risolvere il problema delle prestazioni, occorre vedere prima di tutto come vengono elaborati e spostati i dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="88a74-433">**Lettura dei dati**: il gateway apre una connessione a SQL Server e invia la query.</span><span class="sxs-lookup"><span data-stu-id="88a74-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="88a74-434">SQL Server risponde inviando il flusso di dati al gateway tramite Intranet.</span><span class="sxs-lookup"><span data-stu-id="88a74-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="88a74-435">**Serializzazione e compressione dei dati**: il gateway serializza il flusso dei dati in formato CSV e comprime i dati in un flusso bzip2.</span><span class="sxs-lookup"><span data-stu-id="88a74-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="88a74-436">**Scrittura dei dati**: il gateway carica il flusso bzip2 nell'archivio BLOB tramite Internet.</span><span class="sxs-lookup"><span data-stu-id="88a74-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="88a74-437">Come si può notare, i dati vengono elaborati e spostati in base a un flusso sequenziale: SQL Server > LAN > Gateway > WAN > archivio BLOB.</span><span class="sxs-lookup"><span data-stu-id="88a74-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="88a74-438">**Le prestazioni complessive vengono controllate dalla velocità effettiva minima in tutta la pipeline**.</span><span class="sxs-lookup"><span data-stu-id="88a74-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Flusso di dati](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="88a74-440">Uno o più dei fattori seguenti possono provocare un collo di bottiglia nelle prestazioni:</span><span class="sxs-lookup"><span data-stu-id="88a74-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="88a74-441">**Origine**: SQL Server ha di per sé una velocità effettiva bassa a causa dei carichi elevati.</span><span class="sxs-lookup"><span data-stu-id="88a74-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="88a74-442">**Gateway di gestione dati**:</span><span class="sxs-lookup"><span data-stu-id="88a74-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="88a74-443">**LAN**: il gateway è distante da SQL Server con una connessione a larghezza di banda bassa.</span><span class="sxs-lookup"><span data-stu-id="88a74-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="88a74-444">**Gateway**: il gateway ha raggiunto i relativi limiti di carico per eseguire queste operazioni:</span><span class="sxs-lookup"><span data-stu-id="88a74-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="88a74-445">**Serializzazione**: la serializzazione del flusso di dati in formato CSV ha una velocità effettiva bassa.</span><span class="sxs-lookup"><span data-stu-id="88a74-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="88a74-446">**Compressione**: si è scelto un codec di compressione lenta, ad esempio bzip2 a 2,8 Mbps con core i7.</span><span class="sxs-lookup"><span data-stu-id="88a74-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="88a74-447">**WAN**: la larghezza di banda tra la rete aziendale e i servizi di Azure è bassa, ad esempio T1 = 1.544 Kbps e T2 = 6.312 Kbps.</span><span class="sxs-lookup"><span data-stu-id="88a74-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="88a74-448">**Sink**: l'archivio BLOB ha una velocità effettiva bassa.</span><span class="sxs-lookup"><span data-stu-id="88a74-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="88a74-449">Questo scenario è poco probabile perché il relativo contratto di servizio garantisce un minimo di 60 Mbps.</span><span class="sxs-lookup"><span data-stu-id="88a74-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="88a74-450">In tal caso, la compressione dati bzip2 potrebbe rallentare l'intera pipeline.</span><span class="sxs-lookup"><span data-stu-id="88a74-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="88a74-451">Il passaggio al codec di compressione gzip può ridurre questo collo di bottiglia.</span><span class="sxs-lookup"><span data-stu-id="88a74-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="88a74-452">Scenari di esempio: usare la copia parallela</span><span class="sxs-lookup"><span data-stu-id="88a74-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="88a74-453">**Scenario I** : copiare 1.000 file da 1 MB dal file system locale nell'archivio BLOB.</span><span class="sxs-lookup"><span data-stu-id="88a74-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="88a74-454">**Analisi e ottimizzazione delle prestazioni**: si supponga di aver installato il gateway in un computer quad-core. Data Factory usa 16 copie parallele per spostare simultaneamente i file dal file system all'archivio BLOB.</span><span class="sxs-lookup"><span data-stu-id="88a74-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="88a74-455">L'esecuzione parallela deve garantire una velocità effettiva elevata.</span><span class="sxs-lookup"><span data-stu-id="88a74-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="88a74-456">È anche possibile specificare in modo esplicito il numero di copie parallele.</span><span class="sxs-lookup"><span data-stu-id="88a74-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="88a74-457">Quando si copiano molti file di piccole dimensioni, le copie parallele migliorano notevolmente la velocità effettiva garantendo un uso più efficiente delle risorse.</span><span class="sxs-lookup"><span data-stu-id="88a74-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Scenario 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="88a74-459">**Scenario II**: copiare 20 BLOB da 500 MB dall'archivio BLOB in Data Lake Store Analytics e ottimizzare le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="88a74-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="88a74-460">**Analisi e ottimizzazione delle prestazioni**: in questo scenario Data Factory copia i dati dall'archivio BLOB in Data Lake Store tramite copia singola, con **parallelCopies** impostato su 1, e unità di spostamento dati cloud singole.</span><span class="sxs-lookup"><span data-stu-id="88a74-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="88a74-461">La velocità effettiva osservata si avvicinerà ai valori indicati nella sezione [Informazioni di riferimento sulle prestazioni](#performance-reference)precedente.</span><span class="sxs-lookup"><span data-stu-id="88a74-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Scenario 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="88a74-463">**Scenario III**: i singoli file hanno grandi dimensioni e il volume totale molto elevato.</span><span class="sxs-lookup"><span data-stu-id="88a74-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="88a74-464">**Analisi e ottimizzazione delle prestazioni**: l'aumento di **parallelCopies** non permette di migliorare le prestazioni di copia a causa dei limiti previsti per le risorse di una unità di spostamento dati cloud singola.</span><span class="sxs-lookup"><span data-stu-id="88a74-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="88a74-465">È invece necessario specificare altre unità di spostamento dati cloud per ottenere più risorse ed eseguire lo spostamento dati.</span><span class="sxs-lookup"><span data-stu-id="88a74-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="88a74-466">Non specificare un valore per la proprietà **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="88a74-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="88a74-467">Il parallelismo è gestito da Data Factory.</span><span class="sxs-lookup"><span data-stu-id="88a74-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="88a74-468">Se, in questo caso, si imposta **cloudDataMovementUnits** su 4, è possibile ottenere una velocità effettiva di circa quattro volte superiore.</span><span class="sxs-lookup"><span data-stu-id="88a74-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Scenario 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="88a74-470">Riferimenti</span><span class="sxs-lookup"><span data-stu-id="88a74-470">Reference</span></span>
<span data-ttu-id="88a74-471">Di seguito sono riportati alcuni riferimenti sul monitoraggio e l'ottimizzazione delle prestazioni per alcuni degli archivi dati supportati:</span><span class="sxs-lookup"><span data-stu-id="88a74-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="88a74-472">Archiviazione di Azure, inclusi archivi BLOB e archivi tabelle: [Obiettivi di scalabilità e prestazioni per Archiviazione di Azure](../storage/common/storage-scalability-targets.md) ed [Elenco di controllo di prestazioni e scalabilità per Archiviazione di Microsoft Azure](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="88a74-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="88a74-473">Database SQL di Azure: è possibile [monitorare le prestazioni](../sql-database/sql-database-single-database-monitor.md) e controllare la percentuale di DTU (Database Transaction Unit).</span><span class="sxs-lookup"><span data-stu-id="88a74-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="88a74-474">Azure SQL Data Warehouse: la funzionalità viene misurata in unità data warehouse (DWU). Vedere in proposito [Gestire la potenza di calcolo in Azure SQL Data Warehouse (Panoramica)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="88a74-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="88a74-475">Azure Cosmos DB: [livelli di prestazioni in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="88a74-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="88a74-476">SQL Server locale: [Monitoraggio e ottimizzazione delle prestazioni](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="88a74-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="88a74-477">File server locale: [Performance Tuning for File Servers](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="88a74-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
