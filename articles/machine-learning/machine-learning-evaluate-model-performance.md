---
title: Valutare le prestazioni del modello in Machine Learning | Documentazione Microsoft
description: Viene spiegato come valutare le prestazioni del modello in Azure Machine Learning.
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="93706-103">Come valutare le prestazioni del modello in Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="93706-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="93706-104">Questo articolo illustra come valutare le prestazioni di un modello in Azure Machine Learning Studio e offre una breve spiegazione delle metriche disponibili per questa attività.</span><span class="sxs-lookup"><span data-stu-id="93706-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="93706-105">L'argomento presenta inoltre tre scenari di apprendimento sorvegliato comuni:</span><span class="sxs-lookup"><span data-stu-id="93706-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="93706-106">Regressione</span><span class="sxs-lookup"><span data-stu-id="93706-106">regression</span></span>
* <span data-ttu-id="93706-107">Classificazione binaria</span><span class="sxs-lookup"><span data-stu-id="93706-107">binary classification</span></span> 
* <span data-ttu-id="93706-108">Classificazione multiclasse</span><span class="sxs-lookup"><span data-stu-id="93706-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="93706-109">La valutazione delle prestazioni di un modello è una delle fasi principali nel processo di analisi scientifica dei dati.</span><span class="sxs-lookup"><span data-stu-id="93706-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="93706-110">Indica quanto è stato positivo il punteggio (stime) di un set di dati da un modello sottoposto a training.</span><span class="sxs-lookup"><span data-stu-id="93706-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="93706-111">Azure Machine Learning supporta la valutazione del modello tramite due moduli di apprendimento automatico principali, ovvero [Evaluate Model][evaluate-model] e [Cross-Validate Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="93706-112">Questi moduli consentono all'utente di osservare le prestazioni del proprio modello in termini di una serie di metriche comunemente usate in Machine Learning e nella statistica.</span><span class="sxs-lookup"><span data-stu-id="93706-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="93706-113">Confronto tra la valutazione e la convalida incrociata</span><span class="sxs-lookup"><span data-stu-id="93706-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="93706-114">La valutazione e la convalida incrociata sono due modi standard di misurare le prestazioni del proprio modello.</span><span class="sxs-lookup"><span data-stu-id="93706-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="93706-115">Entrambi generano metriche di valutazione che l'utente può usare per controllare o mettere a confronto quelle di altri modelli.</span><span class="sxs-lookup"><span data-stu-id="93706-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="93706-116">Il modulo [Evaluate Model][evaluate-model] presuppone l'esistenza di un set di dati con punteggio come input (oppure di due set di dati se si desidera confrontare le prestazioni di due modelli diversi).</span><span class="sxs-lookup"><span data-stu-id="93706-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="93706-117">Ciò significa che, prima di valutare i risultati, è necessario eseguire il training del modello con il modulo [Train Model][train-model] ed eseguire stime su alcuni set di dati con il modulo [Score Model][score-model].</span><span class="sxs-lookup"><span data-stu-id="93706-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="93706-118">La valutazione è basata sulle probabilità/etichette con punteggio e sulle etichette vere, tutti elementi restituiti dal modulo [Score Model][score-model].</span><span class="sxs-lookup"><span data-stu-id="93706-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="93706-119">In alternativa, è possibile usare la convalida incrociata per eseguire una serie di operazioni di valutazione, punteggio e training (10 sezioni) in modo automatico su diversi subset di dati di input.</span><span class="sxs-lookup"><span data-stu-id="93706-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="93706-120">I dati di input vengono suddivisi in dieci partizioni, di cui una riservata per la convalida e le rimanenti usate per eseguire il training.</span><span class="sxs-lookup"><span data-stu-id="93706-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="93706-121">Tale processo si ripete per 10 volte e viene calcolata una media delle metriche di valutazione.</span><span class="sxs-lookup"><span data-stu-id="93706-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="93706-122">Ciò consente di determinare come verrebbero generalizzati nuovi set di dati da un modello.</span><span class="sxs-lookup"><span data-stu-id="93706-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="93706-123">Il modulo [Cross-Validate Model][cross-validate-model] riceve in input un modello non sottoposto a training e alcuni set di dati con etichetta e restituisce i risultati della valutazione di ognuna delle 10 sezioni, oltre alla media dei risultati.</span><span class="sxs-lookup"><span data-stu-id="93706-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="93706-124">Nelle sezioni seguenti verranno creati semplici modelli di regressione e classificazione e ne verranno valutate le prestazioni usando i moduli [Evaluate Model][evaluate-model] e [Cross-Validate Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="93706-125">Valutazione di un modello di regressione</span><span class="sxs-lookup"><span data-stu-id="93706-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="93706-126">Si supponga di voler stimare il prezzo di un'auto tramite alcune caratteristiche quali dimensioni, cavalli, specifiche del motore e così via.</span><span class="sxs-lookup"><span data-stu-id="93706-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="93706-127">Si tratta di un tipico problema di regressione, in cui la variabile di destinazione (*price*) è un valore numerico continuo.</span><span class="sxs-lookup"><span data-stu-id="93706-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="93706-128">È possibile preparare un modello di regressione lineare semplice che, dati i valori caratteristici di una determinata auto, sia in grado di fare una stima del prezzo di tale auto.</span><span class="sxs-lookup"><span data-stu-id="93706-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="93706-129">Questo modello di regressione può essere usato per calcolare il punteggio dello stesso set di dati su cui si sta effettuando il training</span><span class="sxs-lookup"><span data-stu-id="93706-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="93706-130">Una volta ottenuti i prezzi stimati per tutte le auto, è possibile valutare le prestazioni del modello osservando la differenza tra le stime e i prezzi reali in media.</span><span class="sxs-lookup"><span data-stu-id="93706-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="93706-131">Per illustrare questo concetto, si usa il set di dati *Automobile price data (Raw)* disponibile nella sezione **Saved Datasets** (Set di dati salvati) in Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="93706-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="93706-132">Creazione di un esperimento</span><span class="sxs-lookup"><span data-stu-id="93706-132">Creating the Experiment</span></span>
<span data-ttu-id="93706-133">Aggiungere i seguenti moduli all'area di lavoro in Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="93706-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="93706-134">Automobile price data (Raw)</span><span class="sxs-lookup"><span data-stu-id="93706-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="93706-135">[Linear Regression][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="93706-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="93706-136">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="93706-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="93706-137">[Score Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="93706-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="93706-138">[Evaluate Model][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="93706-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="93706-139">Connettere le porte come indicato nella figura 1 seguente e impostare la colonna delle etichette nel modulo [Train Model][train-model] su *price*.</span><span class="sxs-lookup"><span data-stu-id="93706-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![Valutazione di un modello di regressione](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="93706-141">Figura 1.</span><span class="sxs-lookup"><span data-stu-id="93706-141">Figure 1.</span></span> <span data-ttu-id="93706-142">Valutazione di un modello di regressione.</span><span class="sxs-lookup"><span data-stu-id="93706-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="93706-143">Controllo dei risultati di valutazione</span><span class="sxs-lookup"><span data-stu-id="93706-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="93706-144">Dopo aver eseguito l'esperimento, è possibile fare clic sulla porta di output del modulo [Evaluate Model][evaluate-model] e selezionare *Visualize* (Visualizza) per visualizzare i risultati della valutazione.</span><span class="sxs-lookup"><span data-stu-id="93706-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="93706-145">Le metriche di valutazione disponibili per i modelli di regressione sono: *Mean Absolute Error* (Errore assoluto medio), *Root Mean Absolute Error* (Errore assoluto medio radice), *Relative Absolute Error* (Errore assoluto relativo), *Relative Squared Error* (Errore quadratico relativo) e *Coefficient of Determination* (Coefficiente di determinazione).</span><span class="sxs-lookup"><span data-stu-id="93706-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="93706-146">In questo caso, il termine "errore" rappresenta la differenza tra il valore stimato e il valore reale.</span><span class="sxs-lookup"><span data-stu-id="93706-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="93706-147">Il valore assoluto o il quadrato di tale differenza solitamente vengono calcolati per ottenere il margine totale dell'errore in tutte le istanze, poiché la differenza tra il valore stimato e quello reale potrebbe essere negativa in alcuni casi.</span><span class="sxs-lookup"><span data-stu-id="93706-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="93706-148">Le metriche di errore misurano le prestazioni predittive di un modello di regressione in termini di deviazione media delle stime rispetto ai valori reali.</span><span class="sxs-lookup"><span data-stu-id="93706-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="93706-149">Più i valori di errore sono bassi, più il modello effettua stime precise.</span><span class="sxs-lookup"><span data-stu-id="93706-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="93706-150">Una metrica di errore complessivo pari a 0 indica che il modello corrisponde perfettamente ai dati.</span><span class="sxs-lookup"><span data-stu-id="93706-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="93706-151">Il coefficiente di determinazione, altrimenti noto come "valore quadratico R", rappresenta, inoltre, un modo standard di misurazione della percentuale di idoneità del modello rispetto ai dati.</span><span class="sxs-lookup"><span data-stu-id="93706-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="93706-152">Può essere definito come la percentuale di variazione esplicitata dal modello.</span><span class="sxs-lookup"><span data-stu-id="93706-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="93706-153">Una percentuale più elevata è migliore nel caso in cui 1 indica un'idoneità perfetta.</span><span class="sxs-lookup"><span data-stu-id="93706-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![Metriche di valutazione della regressione lineare](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="93706-155">Figura 2.</span><span class="sxs-lookup"><span data-stu-id="93706-155">Figure 2.</span></span> <span data-ttu-id="93706-156">Metriche di valutazione della regressione lineare.</span><span class="sxs-lookup"><span data-stu-id="93706-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="93706-157">Uso della convalida incrociata</span><span class="sxs-lookup"><span data-stu-id="93706-157">Using Cross Validation</span></span>
<span data-ttu-id="93706-158">Come accennato in precedenza, è possibile ripetere il training, l'assegnazione del punteggio e le valutazioni in modo automatico usando il modulo [Cross-Validate Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="93706-159">In questo caso occorrono semplicemente un set di dati, un modello non sottoposto a training e un modulo [Cross-Validate Model][cross-validate-model] (vedere la figura seguente).</span><span class="sxs-lookup"><span data-stu-id="93706-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="93706-160">Si noti che è necessario impostare la colonna delle etichette su *price* nelle proprietà del modulo [Cross-Validate Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![Convalida incrociata di un modello di regressione](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="93706-162">Figura 3.</span><span class="sxs-lookup"><span data-stu-id="93706-162">Figure 3.</span></span> <span data-ttu-id="93706-163">Esecuzione della convalida incrociata di un modello di regressione.</span><span class="sxs-lookup"><span data-stu-id="93706-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="93706-164">Dopo aver eseguito l'esperimento, è possibile fare clic sulla porta di output destra del modulo [Cross-Validate Model][cross-validate-model] per controllare i risultati della valutazione.</span><span class="sxs-lookup"><span data-stu-id="93706-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="93706-165">In questo modo viene fornita una visualizzazione dettagliata delle metriche di ciascuna iterazione (sezione) e i risultati medi di ciascuna delle metriche (figura 4).</span><span class="sxs-lookup"><span data-stu-id="93706-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![Risultati della convalida incrociata di un modello di regressione](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="93706-167">Figura 4.</span><span class="sxs-lookup"><span data-stu-id="93706-167">Figure 4.</span></span> <span data-ttu-id="93706-168">Risultati della convalida incrociata di un modello di regressione.</span><span class="sxs-lookup"><span data-stu-id="93706-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="93706-169">Valutazione di un modello di classificazione binaria</span><span class="sxs-lookup"><span data-stu-id="93706-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="93706-170">In uno scenario di classificazione binaria la variabile di destinazione ha solo due risultati possibili, ad esempio: {0, 1} o {false, true}, {negative, positive}.</span><span class="sxs-lookup"><span data-stu-id="93706-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="93706-171">Si presupponga di ricevere un set di dati di un dipendente adulto con alcune variabili demografiche e occupazionali e di dover stimare il livello di reddito, una variabile binaria con i valori {"<=50.000", ">50.000"}.</span><span class="sxs-lookup"><span data-stu-id="93706-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="93706-172">In altri termini, la classe negativa rappresenta il caso in cui il dipendente realizza un valore inferiore o uguale a 50.000 l'anno, mentre la classe positiva rappresenta tutti gli altri dipendenti.</span><span class="sxs-lookup"><span data-stu-id="93706-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="93706-173">Come nello scenario della regressione, verrà eseguito il training di un modello, verrà calcolato il punteggio di alcuni dati e verranno valutati i risultati.</span><span class="sxs-lookup"><span data-stu-id="93706-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="93706-174">In questo caso la differenza principale consiste nella scelta degli output e dei calcoli delle metriche in Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="93706-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="93706-175">Per illustrare lo scenario della stima del livello di reddito, verrà usato il set di dati [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) per creare un esperimento in Azure Machine Learning e valutare le prestazioni di un modello di regressione logistica a due classi, un classificatore binario comunemente usato.</span><span class="sxs-lookup"><span data-stu-id="93706-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="93706-176">Creazione di un esperimento</span><span class="sxs-lookup"><span data-stu-id="93706-176">Creating the Experiment</span></span>
<span data-ttu-id="93706-177">Aggiungere i seguenti moduli all'area di lavoro in Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="93706-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="93706-178">Adult Census Income Binary Classification dataset</span><span class="sxs-lookup"><span data-stu-id="93706-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="93706-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="93706-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="93706-180">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="93706-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="93706-181">[Score Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="93706-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="93706-182">[Evaluate Model][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="93706-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="93706-183">Connettere le porte come indicato nella figura 5 seguente e impostare la colonna delle etichette del modulo [Train Model][train-model] su *income*.</span><span class="sxs-lookup"><span data-stu-id="93706-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![Valutazione di un modello di classificazione binaria](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="93706-185">Figura 5.</span><span class="sxs-lookup"><span data-stu-id="93706-185">Figure 5.</span></span> <span data-ttu-id="93706-186">Valutazione di un modello di classificazione binaria.</span><span class="sxs-lookup"><span data-stu-id="93706-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="93706-187">Controllo dei risultati di valutazione</span><span class="sxs-lookup"><span data-stu-id="93706-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="93706-188">Dopo aver eseguito l'esperimento, è possibile fare clic sulla porta di output del modulo [Evaluate Model][evaluate-model] e selezionare *Visualize* (Visualizza) per visualizzare i risultati della valutazione (Figura 7).</span><span class="sxs-lookup"><span data-stu-id="93706-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="93706-189">Le metriche di valutazione disponibili per i modelli di classificazione binaria sono: *Accuracy* (Accuratezza), *Precision* (Precisione), *Recall* (Richiamo), *F1 Score* (Punteggio F1) e *AUC*.</span><span class="sxs-lookup"><span data-stu-id="93706-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="93706-190">Il modulo restituisce anche una matrice di confusione che mostra il numero di veri positivi, falsi negativi, falsi positivi e veri negativi, nonché le curve *ROC*, *Precision/Recall* (Precisione/Richiamo) e *Lift* (Accuratezza).</span><span class="sxs-lookup"><span data-stu-id="93706-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="93706-191">L'accuratezza è semplicemente la percentuale delle istanze classificate correttamente.</span><span class="sxs-lookup"><span data-stu-id="93706-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="93706-192">In genere è la prima metrica che viene osservata quando si valuta un classificatore.</span><span class="sxs-lookup"><span data-stu-id="93706-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="93706-193">Tuttavia, quando i dati di test non sono bilanciati (se la maggior parte delle istanze appartiene a una delle classi) o se l'utente è più interessato alle prestazioni di una classe, l'accuratezza non mostra realmente l'efficacia di un classificatore.</span><span class="sxs-lookup"><span data-stu-id="93706-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="93706-194">Nello scenario di classificazione del livello di reddito, si supponga di eseguire il test di alcuni dati in cui il 99% delle istanze rappresenta le persone che guadagnano una cifra inferiore o uguale a 50.000 l'anno.</span><span class="sxs-lookup"><span data-stu-id="93706-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="93706-195">È possibile ottenere un'accuratezza pari a 0,99 facendo una stima della classe “<=50.000” per tutte le istanze.</span><span class="sxs-lookup"><span data-stu-id="93706-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="93706-196">In questo caso sembra che il classificatore svolga un buon lavoro in linea generale, ma in realtà non è in grado di classificare correttamente gli individui con un reddito superiore (il restante 1%).</span><span class="sxs-lookup"><span data-stu-id="93706-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="93706-197">Per questo motivo è utile calcolare metriche aggiuntive che raccolgano aspetti più specifici della valutazione.</span><span class="sxs-lookup"><span data-stu-id="93706-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="93706-198">Prima di entrare nei dettagli di tali metriche, è importante comprendere la matrice di confusione della valutazione di una classificazione binaria.</span><span class="sxs-lookup"><span data-stu-id="93706-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="93706-199">Le etichette delle classi nel set di training possono assumere solo 2 valori possibili, cui faremo riferimento con positivo o negativo.</span><span class="sxs-lookup"><span data-stu-id="93706-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="93706-200">Le istanze positive e negative stimate correttamente da un classificatore si definiscono rispettivamente valori veri positivi (VP) e veri negativi (VN).</span><span class="sxs-lookup"><span data-stu-id="93706-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="93706-201">Analogamente, le istanze classificate in modo errato si definiscono valori falsi positivi (FP) e falsi negativi (FN).</span><span class="sxs-lookup"><span data-stu-id="93706-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="93706-202">La matrice di confusione è semplicemente una tabella che mostra il numero di istanze all'interno di ognuna di queste 4 categorie.</span><span class="sxs-lookup"><span data-stu-id="93706-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="93706-203">Azure Machine Learning stabilisce automaticamente quale delle due classi nel set di dati è quella positiva.</span><span class="sxs-lookup"><span data-stu-id="93706-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="93706-204">Se le etichette delle classi sono valori booleani o interi, le istanze con etichetta "true" o "1" vengono assegnate alla classe positiva.</span><span class="sxs-lookup"><span data-stu-id="93706-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="93706-205">Se si tratta di stringhe, come nel caso del set di dati sul reddito, le etichette vengono ordinate alfabeticamente: il primo livello sarà la classe negativa, mentre il secondo livello quella positiva.</span><span class="sxs-lookup"><span data-stu-id="93706-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![Matrice di confusione di classificazione binaria](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="93706-207">Figura 6.</span><span class="sxs-lookup"><span data-stu-id="93706-207">Figure 6.</span></span> <span data-ttu-id="93706-208">Matrice di confusione di classificazione binaria.</span><span class="sxs-lookup"><span data-stu-id="93706-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="93706-209">Tornando al problema della classificazione del reddito, di seguito vengono fornite alcune domande sulla valutazione, utili a comprendere le prestazioni del classificatore usato.</span><span class="sxs-lookup"><span data-stu-id="93706-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="93706-210">Una domanda da porsi è: "Delle persone con un modello di guadagno stimato >50.000 (VP+FP), quante sono state classificate correttamente (VP)?"</span><span class="sxs-lookup"><span data-stu-id="93706-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="93706-211">È possibile rispondere a questa domanda osservando la **precisione** del modello, che è la percentuale di positivi classificati correttamente: VP/(VP+FP).</span><span class="sxs-lookup"><span data-stu-id="93706-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="93706-212">Un'altra domanda comune è la seguente: "Di tutti i dipendenti con un reddito >50.000 (VP+FN), quanti sono stati classificati correttamente dal classificatore (VP)?".</span><span class="sxs-lookup"><span data-stu-id="93706-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="93706-213">Questo è il **richiamo** o tasso di veri positivi, VP/(VP+FN), del classificatore.</span><span class="sxs-lookup"><span data-stu-id="93706-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="93706-214">Come si può notare, vi è un chiaro compromesso tra precisione e richiamo.</span><span class="sxs-lookup"><span data-stu-id="93706-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="93706-215">Ad esempio, in presenza di un set di dati relativamente bilanciato, un classificatore che stima istanze soprattutto positive avrà un richiamo elevato ma una precisione più bassa, poiché molte delle istanze negative verranno classificate in modo errato dando come risultato una serie di falsi positivi.</span><span class="sxs-lookup"><span data-stu-id="93706-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="93706-216">Per vedere un tracciato delle variazioni di queste due metriche, è possibile fare clic sulla curva "PRECISIONE/RICHIAMO" nella pagina di output dei risultati di valutazione (la parte superiore sinistra della figura 7).</span><span class="sxs-lookup"><span data-stu-id="93706-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![Risultati della valutazione della classificazione binaria](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="93706-218">Figura 7.</span><span class="sxs-lookup"><span data-stu-id="93706-218">Figure 7.</span></span> <span data-ttu-id="93706-219">Risultati della valutazione della classificazione binaria.</span><span class="sxs-lookup"><span data-stu-id="93706-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="93706-220">Un'altra metrica correlata spesso usata è **Punteggio F1**, che prende in considerazione precisione e richiamo.</span><span class="sxs-lookup"><span data-stu-id="93706-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="93706-221">Si tratta della media armonica di queste 2 metriche ed è calcolata nel modo seguente: F1 = 2 (precisione x richiamo) / (precisione + richiamo).</span><span class="sxs-lookup"><span data-stu-id="93706-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="93706-222">Il punteggio F1 è un buon modo per riassumere la valutazione in un unico numero, ma si dovrebbe sempre tenere conto di precisione e richiamo parallelamente per comprendere meglio il comportamento di un classificatore.</span><span class="sxs-lookup"><span data-stu-id="93706-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="93706-223">È anche possibile confrontare il tasso di veri positivi e il tasso di falsi positivi nella curva **ROC (Receiver Operating Characteristic)** e il valore **AUC (Area Under the Curve)** corrispondente.</span><span class="sxs-lookup"><span data-stu-id="93706-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="93706-224">Più questa curva è vicina all'angolo superiore sinistro, migliori sono le prestazioni del classificatore (vale a dire portando al massimo il tasso vero positivo e riducendo al minimo il tasso falso positivo).</span><span class="sxs-lookup"><span data-stu-id="93706-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="93706-225">Le curve che si trovano vicino alla diagonale del tracciato risultano dai classificatori che tendono a fare delle stime al limite della casualità.</span><span class="sxs-lookup"><span data-stu-id="93706-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="93706-226">Uso della convalida incrociata</span><span class="sxs-lookup"><span data-stu-id="93706-226">Using Cross Validation</span></span>
<span data-ttu-id="93706-227">Come nell'esempio della regressione, è possibile eseguire la convalida incrociata per ripetere il training, calcolare il punteggio e valutare diversi subset di dati in modo automatico.</span><span class="sxs-lookup"><span data-stu-id="93706-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="93706-228">Analogamente, è possibile usare il modulo [Cross-Validate Model][cross-validate-model], un modello di regressione logistica non sottoposto a training, e un set di dati.</span><span class="sxs-lookup"><span data-stu-id="93706-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="93706-229">La colonna delle etichette deve essere impostata su *income* nelle proprietà del modulo [Cross-Validate Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="93706-230">Dopo aver eseguito l'esperimento e selezionato la porta di output destra del modulo [Cross-Validate Model][cross-validate-model], è possibile visualizzare i valori metrici per ogni sezione, oltre alla deviazione media e standard di ognuna di esse.</span><span class="sxs-lookup"><span data-stu-id="93706-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![Convalida incrociata di un modello di classificazione binaria](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="93706-232">Figura 8.</span><span class="sxs-lookup"><span data-stu-id="93706-232">Figure 8.</span></span> <span data-ttu-id="93706-233">Convalida incrociata di un modello di classificazione binaria.</span><span class="sxs-lookup"><span data-stu-id="93706-233">Cross-Validating a Binary Classification Model.</span></span>

![Risultati della convalida incrociata di un classificatore binario.](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="93706-235">Figura 9.</span><span class="sxs-lookup"><span data-stu-id="93706-235">Figure 9.</span></span> <span data-ttu-id="93706-236">Risultati della convalida incrociata di un classificatore binario.</span><span class="sxs-lookup"><span data-stu-id="93706-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="93706-237">Valutazione di un modello di classificazione multiclasse</span><span class="sxs-lookup"><span data-stu-id="93706-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="93706-238">In questo esperimento verrà usato il comune set di dati [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris"), contenente istanze di 3 diversi tipi (classi) di iris.</span><span class="sxs-lookup"><span data-stu-id="93706-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="93706-239">Esistono 4 valori caratteristici (lunghezza/larghezza sepalo e lunghezza/larghezza petalo) per ogni istanza.</span><span class="sxs-lookup"><span data-stu-id="93706-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="93706-240">Negli esperimenti precedenti è stato eseguito il training e il test di modelli che usano gli stessi set di dati.</span><span class="sxs-lookup"><span data-stu-id="93706-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="93706-241">In questo caso, viene usato il modulo [Split Data][split] per creare due subset di dati, eseguire il training sul primo e classificare e valutare il secondo.</span><span class="sxs-lookup"><span data-stu-id="93706-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="93706-242">Il set di dati Iris è disponibile pubblicamente nel [repository di Machine Learning UCI](http://archive.ics.uci.edu/ml/index.html) e può essere scaricato usando un modulo [Import Data][import-data].</span><span class="sxs-lookup"><span data-stu-id="93706-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="93706-243">Creazione di un esperimento</span><span class="sxs-lookup"><span data-stu-id="93706-243">Creating the Experiment</span></span>
<span data-ttu-id="93706-244">Aggiungere i seguenti moduli all'area di lavoro in Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="93706-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="93706-245">[Import Data][import-data]</span><span class="sxs-lookup"><span data-stu-id="93706-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="93706-246">[Multiclass Decision Forest][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="93706-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="93706-247">[Split Data][split]</span><span class="sxs-lookup"><span data-stu-id="93706-247">[Split Data][split]</span></span>
* <span data-ttu-id="93706-248">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="93706-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="93706-249">[Score Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="93706-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="93706-250">[Evaluate Model][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="93706-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="93706-251">Connettere le porte come mostrato in basso nella figura 10.</span><span class="sxs-lookup"><span data-stu-id="93706-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="93706-252">Impostare l'indice della colonna delle etichette del modulo [Train Model][train-model] su 5.</span><span class="sxs-lookup"><span data-stu-id="93706-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="93706-253">Il set di dati non dispone di una riga di intestazione ma, com'è noto, le etichette delle classi si trovano nella quinta colonna.</span><span class="sxs-lookup"><span data-stu-id="93706-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="93706-254">Fare clic sul modulo [Import Data][import-data] (Impora dati) e impostare la proprietà *Data source* (Origine dati) su *Web URL via HTTP* (URL Web via HTTP) e *URL* su http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span><span class="sxs-lookup"><span data-stu-id="93706-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="93706-255">Impostare la frazione delle istanze da usare per il training nel modulo [Split Data][split], ad esempio 0,7.</span><span class="sxs-lookup"><span data-stu-id="93706-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![Valutazione di un classificatore multiclasse](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="93706-257">Figura 10.</span><span class="sxs-lookup"><span data-stu-id="93706-257">Figure 10.</span></span> <span data-ttu-id="93706-258">Valutazione di un classificatore multiclasse</span><span class="sxs-lookup"><span data-stu-id="93706-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="93706-259">Controllo dei risultati di valutazione</span><span class="sxs-lookup"><span data-stu-id="93706-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="93706-260">Eseguire l'esperimento e fare clic sulla porta di output di [Evaluate Model][evaluate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="93706-261">In questo caso, i risultati di valutazione sono presentati nel formato di una matrice di confusione.</span><span class="sxs-lookup"><span data-stu-id="93706-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="93706-262">Nella matrice sono riportate le istanze stimate e reali per le 3 classi.</span><span class="sxs-lookup"><span data-stu-id="93706-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![Risultati della valutazione della classificazione multiclasse](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="93706-264">Figura 11.</span><span class="sxs-lookup"><span data-stu-id="93706-264">Figure 11.</span></span> <span data-ttu-id="93706-265">Risultati di valutazione della classificazione a più classi.</span><span class="sxs-lookup"><span data-stu-id="93706-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="93706-266">Uso della convalida incrociata</span><span class="sxs-lookup"><span data-stu-id="93706-266">Using Cross Validation</span></span>
<span data-ttu-id="93706-267">Come accennato in precedenza, è possibile ripetere il training, l'assegnazione del punteggio e le valutazioni in modo automatico usando il modulo [Cross-Validate Model][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="93706-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="93706-268">Saranno necessari un set di dati, un modello non sottoposto a training e un modulo [Cross-Validate Model][cross-validate-model] (vedere la figura seguente).</span><span class="sxs-lookup"><span data-stu-id="93706-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="93706-269">È nuovamente necessario impostare la colonna delle etichette del modulo [Cross-Validate Model][cross-validate-model] (in questo caso, indice della colonna 5).</span><span class="sxs-lookup"><span data-stu-id="93706-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="93706-270">Dopo aver eseguito l'esperimento e selezionato la porta destra di output del modulo [Cross-Validate Model][cross-validate-model], è possibile controllare i valori metrici per ogni sezione, nonché la deviazione media e standard.</span><span class="sxs-lookup"><span data-stu-id="93706-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="93706-271">Le metriche visualizzate sono simili a quelle illustrate nel caso della classificazione binaria.</span><span class="sxs-lookup"><span data-stu-id="93706-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="93706-272">Tuttavia, si tenga presente che, nella classificazione a più classi, il calcolo dei veri positivi/negativi e dei falsi positivi/negativi è effettuato con un conteggio su una base specifica per ogni classe, poiché non esiste una classe positiva o negativa complessiva.</span><span class="sxs-lookup"><span data-stu-id="93706-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="93706-273">Ad esempio, quando si esegue il calcolo della precisione o del richiamo della classe "Iris-setosa", si presuppone che questa sia la classe positiva e le altre quelle negative.</span><span class="sxs-lookup"><span data-stu-id="93706-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![Convalida incrociata di un modello di classificazione multiclasse](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="93706-275">Figura 12.</span><span class="sxs-lookup"><span data-stu-id="93706-275">Figure 12.</span></span> <span data-ttu-id="93706-276">Convalida incrociata di un modello di classificazione a più classi.</span><span class="sxs-lookup"><span data-stu-id="93706-276">Cross-Validating a Multiclass Classification Model.</span></span>

![Risultati della convalida incrociata di un modello di classificazione multiclasse](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="93706-278">Figura 13.</span><span class="sxs-lookup"><span data-stu-id="93706-278">Figure 13.</span></span> <span data-ttu-id="93706-279">Risultati della convalida incrociata di un modello di classificazione multiclasse.</span><span class="sxs-lookup"><span data-stu-id="93706-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

