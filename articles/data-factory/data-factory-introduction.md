---
title: aaaIntroduction tooData Factory, un servizio di integrazione dati | Documenti Microsoft
description: "Informazioni su Azure Data Factory: è un servizio di integrazione dei dati cloud che consente di orchestrare e automatizzare lo spostamento e la trasformazione dei dati."
keywords: "integrazione dei dati, integrazione dei dati cloud, che cos'è azure data factory"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 4cc30515315efc938951057743ff8eb3701214ef
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-tooazure-data-factory"></a><span data-ttu-id="d0461-104">Introduzione tooAzure Data Factory</span><span class="sxs-lookup"><span data-stu-id="d0461-104">Introduction tooAzure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="d0461-105">Che cos'è Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="d0461-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="d0461-106">In HelloWorld dei big data, come viene dati esistenti usati in azienda?</span><span class="sxs-lookup"><span data-stu-id="d0461-106">In hello world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="d0461-107">È possibile tooenrich dati generati nel cloud hello utilizzando dati di riferimento da origini dati locali o altre origini dati diverse?</span><span class="sxs-lookup"><span data-stu-id="d0461-107">Is it possible tooenrich data generated in hello cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="d0461-108">Ad esempio, una società di gioco raccoglie molti log di prodotti da giochi nel cloud hello.</span><span class="sxs-lookup"><span data-stu-id="d0461-108">For example, a gaming company collects many logs produced by games in hello cloud.</span></span> <span data-ttu-id="d0461-109">Desidera tooanalyze informazioni toogain questi registri toocustomer preferenze, i dati demografici, il comportamento di utilizzo opportunità di offerte speciali e cross-selling di tooidentify e così via, sviluppare nuove interessanti crescita toodrive delle funzionalità e fornire un'esperienza migliore toocustomers.</span><span class="sxs-lookup"><span data-stu-id="d0461-109">It wants tooanalyze these logs toogain insights in toocustomer preferences, demographics, usage behavior etc. tooidentify up-sell and cross-sell opportunities, develop new compelling features toodrive business growth, and provide a better experience toocustomers.</span></span> 

<span data-ttu-id="d0461-110">tooanalyze questi registri, società hello necessita di dati di riferimento di hello toouse, ad esempio informazioni sui clienti, informazioni di gioco, informazioni in un archivio dati locale campagna di marketing.</span><span class="sxs-lookup"><span data-stu-id="d0461-110">tooanalyze these logs, hello company needs toouse hello reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="d0461-111">Pertanto, società di hello vuole tooingest dati del log dall'archivio dati di cloud hello e dati di riferimento da archivio dati locale di hello.</span><span class="sxs-lookup"><span data-stu-id="d0461-111">Therefore, hello company wants tooingest log data from hello cloud data store and reference data from hello on-premises data store.</span></span> <span data-ttu-id="d0461-112">Quindi, elaborare i dati hello con Hadoop in hello cloud (Azure HDInsight) e pubblicano i risultati di hello archivio dati in un data warehouse di cloud, ad esempio Azure SQL Data Warehouse o un dati locali, ad esempio SQL Server.</span><span class="sxs-lookup"><span data-stu-id="d0461-112">Then, process hello data by using Hadoop in hello cloud (Azure HDInsight) and publish hello result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="d0461-113">Nell'esempio toorun questo flusso di lavoro settimanale di una volta.</span><span class="sxs-lookup"><span data-stu-id="d0461-113">It wants this workflow toorun weekly once.</span></span> 

<span data-ttu-id="d0461-114">È necessario è una piattaforma che consente a un flusso di lavoro può inserire dati on-premise e archivi dati cloud e i dati di trasformazione o un processo mediante i servizi di calcolo esistente, ad esempio Hadoop e pubblicare hello risultati tooan locale hello aziendale toocreate o archivio dati cloud per tooconsume applicazioni di Business Intelligence.</span><span class="sxs-lookup"><span data-stu-id="d0461-114">What is needed is a platform that allows hello company toocreate a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish hello results tooan on-premises or cloud data store for BI applications tooconsume.</span></span> 

![Panoramica di Data Factory](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="d0461-116">Azure Data Factory è hello piattaforma per questo tipo di scenari.</span><span class="sxs-lookup"><span data-stu-id="d0461-116">Azure Data Factory is hello platform for this kind of scenarios.</span></span> <span data-ttu-id="d0461-117">Si tratta di un **servizio di integrazione di dati basato su cloud che consente di toocreate basati sui dati dei flussi di lavoro nel cloud hello per gestire e automatizzare lo spostamento dei dati e la trasformazione dei dati**.</span><span class="sxs-lookup"><span data-stu-id="d0461-117">It is a **cloud-based data integration service that allows you toocreate data-driven workflows in hello cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="d0461-118">Utilizza Data Factory di Azure, è possibile creare e pianificare basati sui dati dei flussi di lavoro (denominati pipeline) che possono caricare dati da archivi dati diversi, processo/trasformare dati hello utilizzando i servizi di calcolo, ad esempio Azure HDInsight Hadoop, Spark, Azure Data Lake Analitica e Azure Machine Learning e pubblicare dati toodata Archivia, ad esempio Azure SQL Data Warehouse per tooconsume applicazioni di business intelligence (BI) di output.</span><span class="sxs-lookup"><span data-stu-id="d0461-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform hello data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data toodata stores such as Azure SQL Data Warehouse for business intelligence (BI) applications tooconsume.</span></span>  

<span data-ttu-id="d0461-119">È più una piattaforma di estrazione e caricamento (Extract-and-Load, EL) e quindi di trasformazione e caricamento (Transform-and-Load, TL) che una piattaforma di estrazione, trasformazione e caricamento (Extract-Transform-and-Load, ETL) tradizionale.</span><span class="sxs-lookup"><span data-stu-id="d0461-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="d0461-120">trasformazioni di Hello che vengono eseguite vengono tootransform/elaborare i dati utilizzando i servizi di calcolo, anziché derivato di trasformazioni tooperform come hello quelli per l'aggiunta di colonne, il conteggio del numero di righe, l'ordinamento dei dati e così via.</span><span class="sxs-lookup"><span data-stu-id="d0461-120">hello transformations that are performed are tootransform/process data by using compute services rather than tooperform transformations like hello ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="d0461-121">Attualmente, in Data Factory di Azure, dati hello che vengano utilizzati e prodotti dai flussi di lavoro sono **sezionati ora dati** (oraria, giornaliera, settimanale, ecc.).</span><span class="sxs-lookup"><span data-stu-id="d0461-121">Currently, in Azure Data Factory, hello data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="d0461-122">Una pipeline può ad esempio leggere i dati di input, elaborare i dati e generare dati di output una volta al giorno.</span><span class="sxs-lookup"><span data-stu-id="d0461-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="d0461-123">È anche possibile eseguire un flusso di lavoro solo una volta.</span><span class="sxs-lookup"><span data-stu-id="d0461-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="d0461-124">Come funziona?</span><span class="sxs-lookup"><span data-stu-id="d0461-124">How does it work?</span></span> 
<span data-ttu-id="d0461-125">le pipeline Hello (flussi di lavoro basati su dati) in Azure Data Factory in genere eseguono hello tre passaggi:</span><span class="sxs-lookup"><span data-stu-id="d0461-125">hello pipelines (data-driven workflows) in Azure Data Factory typically perform hello following three steps:</span></span>

![Le tre fasi di Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="d0461-127">Connettersi e raccogliere</span><span class="sxs-lookup"><span data-stu-id="d0461-127">Connect and collect</span></span>
<span data-ttu-id="d0461-128">Le aziende hanno dati di tipi diversi in origini differenti.</span><span class="sxs-lookup"><span data-stu-id="d0461-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="d0461-129">primo passaggio nella creazione di un sistema di produzione informazioni Hello è tooconnect tooall hello necessarie origini dati e l'elaborazione, ad esempio servizi SaaS, servizi web FTP, condivisioni di file e spostare hello dati tooa esigenze centralizzata per successive l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="d0461-129">hello first step in building an information production system is tooconnect tooall hello required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move hello data as-needed tooa centralized location for subsequent processing.</span></span>

<span data-ttu-id="d0461-130">Senza Data Factory, le aziende devono compilare componenti lo spostamento dei dati personalizzati o scrivere servizi personalizzati toointegrate queste origini dati e l'elaborazione.</span><span class="sxs-lookup"><span data-stu-id="d0461-130">Without Data Factory, enterprises must build custom data movement components or write custom services toointegrate these data sources and processing.</span></span> <span data-ttu-id="d0461-131">È toointegrate costosa e hardware e gestire tali sistemi, e spesso manca il livello aziendale hello di monitoraggio e avviso e i controlli di hello che offerta un servizio completamente gestito.</span><span class="sxs-lookup"><span data-stu-id="d0461-131">It is expensive and hard toointegrate and maintain such systems, and it often lacks hello enterprise grade monitoring and alerting, and hello controls that a fully managed service can offer.</span></span>

<span data-ttu-id="d0461-132">Con Data Factory, è possibile utilizzare hello attività di copia in una pipeline di dati toomove dati da sia in locale e cloud di origine dati archivi tooa centralizzazione come archivio dati cloud hello per un'ulteriore analisi.</span><span class="sxs-lookup"><span data-stu-id="d0461-132">With Data Factory, you can use hello Copy Activity in a data pipeline toomove data from both on-premises and cloud source data stores tooa centralization data store in hello cloud for further analysis.</span></span> <span data-ttu-id="d0461-133">Ad esempio, è possibile raccogliere dati in un archivio Azure Data Lake e trasformare i dati di hello in un secondo momento utilizzando un servizio di calcolo di Azure Data Lake Analitica.</span><span class="sxs-lookup"><span data-stu-id="d0461-133">For example, you can collect data in an Azure Data Lake Store and transform hello data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="d0461-134">oppure raccogliere i dati in un archivio BLOB di Azure e quindi trasformarli usando un cluster Hadoop Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d0461-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="d0461-135">Trasformare e arricchire</span><span class="sxs-lookup"><span data-stu-id="d0461-135">Transform and enrich</span></span>
<span data-ttu-id="d0461-136">Una volta dati sono presenti in un archivio dati centralizzata nel cloud hello, si desidera hello raccolti dati toobe elaborato o trasformati utilizzando i servizi di calcolo, ad esempio HDInsight Hadoop, Spark, Data Lake Analitica e Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="d0461-136">Once data is present in a centralized data store in hello cloud, you want hello collected data toobe processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="d0461-137">Tooreliably trasformata produrre dati desiderata in ambienti di produzione toofeed una pianificazione controllata e gestibile con dati attendibili.</span><span class="sxs-lookup"><span data-stu-id="d0461-137">You want tooreliably produce transformed data on a maintainable and controlled schedule toofeed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="d0461-138">Pubblica</span><span class="sxs-lookup"><span data-stu-id="d0461-138">Publish</span></span> 
<span data-ttu-id="d0461-139">Fornire i dati trasformati dal cloud hello origini tooon locali come SQL Server oppure mantenerla in cloud di origini di archiviazione per l'utilizzo con la business intelligence (BI) e gli strumenti di analitica e altre applicazioni.</span><span class="sxs-lookup"><span data-stu-id="d0461-139">Deliver transformed data from hello cloud tooon-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="d0461-140">Componenti chiave</span><span class="sxs-lookup"><span data-stu-id="d0461-140">Key components</span></span>
<span data-ttu-id="d0461-141">Una sottoscrizione di Azure può includere una o più istanze di Azure Data Factory (o data factory).</span><span class="sxs-lookup"><span data-stu-id="d0461-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="d0461-142">Data Factory di Azure è composto da quattro componenti principali che interagiscono tra di loro piattaforma hello tooprovide in cui è possibile comporre i flussi di lavoro con passaggi toomove e trasformare i dati basati sui dati.</span><span class="sxs-lookup"><span data-stu-id="d0461-142">Azure Data Factory is composed of four key components that work together tooprovide hello platform on which you can compose data-driven workflows with steps toomove and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="d0461-143">Pipeline</span><span class="sxs-lookup"><span data-stu-id="d0461-143">Pipeline</span></span>
<span data-ttu-id="d0461-144">Una data factory può comprendere una o più pipeline.</span><span class="sxs-lookup"><span data-stu-id="d0461-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="d0461-145">Una pipeline è un gruppo di attività,</span><span class="sxs-lookup"><span data-stu-id="d0461-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="d0461-146">Insieme, le attività di hello in una pipeline di eseguono un'attività.</span><span class="sxs-lookup"><span data-stu-id="d0461-146">Together, hello activities in a pipeline perform a task.</span></span> <span data-ttu-id="d0461-147">Ad esempio, una pipeline potrebbe contenere un gruppo di attività che inserisce i dati da un blob di Azure e quindi eseguire una query Hive su una data di hello toopartition cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d0461-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster toopartition hello data.</span></span> <span data-ttu-id="d0461-148">Hello questo modo che pipeline hello consente attività hello toomanage come set anziché ognuna singolarmente.</span><span class="sxs-lookup"><span data-stu-id="d0461-148">hello benefit of this is that hello pipeline allows you toomanage hello activities as a set instead of each one individually.</span></span> <span data-ttu-id="d0461-149">Ad esempio, è possibile distribuire e pianificare le pipeline di hello, anziché le attività di hello in modo indipendente.</span><span class="sxs-lookup"><span data-stu-id="d0461-149">For example, you can deploy and schedule hello pipeline, instead of hello activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="d0461-150">Attività</span><span class="sxs-lookup"><span data-stu-id="d0461-150">Activity</span></span>
<span data-ttu-id="d0461-151">Una pipeline può comprendere una o più attività.</span><span class="sxs-lookup"><span data-stu-id="d0461-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="d0461-152">Attività definiscono hello azioni tooperform sui dati.</span><span class="sxs-lookup"><span data-stu-id="d0461-152">Activities define hello actions tooperform on your data.</span></span> <span data-ttu-id="d0461-153">Ad esempio, si potrebbero utilizzare un copia attività toocopy dati da un archivio tooanother dati archivio dati.</span><span class="sxs-lookup"><span data-stu-id="d0461-153">For example, you may use a Copy activity toocopy data from one data store tooanother data store.</span></span> <span data-ttu-id="d0461-154">Analogamente, è possibile utilizzare un'attività Hive, che viene eseguita una query Hive in un tootransform cluster HDInsight di Azure o analizzare i dati.</span><span class="sxs-lookup"><span data-stu-id="d0461-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster tootransform or analyze your data.</span></span> <span data-ttu-id="d0461-155">Data Factory supporta due tipi di attività: attività di spostamento dei dati e attività di trasformazione dei dati.</span><span class="sxs-lookup"><span data-stu-id="d0461-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="d0461-156">Attività di spostamento dei dati</span><span class="sxs-lookup"><span data-stu-id="d0461-156">Data movement activities</span></span>
<span data-ttu-id="d0461-157">Attività di copia in Data Factory copia dati da un archivio dati di origine dati archivio tooa sink.</span><span class="sxs-lookup"><span data-stu-id="d0461-157">Copy Activity in Data Factory copies data from a source data store tooa sink data store.</span></span> <span data-ttu-id="d0461-158">Data Factory supporta hello seguenti archivi dati.</span><span class="sxs-lookup"><span data-stu-id="d0461-158">Data Factory supports hello following data stores.</span></span> <span data-ttu-id="d0461-159">È possibile scrivere dati da qualsiasi origine tooany sink.</span><span class="sxs-lookup"><span data-stu-id="d0461-159">Data from any source can be written tooany sink.</span></span> <span data-ttu-id="d0461-160">Fare clic su un toolearn archivio dati come toocopy tooand di dati dall'archivio.</span><span class="sxs-lookup"><span data-stu-id="d0461-160">Click a data store toolearn how toocopy data tooand from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="d0461-161">Per altre informazioni, vedere l'articolo [Attività di spostamento dei dati](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="d0461-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="d0461-162">Attività di trasformazione dei dati</span><span class="sxs-lookup"><span data-stu-id="d0461-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="d0461-163">Per altre informazioni, vedere l'articolo [Attività di trasformazione dei dati](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="d0461-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="d0461-164">Attività .NET personalizzate</span><span class="sxs-lookup"><span data-stu-id="d0461-164">Custom .NET activities</span></span>
<span data-ttu-id="d0461-165">Se sono necessari dati toomove a/da un archivio dati di attività di copia non supporta, o trasformare i dati usando la logica personalizzata, creare un **attività .NET personalizzata**.</span><span class="sxs-lookup"><span data-stu-id="d0461-165">If you need toomove data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="d0461-166">Per i dettagli sulla creazione e l'uso di un'attività personalizzata, vedere l'articolo [Usare attività personalizzate in una pipeline di Azure Data Factory](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="d0461-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="d0461-167">Set di dati</span><span class="sxs-lookup"><span data-stu-id="d0461-167">Datasets</span></span>
<span data-ttu-id="d0461-168">Un'attività accetta zero o più set di dati come input e uno o più set di dati come output.</span><span class="sxs-lookup"><span data-stu-id="d0461-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="d0461-169">Set di dati rappresentano strutture dei dati in archivi dati hello, che è sufficiente scegliere o fare riferimento a dati hello da toouse nelle attività come input o output.</span><span class="sxs-lookup"><span data-stu-id="d0461-169">Datasets represent data structures within hello data stores, which simply point or reference hello data you want toouse in your activities as inputs or outputs.</span></span> <span data-ttu-id="d0461-170">Ad esempio, un set di dati Blob di Azure specifica contenitore blob hello e cartelle nell'archiviazione Blob di Azure hello dal quale hello pipeline deve leggere i dati di hello.</span><span class="sxs-lookup"><span data-stu-id="d0461-170">For example, an Azure Blob dataset specifies hello blob container and folder in hello Azure Blob Storage from which hello pipeline should read hello data.</span></span> <span data-ttu-id="d0461-171">In alternativa, un set di dati di tabelle di SQL Azure consente di specificare dati di output di hello tabella toowhich hello sono scritto da attività hello.</span><span class="sxs-lookup"><span data-stu-id="d0461-171">Or, an Azure SQL Table dataset specifies hello table toowhich hello output data is written by hello activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="d0461-172">Servizi collegati</span><span class="sxs-lookup"><span data-stu-id="d0461-172">Linked services</span></span>
<span data-ttu-id="d0461-173">Servizi collegati sono molto simili a stringhe di connessione, che definiscono le informazioni di connessione hello necessarie per le risorse di tooexternal tooconnect Data Factory.</span><span class="sxs-lookup"><span data-stu-id="d0461-173">Linked services are much like connection strings, which define hello connection information needed for Data Factory tooconnect tooexternal resources.</span></span> <span data-ttu-id="d0461-174">Pensare in questo modo, un servizio collegato definisce l'origine dati di hello connessione toohello e un set di dati rappresenta struttura hello dei dati di hello.</span><span class="sxs-lookup"><span data-stu-id="d0461-174">Think of it this way - a linked service defines hello connection toohello data source and a dataset represents hello structure of hello data.</span></span> <span data-ttu-id="d0461-175">Ad esempio, un servizio collegato di archiviazione di Azure specifica connessione stringa tooconnect toohello account di archiviazione Azure.</span><span class="sxs-lookup"><span data-stu-id="d0461-175">For example, an Azure Storage linked service specifies connection string tooconnect toohello Azure Storage account.</span></span> <span data-ttu-id="d0461-176">E un set di dati Blob di Azure specifica contenitore blob hello e la cartella di hello che contiene dati hello.</span><span class="sxs-lookup"><span data-stu-id="d0461-176">And, an Azure Blob dataset specifies hello blob container and hello folder that contains hello data.</span></span>   

<span data-ttu-id="d0461-177">In Data factory i servizi collegati vengono usati per i due scopi seguenti:</span><span class="sxs-lookup"><span data-stu-id="d0461-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="d0461-178">toorepresent un **archivio dati** inclusi via esemplificativa, un Server SQL locale, i database Oracle, condivisione file o un account di archiviazione Blob di Azure.</span><span class="sxs-lookup"><span data-stu-id="d0461-178">toorepresent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="d0461-179">Vedere hello [attività lo spostamento dei dati](#data-movement-activities) sezione per un elenco degli archivi di dati supportati.</span><span class="sxs-lookup"><span data-stu-id="d0461-179">See hello [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="d0461-180">toorepresent un **risorse di calcolo** che può ospitare esecuzione hello di un'attività.</span><span class="sxs-lookup"><span data-stu-id="d0461-180">toorepresent a **compute resource** that can host hello execution of an activity.</span></span> <span data-ttu-id="d0461-181">Ad esempio, hello HDInsightHive attività viene eseguito in un cluster HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="d0461-181">For example, hello HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="d0461-182">Vedere la sezione [Attività di spostamento dei dati](#data-transformation-activities) per un elenco di ambienti di calcolo supportati.</span><span class="sxs-lookup"><span data-stu-id="d0461-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="d0461-183">Relazioni tra le entità di Data Factory</span><span class="sxs-lookup"><span data-stu-id="d0461-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="d0461-184">![Diagramma: Data Factory, servizio di integrazione dei dati cloud - Concetti chiave](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figura 2.**</span><span class="sxs-lookup"><span data-stu-id="d0461-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="d0461-185">Relazioni tra set di dati, attività, pipeline e servizio collegato</span><span class="sxs-lookup"><span data-stu-id="d0461-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="d0461-186">Aree supportate</span><span class="sxs-lookup"><span data-stu-id="d0461-186">Supported regions</span></span>
<span data-ttu-id="d0461-187">Attualmente, è possibile creare data factory in hello **Stati Uniti occidentali**, **Stati Uniti orientali**, e **Europa settentrionale** aree.</span><span class="sxs-lookup"><span data-stu-id="d0461-187">Currently, you can create data factories in hello **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="d0461-188">Tuttavia, una data factory può accedere ad archivi dati e altri dati toomove aree di Azure tra archivi dati servizi di calcolo o dati di processo tramite servizi di calcolo.</span><span class="sxs-lookup"><span data-stu-id="d0461-188">However, a data factory can access data stores and compute services in other Azure regions toomove data between data stores or process data using compute services.</span></span>

<span data-ttu-id="d0461-189">Azure Data Factory stesso non archivia alcun dato.</span><span class="sxs-lookup"><span data-stu-id="d0461-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="d0461-190">Consente di creare flussi di lavoro basati su dati tooorchestrate spostamento dei dati tra [supportati archivi dati](#data-movement-activities) e l'elaborazione dei dati mediante [servizi di calcolo](#data-transformation-activities) in altre aree o in un locale ambiente.</span><span class="sxs-lookup"><span data-stu-id="d0461-190">It lets you create data-driven workflows tooorchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="d0461-191">Consente inoltre troppo[monitorare e gestire i flussi di lavoro](data-factory-monitor-manage-pipelines.md) utilizzando sia a livello di codice e i meccanismi di interfaccia utente.</span><span class="sxs-lookup"><span data-stu-id="d0461-191">It also allows you too[monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="d0461-192">Anche se Data Factory è disponibile solo in **Stati Uniti occidentali**, **Stati Uniti orientali**, e **Europa settentrionale** aree, il servizio di hello accensione lo spostamento dei dati di hello in Data Factory è disponibile [globale](data-factory-data-movement-activities.md#global) in aree diverse.</span><span class="sxs-lookup"><span data-stu-id="d0461-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, hello service powering hello data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="d0461-193">Se un archivio dati si trova dietro un firewall, quindi un [Gateway di gestione dati](data-factory-move-data-between-onprem-and-cloud.md) installato invece dei dati di hello passa ambiente locale.</span><span class="sxs-lookup"><span data-stu-id="d0461-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves hello data instead.</span></span>

<span data-ttu-id="d0461-194">Si supponga ad esempio che gli ambienti di calcolo, come un cluster Azure HDInsight e Azure Machine Learning, siano in esecuzione nell'area Europa occidentale.</span><span class="sxs-lookup"><span data-stu-id="d0461-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="d0461-195">È possibile creare e utilizzare un'istanza di Azure Data Factory in Europa settentrionale e usarlo processi tooschedule negli ambienti di calcolo in Europa occidentale.</span><span class="sxs-lookup"><span data-stu-id="d0461-195">You can create and use an Azure Data Factory instance in North Europe and use it tooschedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="d0461-196">Occorrono pochi millisecondi per il processo di Data Factory tootrigger hello nell'ambiente di calcolo, ma ora hello per l'esecuzione processo hello in ambiente di elaborazione non cambia.</span><span class="sxs-lookup"><span data-stu-id="d0461-196">It takes a few milliseconds for Data Factory tootrigger hello job on your compute environment but hello time for running hello job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="d0461-197">Introduzione alla creazione di una pipeline</span><span class="sxs-lookup"><span data-stu-id="d0461-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="d0461-198">È possibile utilizzare uno di questi strumenti o una pipeline di dati toocreate API in Azure Data Factory:</span><span class="sxs-lookup"><span data-stu-id="d0461-198">You can use one of these tools or APIs toocreate data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="d0461-199">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="d0461-199">Azure portal</span></span>
- <span data-ttu-id="d0461-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="d0461-200">Visual Studio</span></span>
- <span data-ttu-id="d0461-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="d0461-201">PowerShell</span></span>
- <span data-ttu-id="d0461-202">API .NET</span><span class="sxs-lookup"><span data-stu-id="d0461-202">.NET API</span></span>
- <span data-ttu-id="d0461-203">API REST</span><span class="sxs-lookup"><span data-stu-id="d0461-203">REST API</span></span>
- <span data-ttu-id="d0461-204">Modello di Azure Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="d0461-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="d0461-205">toolearn come pipeline toobuild data factory con i dati, seguire le istruzioni dettagliate in hello seguenti esercitazioni:</span><span class="sxs-lookup"><span data-stu-id="d0461-205">toolearn how toobuild data factories with data pipelines, follow step-by-step instructions in hello following tutorials:</span></span>

| <span data-ttu-id="d0461-206">Esercitazione</span><span class="sxs-lookup"><span data-stu-id="d0461-206">Tutorial</span></span> | <span data-ttu-id="d0461-207">Descrizione</span><span class="sxs-lookup"><span data-stu-id="d0461-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="d0461-208">Spostare dati tra due archivi dati cloud</span><span class="sxs-lookup"><span data-stu-id="d0461-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="d0461-209">In questa esercitazione, si crea una factory di dati con una pipeline che **sposta dati** dal database tooSQL di archiviazione Blob.</span><span class="sxs-lookup"><span data-stu-id="d0461-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage tooSQL database.</span></span> |
| [<span data-ttu-id="d0461-210">Trasformare i dati usando cluster Hadoop</span><span class="sxs-lookup"><span data-stu-id="d0461-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="d0461-211">Questa esercitazione mostra come compilare la prima istanza di Azure Data Factory con una pipeline di dati che **elabora i dati** eseguendo uno script Hive in un cluster Azure HDInsight (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="d0461-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="d0461-212">Spostare dati tra un archivio dati locale e un archivio dati cloud usando il gateway di gestione dati</span><span class="sxs-lookup"><span data-stu-id="d0461-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="d0461-213">In questa esercitazione si compila una data factory con una pipeline che **sposta dati** da un **locale** tooan di database di SQL Server blob di Azure.</span><span class="sxs-lookup"><span data-stu-id="d0461-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database tooan Azure blob.</span></span> <span data-ttu-id="d0461-214">Come parte della procedura dettagliata di hello, installare e configurare hello Gateway di gestione dati nel computer.</span><span class="sxs-lookup"><span data-stu-id="d0461-214">As part of hello walkthrough, you install and configure hello Data Management Gateway on your machine.</span></span> |
