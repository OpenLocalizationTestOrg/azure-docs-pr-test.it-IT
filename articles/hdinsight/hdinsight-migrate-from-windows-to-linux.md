---
title: Eseguire la migrazione da HDInsight basato su Windows a HDInsight basato su Linux - Azure| Microsoft Docs
description: Informazioni sulla migrazione da un cluster HDInsight basato su Windows a un cluster HDInsight basato su Linux.
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 35e80efe27081cd43243f488fa60447b76a20c32
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/03/2017
---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a><span data-ttu-id="c8605-103">Migrare da un cluster HDInsight basato su Windows a un cluster basato su Linux</span><span class="sxs-lookup"><span data-stu-id="c8605-103">Migrate from a Windows-based HDInsight cluster to a Linux-based cluster</span></span>

<span data-ttu-id="c8605-104">Questo documento contiene informazioni dettagliate sulle differenze tra HDInsight in Windows e Linux e indicazioni su come eseguire la migrazione dei carichi di lavoro esistenti verso un cluster basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-104">This document provides details on the differences between HDInsight on Windows and Linux, and guidance on how to migrate existing workloads to a Linux-based cluster.</span></span>

<span data-ttu-id="c8605-105">Anche se HDInsight basato su Windows fornisce un modo semplice per usare Hadoop nel cloud, potrebbe essere necessario eseguire la migrazione a un cluster basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-105">While Windows-based HDInsight provides an easy way to use Hadoop in the cloud, you may need to migrate to a Linux-based cluster.</span></span> <span data-ttu-id="c8605-106">Ad esempio, per sfruttare i vantaggi di strumenti e tecnologie basati su Linux che sono necessari per la soluzione.</span><span class="sxs-lookup"><span data-stu-id="c8605-106">For example, to take advantage of Linux-based tools and technologies that are required for your solution.</span></span> <span data-ttu-id="c8605-107">Molti elementi nell'ecosistema Hadoop vengono sviluppati in sistemi basati su Linux e potrebbero non essere compatibili con HDInsight basato su Windows.</span><span class="sxs-lookup"><span data-stu-id="c8605-107">Many things in the Hadoop ecosystem are developed on Linux-based systems, and may not be available for use with Windows-based HDInsight.</span></span> <span data-ttu-id="c8605-108">Inoltre, molti libri, video e altre forme di materiale didattico prevedono che si usi un sistema Linux quando si lavora con Hadoop.</span><span class="sxs-lookup"><span data-stu-id="c8605-108">Additionally, many books, videos, and other training material assume that you are using a Linux system when working with Hadoop.</span></span>

> [!NOTE]
> <span data-ttu-id="c8605-109">I cluster HDInsight usano il supporto a lungo termine Ubuntu (LTS) come sistema operativo per i nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-109">HDInsight clusters use Ubuntu long-term support (LTS) as the operating system for the nodes in the cluster.</span></span> <span data-ttu-id="c8605-110">Per informazioni sulla versione di Ubuntu disponibile con HDInsight e sulle versioni degli altri componenti, vedere le [versioni dei componenti HDInsight](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-110">For information on the version of Ubuntu available with HDInsight, along with other component versioning information, see [HDInsight component versions](hdinsight-component-versioning.md).</span></span>

## <a name="migration-tasks"></a><span data-ttu-id="c8605-111">Attività di migrazione</span><span class="sxs-lookup"><span data-stu-id="c8605-111">Migration tasks</span></span>

<span data-ttu-id="c8605-112">Il flusso di lavoro generale per la migrazione è il seguente:</span><span class="sxs-lookup"><span data-stu-id="c8605-112">The general workflow for migration is as follows.</span></span>

![Diagramma del flusso di lavoro della migrazione](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. <span data-ttu-id="c8605-114">Leggere interamente questo documento per comprendere le modifiche che potrebbero essere necessarie durante la migrazione del flusso di lavoro esistente, dei processi e così via in un cluster basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-114">Read each section of this document to understand changes that may be required when migrating your existing workflow, jobs, etc. to a Linux-based cluster.</span></span>

2. <span data-ttu-id="c8605-115">Creare un cluster basato su Linux come ambiente di test/controllo qualità.</span><span class="sxs-lookup"><span data-stu-id="c8605-115">Create a Linux-based cluster as a test/quality assurance environment.</span></span> <span data-ttu-id="c8605-116">Per altre informazioni sulla creazione di un cluster basato su Linux, vedere [Creare cluster Hadoop basati su Linux in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-116">For more information on creating a Linux-based cluster, see [Create Linux-based clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span></span>

3. <span data-ttu-id="c8605-117">Copiare processi esistenti, origini dati e sink nel nuovo ambiente.</span><span class="sxs-lookup"><span data-stu-id="c8605-117">Copy existing jobs, data sources, and sinks to the new environment.</span></span>

4. <span data-ttu-id="c8605-118">Eseguire il test di convalida per assicurarsi che i processi funzionino come previsto nel nuovo cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-118">Perform validation testing to make sure that your jobs work as expected on the new cluster.</span></span>

<span data-ttu-id="c8605-119">Dopo avere verificato che tutto funzioni come previsto, pianificare i tempi di inattività per la migrazione.</span><span class="sxs-lookup"><span data-stu-id="c8605-119">Once you have verified that everything works as expected, schedule downtime for the migration.</span></span> <span data-ttu-id="c8605-120">Durante questo periodo di inattività, eseguire le operazioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="c8605-120">During this downtime, perform the following actions:</span></span>

1. <span data-ttu-id="c8605-121">Eseguire il backup tutti i dati temporanei archiviati localmente sui nodi del cluster,</span><span class="sxs-lookup"><span data-stu-id="c8605-121">Back up any transient data stored locally on the cluster nodes.</span></span> <span data-ttu-id="c8605-122">ad esempio se i dati sono archiviati direttamente in un nodo head.</span><span class="sxs-lookup"><span data-stu-id="c8605-122">For example, if you have data stored directly on a head node.</span></span>

2. <span data-ttu-id="c8605-123">Eliminare il cluster basato su Windows.</span><span class="sxs-lookup"><span data-stu-id="c8605-123">Delete the Windows-based cluster.</span></span>

3. <span data-ttu-id="c8605-124">Creare un cluster basato su Linux con lo stesso archivio dati predefinito usato dal cluster basato su Windows.</span><span class="sxs-lookup"><span data-stu-id="c8605-124">Create a Linux-based cluster using the same default data store that the Windows-based cluster used.</span></span> <span data-ttu-id="c8605-125">Il nuovo cluster basato su Linux può continuare a lavorare con i dati di produzione esistenti.</span><span class="sxs-lookup"><span data-stu-id="c8605-125">The Linux-based cluster can continue working against your existing production data.</span></span>

4. <span data-ttu-id="c8605-126">Importare i dati temporanei di cui è stata eseguita una copia di backup.</span><span class="sxs-lookup"><span data-stu-id="c8605-126">Import any transient data you backed up.</span></span>

5. <span data-ttu-id="c8605-127">Avviare processi/continuare l'elaborazione con il nuovo cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-127">Start jobs/continue processing using the new cluster.</span></span>

### <a name="copy-data-to-the-test-environment"></a><span data-ttu-id="c8605-128">Copiare i dati nell'ambiente di test</span><span class="sxs-lookup"><span data-stu-id="c8605-128">Copy data to the test environment</span></span>

<span data-ttu-id="c8605-129">Esistono molti metodi per copiare dati e processi, ma i due metodi illustrati in questa sezione sono i più semplici per spostare direttamente i file in un cluster di prova.</span><span class="sxs-lookup"><span data-stu-id="c8605-129">There are many methods to copy the data and jobs, however the two discussed in this section are the simplest methods to directly move files to a test cluster.</span></span>

#### <a name="hdfs-copy"></a><span data-ttu-id="c8605-130">Copia HDFS</span><span class="sxs-lookup"><span data-stu-id="c8605-130">HDFS copy</span></span>

<span data-ttu-id="c8605-131">Usare la procedura seguente per copiare i dati dal cluster di produzione al cluster di test.</span><span class="sxs-lookup"><span data-stu-id="c8605-131">Use the following steps to copy data from the production cluster to the test cluster.</span></span> <span data-ttu-id="c8605-132">In queste procedure viene usata l'utilità `hdfs dfs` inclusa in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="c8605-132">These steps use the `hdfs dfs` utility that is included with HDInsight.</span></span>

1. <span data-ttu-id="c8605-133">Individuare le informazioni dell'account di archiviazione e del contenitore predefinito per il cluster esistente.</span><span class="sxs-lookup"><span data-stu-id="c8605-133">Find the storage account and default container information for your existing cluster.</span></span> <span data-ttu-id="c8605-134">Nell'esempio seguente viene usato PowerShell per recuperare queste informazioni:</span><span class="sxs-lookup"><span data-stu-id="c8605-134">The following example uses PowerShell to retrieve this information:</span></span>

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. <span data-ttu-id="c8605-135">Per creare un ambiente di test, seguire la procedura riportata nel documento Creare cluster basati su Linux in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="c8605-135">To create a test environment, follow the steps in the Create Linux-based clusters in HDInsight document.</span></span> <span data-ttu-id="c8605-136">Prima di creare il cluster, interrompersi e selezionare **Configurazione facoltativa**.</span><span class="sxs-lookup"><span data-stu-id="c8605-136">Stop before creating the cluster, and instead select **Optional Configuration**.</span></span>

3. <span data-ttu-id="c8605-137">Nel pannello Configurazione facoltativa selezionare **Account di archiviazione collegati**.</span><span class="sxs-lookup"><span data-stu-id="c8605-137">From the Optional Configuration blade, select **Linked Storage Accounts**.</span></span>

4. <span data-ttu-id="c8605-138">Selezionare **Aggiungi una chiave di archiviazione**e, quando richiesto, selezionare l'account di archiviazione restituito dallo script PowerShell nel passaggio 1.</span><span class="sxs-lookup"><span data-stu-id="c8605-138">Select **Add a storage key**, and when prompted, select the storage account that was returned by the PowerShell script in step 1.</span></span> <span data-ttu-id="c8605-139">Fare clic su **Seleziona** in ogni pannello.</span><span class="sxs-lookup"><span data-stu-id="c8605-139">Click **Select** on each blade.</span></span> <span data-ttu-id="c8605-140">Al termine, creare il cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-140">Finally, create the cluster.</span></span>

5. <span data-ttu-id="c8605-141">Dopo aver creato il cluster, connettersi tramite **SSH**</span><span class="sxs-lookup"><span data-stu-id="c8605-141">Once the cluster has been created, connect to it using **SSH.**</span></span> <span data-ttu-id="c8605-142">Per altre informazioni, vedere [Usare SSH con HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-142">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

6. <span data-ttu-id="c8605-143">Dalla sessione SSH usare il comando seguente per copiare i file dall'account di archiviazione collegato al nuovo account di archiviazione predefinito.</span><span class="sxs-lookup"><span data-stu-id="c8605-143">From the SSH session, use the following command to copy files from the linked storage account to the new default storage account.</span></span> <span data-ttu-id="c8605-144">Sostituire CONTAINER con le informazioni sul contenitore restituite da PowerShell.</span><span class="sxs-lookup"><span data-stu-id="c8605-144">Replace CONTAINER with the container information returned by PowerShell.</span></span> <span data-ttu-id="c8605-145">Sostituire __ACCOUNT__ con il nome dell'account.</span><span class="sxs-lookup"><span data-stu-id="c8605-145">Replace __ACCOUNT__ with the account name.</span></span> <span data-ttu-id="c8605-146">Sostituire il percorso dei dati con il percorso di un file di dati.</span><span class="sxs-lookup"><span data-stu-id="c8605-146">Replace the path to data with the path to a data file.</span></span>

    ```bash
    hdfs dfs -cp wasb://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > <span data-ttu-id="c8605-147">Se la struttura della directory che contiene i dati non esiste nell'ambiente di test, è possibile crearla usando il comando seguente:</span><span class="sxs-lookup"><span data-stu-id="c8605-147">If the directory structure that contains the data does not exist on the test environment, you can create it using the following command:</span></span>

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    <span data-ttu-id="c8605-148">L'opzione `-p` consente di creare tutte le directory nel percorso.</span><span class="sxs-lookup"><span data-stu-id="c8605-148">The `-p` switch enables the creation of all directories in  the path.</span></span>

#### <a name="direct-copy-between-blobs-in-azure-storage"></a><span data-ttu-id="c8605-149">Copia diretta tra i BLOB in Archiviazione di Azure</span><span class="sxs-lookup"><span data-stu-id="c8605-149">Direct copy between blobs in Azure Storage</span></span>

<span data-ttu-id="c8605-150">In alternativa si può usare il cmdlet `Start-AzureStorageBlobCopy` di Azure PowerShell per copiare i BLOB tra gli account di archiviazione all'esterno di HDInsight.</span><span class="sxs-lookup"><span data-stu-id="c8605-150">Alternatively, you may want to use the `Start-AzureStorageBlobCopy` Azure PowerShell cmdlet to copy blobs between storage accounts outside of HDInsight.</span></span> <span data-ttu-id="c8605-151">Per altre informazioni, vedere la sezione Come gestire i BLOB di Azure del documento Uso di Azure PowerShell con Archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="c8605-151">For more information, see the How to manage Azure Blobs section of Using Azure PowerShell with Azure Storage.</span></span>

## <a name="client-side-technologies"></a><span data-ttu-id="c8605-152">Tecnologie lato client</span><span class="sxs-lookup"><span data-stu-id="c8605-152">Client-side technologies</span></span>

<span data-ttu-id="c8605-153">Le tecnologie lato client, ad esempio i [cmdlet di Azure PowerShell](/powershell/azureps-cmdlets-docs), l'[interfaccia della riga di comando di Azure](../cli-install-nodejs.md) o [.NET SDK per Hadoop](https://hadoopsdk.codeplex.com/) continuano a usare i cluster basati su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-153">Client-side technologies such as [Azure PowerShell cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), or the [.NET SDK for Hadoop](https://hadoopsdk.codeplex.com/) continue to work Linux-based clusters.</span></span> <span data-ttu-id="c8605-154">Queste tecnologie si basano sulle stesse API REST dei tipi di cluster del sistema operativo.</span><span class="sxs-lookup"><span data-stu-id="c8605-154">These technologies rely on REST APIs that are the same across both cluster OS types.</span></span>

## <a name="server-side-technologies"></a><span data-ttu-id="c8605-155">Tecnologie lato server</span><span class="sxs-lookup"><span data-stu-id="c8605-155">Server-side technologies</span></span>

<span data-ttu-id="c8605-156">La tabella seguente contiene indicazioni sulla migrazione dei componenti lato server specifici di Windows.</span><span class="sxs-lookup"><span data-stu-id="c8605-156">The following table provides guidance on migrating server-side components that are Windows-specific.</span></span>

| <span data-ttu-id="c8605-157">Se si usa questa tecnologia...</span><span class="sxs-lookup"><span data-stu-id="c8605-157">If you are using this technology...</span></span> | <span data-ttu-id="c8605-158">Eseguire questa operazione...</span><span class="sxs-lookup"><span data-stu-id="c8605-158">Take this action...</span></span> |
| --- | --- |
| <span data-ttu-id="c8605-159">**PowerShell** (script sul lato server, incluse le Azioni script usate durante la creazione del cluster)</span><span class="sxs-lookup"><span data-stu-id="c8605-159">**PowerShell** (server-side scripts, including Script Actions used during cluster creation)</span></span> |<span data-ttu-id="c8605-160">Riscriverli come script di Bash.</span><span class="sxs-lookup"><span data-stu-id="c8605-160">Rewrite as Bash scripts.</span></span> <span data-ttu-id="c8605-161">Per le azioni script vedere [Personalizzare cluster HDInsight basati su Linux tramite Azione script](hdinsight-hadoop-customize-cluster-linux.md) e [Sviluppo di azioni script con HDInsight basati su Linux](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-161">For Script Actions, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span> |
| <span data-ttu-id="c8605-162">**Interfaccia della riga di comando di Azure** (script lato server)</span><span class="sxs-lookup"><span data-stu-id="c8605-162">**Azure CLI** (server-side scripts)</span></span> |<span data-ttu-id="c8605-163">Anche se l'interfaccia della riga di comando di Azure è disponibile in Linux, non è preinstallata nei nodi head del cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="c8605-163">While the Azure CLI is available on Linux, it does not come pre-installed on the HDInsight cluster head nodes.</span></span> <span data-ttu-id="c8605-164">Per altre informazioni sull'interfaccia della riga di comando di Azure, vedere [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli) (Introduzione all'interfaccia della riga di comando di Azure 2.0).</span><span class="sxs-lookup"><span data-stu-id="c8605-164">For more information on installing the Azure CLI, see [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span></span> |
| <span data-ttu-id="c8605-165">**Componenti .NET**</span><span class="sxs-lookup"><span data-stu-id="c8605-165">**.NET components**</span></span> |<span data-ttu-id="c8605-166">.NET è supportato nei cluster HDInsight basati su Linux tramite [Mono](https://mono-project.com).</span><span class="sxs-lookup"><span data-stu-id="c8605-166">.NET is supported on Linux-based HDInsight through [Mono](https://mono-project.com).</span></span> <span data-ttu-id="c8605-167">Per ulteriori informazioni, vedere [Eseguire la migrazione per le soluzioni .NET per HDInsight basato su Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-167">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span> |
| <span data-ttu-id="c8605-168">**Componenti di Win32 o altre tecnologie esclusive di Windows**</span><span class="sxs-lookup"><span data-stu-id="c8605-168">**Win32 components or other Windows-only technology**</span></span> |<span data-ttu-id="c8605-169">La procedura dipende dal componente o dalla tecnologia.</span><span class="sxs-lookup"><span data-stu-id="c8605-169">Guidance depends on the component or technology.</span></span> <span data-ttu-id="c8605-170">Si potrebbe trovare una versione compatibile con Linux o potrebbe essere necessario trovare una soluzione alternativa o riscrivere il componente.</span><span class="sxs-lookup"><span data-stu-id="c8605-170">You may be able to find a version that is compatible with Linux, or you may need to find an alternate solution or rewrite this component.</span></span> |

> [!IMPORTANT]
> <span data-ttu-id="c8605-171">L'SDK di gestione di HDInsight non è completamente compatibile con Mono.</span><span class="sxs-lookup"><span data-stu-id="c8605-171">The HDInsight management SDK is not fully compatible with Mono.</span></span> <span data-ttu-id="c8605-172">E non deve essere usato come parte delle soluzioni distribuite al cluster HDInsight in questo momento.</span><span class="sxs-lookup"><span data-stu-id="c8605-172">It should not be used as part of solutions deployed to the HDInsight cluster at this time.</span></span>

## <a name="cluster-creation"></a><span data-ttu-id="c8605-173">Creazione del cluster</span><span class="sxs-lookup"><span data-stu-id="c8605-173">Cluster creation</span></span>

<span data-ttu-id="c8605-174">Questa sezione illustra le differenze nella creazione del cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-174">This section provides information on differences in cluster creation.</span></span>

### <a name="ssh-user"></a><span data-ttu-id="c8605-175">Utente SSH</span><span class="sxs-lookup"><span data-stu-id="c8605-175">SSH User</span></span>

<span data-ttu-id="c8605-176">I cluster HDInsight basati su Linux usano il protocollo **Secure Shell (SSH)** per fornire l'accesso remoto ai nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-176">Linux-based HDInsight clusters use the **Secure Shell (SSH)** protocol to provide remote access to the cluster nodes.</span></span> <span data-ttu-id="c8605-177">A differenza dei desktop remoti per i cluster basati Windows, la maggior parte dei client SSH non offrono un'esperienza utente con interfaccia grafica.</span><span class="sxs-lookup"><span data-stu-id="c8605-177">Unlike Remote Desktop for Windows-based clusters, most SSH clients do not provide a graphical user experience.</span></span> <span data-ttu-id="c8605-178">Al contrario, i client SSH offrono una riga di comando che consente di eseguire comandi nel cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-178">Instead, SSH clients provide a command line that allows you to run commands on the cluster.</span></span> <span data-ttu-id="c8605-179">Alcuni client, ad esempio [MobaXterm](http://mobaxterm.mobatek.net/), offrono un browser grafico per il file system oltre a una riga di comando remota.</span><span class="sxs-lookup"><span data-stu-id="c8605-179">Some clients (such as [MobaXterm](http://mobaxterm.mobatek.net/)) provide a graphical file system browser in addition to a remote command line.</span></span>

<span data-ttu-id="c8605-180">Durante la creazione del cluster è necessario specificare un utente SSH e una **password** oppure un **certificato di chiave pubblica** per l'autenticazione.</span><span class="sxs-lookup"><span data-stu-id="c8605-180">During cluster creation, you must provide an SSH user and either a **password** or **public key certificate** for authentication.</span></span>

<span data-ttu-id="c8605-181">È consigliabile usare il certificato di chiave pubblica perché è più sicuro rispetto alla password.</span><span class="sxs-lookup"><span data-stu-id="c8605-181">We recommend using Public key certificate, as it is more secure than using a password.</span></span> <span data-ttu-id="c8605-182">L'autenticazione del certificato genera una coppia di chiavi pubblica/privata firmata e fornisce la chiave pubblica durante la creazione del cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-182">Certificate authentication works by generating a signed public/private key pair, then providing the public key when creating the cluster.</span></span> <span data-ttu-id="c8605-183">Durante la connessione al server tramite SSH, la chiave privata del client consente l'autenticazione per la connessione.</span><span class="sxs-lookup"><span data-stu-id="c8605-183">When connecting to the server using SSH, the private key on the client provides authentication for the connection.</span></span>

<span data-ttu-id="c8605-184">Per altre informazioni, vedere [Usare SSH con HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-184">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

### <a name="cluster-customization"></a><span data-ttu-id="c8605-185">Personalizzazione cluster</span><span class="sxs-lookup"><span data-stu-id="c8605-185">Cluster customization</span></span>

<span data-ttu-id="c8605-186">**Azioni script** usate con i cluster basati su Linux devono essere scritte nello script Bash.</span><span class="sxs-lookup"><span data-stu-id="c8605-186">**Script Actions** used with Linux-based clusters must be written in Bash script.</span></span> <span data-ttu-id="c8605-187">Sebbene le Azioni script possano essere usate durante la creazione del cluster, per i cluster basati su Linux possono anche essere usate per eseguire la personalizzazione dopo che il cluster entra in funzione.</span><span class="sxs-lookup"><span data-stu-id="c8605-187">While Script Actions can be used during cluster creation, for Linux-based clusters they can also be used to perform customization after a cluster is up and running.</span></span> <span data-ttu-id="c8605-188">Per altre informazioni vedere [Personalizzare cluster HDInsight basati su Linux tramite Azione script](hdinsight-hadoop-customize-cluster-linux.md) e [Sviluppo di azioni script con HDInsight basati su Linux](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-188">For more information, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

<span data-ttu-id="c8605-189">Un'altra funzionalità di personalizzazione è **bootstrap**,</span><span class="sxs-lookup"><span data-stu-id="c8605-189">Another customization feature is **bootstrap**.</span></span> <span data-ttu-id="c8605-190">che per i cluster basati su Windows consente di specificare la posizione di librerie aggiuntive da usare con Hive.</span><span class="sxs-lookup"><span data-stu-id="c8605-190">For Windows clusters, this feature allows you to specify the location of additional libraries for use with Hive.</span></span> <span data-ttu-id="c8605-191">Dopo la creazione del cluster, queste librerie sono automaticamente disponibili per l'uso con le query Hive, senza la necessità di usare `ADD JAR`.</span><span class="sxs-lookup"><span data-stu-id="c8605-191">After cluster creation, these libraries are automatically available for use with Hive queries without the need to use `ADD JAR`.</span></span>

<span data-ttu-id="c8605-192">Bootstrap per i cluster basati su Linux non offre questa funzionalità.</span><span class="sxs-lookup"><span data-stu-id="c8605-192">The Bootstrap feature for Linux-based clusters does not provide this functionality.</span></span> <span data-ttu-id="c8605-193">Usare invece l'azione script documentata nell'articolo [Aggiungere librerie Hive durante la creazione del cluster HDInsight](hdinsight-hadoop-add-hive-libraries.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-193">Instead, use script action documented in [Add Hive libraries during cluster creation](hdinsight-hadoop-add-hive-libraries.md).</span></span>

### <a name="virtual-networks"></a><span data-ttu-id="c8605-194">Reti virtuali</span><span class="sxs-lookup"><span data-stu-id="c8605-194">Virtual Networks</span></span>

<span data-ttu-id="c8605-195">I cluster HDInsight basati su Windows funzionano soltanto con le reti virtuali classiche, mentre i cluster HDInsight basati su Linux richiedono le reti virtuali di gestione risorse.</span><span class="sxs-lookup"><span data-stu-id="c8605-195">Windows-based HDInsight clusters only work with Classic Virtual Networks, while Linux-based HDInsight clusters require Resource Manager Virtual Networks.</span></span> <span data-ttu-id="c8605-196">Se nella rete virtuale classica sono presenti risorse a cui si deve connettere il cluster HDInsight basato su Linux, vedere [Connessione di una rete virtuale classica a una rete virtuale di Azure Resource Manager](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-196">If you have resources in a Classic Virtual Network that the Linux-HDInsight cluster must connect to, see [Connecting a Classic Virtual Network to a Resource Manager Virtual Network](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span></span>

<span data-ttu-id="c8605-197">Per altre informazioni sui requisiti di configurazione per usare le reti virtuali di Azure con HDInsight, vedere [Estendere le funzionalità di HDInsight usando una rete virtuale](hdinsight-extend-hadoop-virtual-network.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-197">For more information on configuration requirements for using Azure Virtual Networks with HDInsight, see [Extend HDInsight capabilities by using a Virtual Network](hdinsight-extend-hadoop-virtual-network.md).</span></span>

## <a name="management-and-monitoring"></a><span data-ttu-id="c8605-198">Gestione e monitoraggio</span><span class="sxs-lookup"><span data-stu-id="c8605-198">Management and monitoring</span></span>

<span data-ttu-id="c8605-199">Molte interfacce utente Web usate con HDInsight basato su Windows, ad esempio l'interfaccia di Cronologia processo o YARN, sono disponibili tramite Ambari.</span><span class="sxs-lookup"><span data-stu-id="c8605-199">Many of the web UIs you may have used with Windows-based HDInsight, such as Job History or Yarn UI, are available through Ambari.</span></span> <span data-ttu-id="c8605-200">La vista Hive di Ambari rappresenta inoltre un modo per eseguire query Hive usando il browser Web.</span><span class="sxs-lookup"><span data-stu-id="c8605-200">In addition, the Ambari Hive View provides a way to run Hive queries using your web browser.</span></span> <span data-ttu-id="c8605-201">L'interfaccia utente Web di Ambari è disponibile in ogni cluster basato su Linux all'indirizzo https://NOMECLUSTER.azurehdinsight.net.</span><span class="sxs-lookup"><span data-stu-id="c8605-201">The Ambari Web UI is available on Linux-based clusters at https://CLUSTERNAME.azurehdinsight.net.</span></span>

<span data-ttu-id="c8605-202">Per altre informazioni sull'uso di Ambari, vedere i documenti seguenti:</span><span class="sxs-lookup"><span data-stu-id="c8605-202">For more information on working with Ambari, see the following documents:</span></span>

* [<span data-ttu-id="c8605-203">Web Ambari</span><span class="sxs-lookup"><span data-stu-id="c8605-203">Ambari Web</span></span>](hdinsight-hadoop-manage-ambari.md)
* [<span data-ttu-id="c8605-204">API REST Ambari</span><span class="sxs-lookup"><span data-stu-id="c8605-204">Ambari REST API</span></span>](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a><span data-ttu-id="c8605-205">Avvisi di Ambari</span><span class="sxs-lookup"><span data-stu-id="c8605-205">Ambari Alerts</span></span>

<span data-ttu-id="c8605-206">Ambari offre un sistema di avvisi in grado di indicare i potenziali problemi con il cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-206">Ambari has an alert system that can tell you of potential problems with the cluster.</span></span> <span data-ttu-id="c8605-207">Gli avvisi vengono visualizzati come voci rosse o gialle nell'interfaccia utente Web Ambari, ma possono anche essere recuperati tramite l'API REST.</span><span class="sxs-lookup"><span data-stu-id="c8605-207">Alerts appear as red or yellow entries in the Ambari Web UI, however you can also retrieve them through the REST API.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="c8605-208">Gli avvisi Ambari indicano che *potrebbe* esserci un problema e non che *è* presente un problema.</span><span class="sxs-lookup"><span data-stu-id="c8605-208">Ambari alerts indicate that there *may* be a problem, not that there *is* a problem.</span></span> <span data-ttu-id="c8605-209">Ad esempio, un avviso potrebbe indicare che HiveServer2 non è accessibile anche se è possibile accedervi normalmente.</span><span class="sxs-lookup"><span data-stu-id="c8605-209">For example, you may receive an alert that HiveServer2 cannot be accessed, even though you can access it normally.</span></span>
>
> <span data-ttu-id="c8605-210">Molti avvisi vengono implementati come query basate su intervalli di tempo nell'ambito di un servizio e attendono una risposta entro un intervallo di tempo specifico.</span><span class="sxs-lookup"><span data-stu-id="c8605-210">Many alerts are implemented as interval-based queries against a service, and expect a response within a specific time frame.</span></span> <span data-ttu-id="c8605-211">L'avviso pertanto non significa necessariamente che il servizio è inattivo, bensì che non ha restituito risultati entro l'intervallo di tempo previsto.</span><span class="sxs-lookup"><span data-stu-id="c8605-211">So the alert doesn't necessarily mean that the service is down, just that it didn't return results within the expected time frame.</span></span>

<span data-ttu-id="c8605-212">È opportuno valutare se un avviso si verifica per molto tempo o se indica problemi dell'utente che erano stati segnalati prima di intervenire.</span><span class="sxs-lookup"><span data-stu-id="c8605-212">You should evaluate whether an alert has been occurring for an extended period, or mirrors user problems that have been reported before taking action on it.</span></span>

## <a name="file-system-locations"></a><span data-ttu-id="c8605-213">Percorsi del file system</span><span class="sxs-lookup"><span data-stu-id="c8605-213">File system locations</span></span>

<span data-ttu-id="c8605-214">Il file system del cluster Linux è strutturato diversamente rispetto ai cluster HDInsight basati su Windows.</span><span class="sxs-lookup"><span data-stu-id="c8605-214">The Linux cluster file system is laid out differently than Windows-based HDInsight clusters.</span></span> <span data-ttu-id="c8605-215">Usare la tabella seguente per individuare i file usati comunemente.</span><span class="sxs-lookup"><span data-stu-id="c8605-215">Use the following table to find commonly used files.</span></span>

| <span data-ttu-id="c8605-216">Devo cercare...</span><span class="sxs-lookup"><span data-stu-id="c8605-216">I need to find...</span></span> | <span data-ttu-id="c8605-217">Si trova...</span><span class="sxs-lookup"><span data-stu-id="c8605-217">It is located...</span></span> |
| --- | --- |
| <span data-ttu-id="c8605-218">Configurazione</span><span class="sxs-lookup"><span data-stu-id="c8605-218">Configuration</span></span> |<span data-ttu-id="c8605-219">`/etc`.</span><span class="sxs-lookup"><span data-stu-id="c8605-219">`/etc`.</span></span> <span data-ttu-id="c8605-220">Ad esempio, `/etc/hadoop/conf/core-site.xml`</span><span class="sxs-lookup"><span data-stu-id="c8605-220">For example, `/etc/hadoop/conf/core-site.xml`</span></span> |
| <span data-ttu-id="c8605-221">File di log</span><span class="sxs-lookup"><span data-stu-id="c8605-221">Log files</span></span> |`/var/logs` |
| <span data-ttu-id="c8605-222">Hortonworks Data Platform (HDP)</span><span class="sxs-lookup"><span data-stu-id="c8605-222">Hortonworks Data Platform (HDP)</span></span> |<span data-ttu-id="c8605-223">`/usr/hdp`. Qui sono presenti due directory: una è la versione HDP corrente, l'altra è `current`.</span><span class="sxs-lookup"><span data-stu-id="c8605-223">`/usr/hdp`.There are two directories located here, one that is the current HDP version and `current`.</span></span> <span data-ttu-id="c8605-224">La directory `current` contiene i collegamenti simbolici a file e directory all'interno della directory dei numeri di versione.</span><span class="sxs-lookup"><span data-stu-id="c8605-224">The `current` directory contains symbolic links to files and directories located in the version number directory.</span></span> <span data-ttu-id="c8605-225">La directory `current` è un modo pratico per accedere ai file HDP, poiché il numero di versione cambia non appena viene aggiornata la versione di HDP.</span><span class="sxs-lookup"><span data-stu-id="c8605-225">The `current` directory is provided as a convenient way of accessing HDP files since the version number changes as the HDP version is updated.</span></span> |
| <span data-ttu-id="c8605-226">hadoop-streaming.jar</span><span class="sxs-lookup"><span data-stu-id="c8605-226">hadoop-streaming.jar</span></span> |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

<span data-ttu-id="c8605-227">In genere, se si conosce il nome del file, è possibile usare il comando seguente da una sessione SSH per trovare il percorso del file:</span><span class="sxs-lookup"><span data-stu-id="c8605-227">In general, if you know the name of the file, you can use the following command from an SSH session to find the file path:</span></span>

    find / -name FILENAME 2>/dev/null

<span data-ttu-id="c8605-228">È possibile usare anche caratteri jolly con il nome del file.</span><span class="sxs-lookup"><span data-stu-id="c8605-228">You can also use wildcards with the file name.</span></span> <span data-ttu-id="c8605-229">Ad esempio, `find / -name *streaming*.jar 2>/dev/null` restituisce il percorso dei file con estensione jar contenenti la parola 'streaming' nel nome del file.</span><span class="sxs-lookup"><span data-stu-id="c8605-229">For example, `find / -name *streaming*.jar 2>/dev/null` returns the path to any jar files that contain the word 'streaming' as part of the file name.</span></span>

## <a name="hive-pig-and-mapreduce"></a><span data-ttu-id="c8605-230">Hive, Pig e MapReduce</span><span class="sxs-lookup"><span data-stu-id="c8605-230">Hive, Pig, and MapReduce</span></span>

<span data-ttu-id="c8605-231">I carichi di lavoro di Pig e MapReduce sono simili ai cluster basati su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-231">Pig and MapReduce workloads are similar on Linux-based clusters.</span></span> <span data-ttu-id="c8605-232">Tuttavia, i cluster HDInsight basati su Linux possono essere creati usando versioni più recenti di Hadoop, Hive e Pig.</span><span class="sxs-lookup"><span data-stu-id="c8605-232">However, Linux-based HDInsight clusters can be created using newer versions of Hadoop, Hive, and Pig.</span></span> <span data-ttu-id="c8605-233">Queste differenze di versione potrebbero introdurre modifiche nel funzionamento delle soluzioni esistenti.</span><span class="sxs-lookup"><span data-stu-id="c8605-233">These version differences may introduce changes in how your existing solutions function.</span></span> <span data-ttu-id="c8605-234">Per altre informazioni sulle versioni dei componenti compresi in HDInsight, vedere [Controllo delle versioni dei componenti di HDInsight](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-234">For more information on the versions of components included with HDInsight, see [HDInsight component versioning](hdinsight-component-versioning.md).</span></span>

<span data-ttu-id="c8605-235">HDInsight basato su Linux non offre la funzionalità di desktop remoto.</span><span class="sxs-lookup"><span data-stu-id="c8605-235">Linux-based HDInsight does not provide remote desktop functionality.</span></span> <span data-ttu-id="c8605-236">In alternativa, è possibile usare SSH per connettersi in remoto ai nodi head del cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-236">Instead, you can use SSH to remotely connect to the cluster head nodes.</span></span> <span data-ttu-id="c8605-237">Per altre informazioni, vedere i documenti seguenti:</span><span class="sxs-lookup"><span data-stu-id="c8605-237">For more information, see the following documents:</span></span>

* [<span data-ttu-id="c8605-238">Usare Hive con SSH</span><span class="sxs-lookup"><span data-stu-id="c8605-238">Use Hive with SSH</span></span>](hdinsight-hadoop-use-hive-ssh.md)
* [<span data-ttu-id="c8605-239">Usare Pig con SSH</span><span class="sxs-lookup"><span data-stu-id="c8605-239">Use Pig with SSH</span></span>](hdinsight-hadoop-use-pig-ssh.md)
* [<span data-ttu-id="c8605-240">Usare MapReduce con SSH</span><span class="sxs-lookup"><span data-stu-id="c8605-240">Use MapReduce with SSH</span></span>](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a><span data-ttu-id="c8605-241">Hive</span><span class="sxs-lookup"><span data-stu-id="c8605-241">Hive</span></span>

> [!IMPORTANT]
> <span data-ttu-id="c8605-242">Se si usa un metastore di Hive esterno, è necessario eseguire il backup del metastore prima di usarlo con HDInsight basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-242">If you use an external Hive metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="c8605-243">HDInsight basato su Linux è disponibile nelle versioni più recenti di Hive, che possono presentare problemi di incompatibilità con i metastore creati nelle versioni precedenti.</span><span class="sxs-lookup"><span data-stu-id="c8605-243">Linux-based HDInsight is available with newer versions of Hive, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="c8605-244">Il grafico seguente fornisce indicazioni sulla migrazione dei carichi di lavoro di Hive.</span><span class="sxs-lookup"><span data-stu-id="c8605-244">The following chart provides guidance on migrating your Hive workloads.</span></span>

| <span data-ttu-id="c8605-245">Nel sistema basato su Windows si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-245">On Windows-based, I use...</span></span> | <span data-ttu-id="c8605-246">Nel sistema basato su Linux si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-246">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="c8605-247">**Editor Hive**</span><span class="sxs-lookup"><span data-stu-id="c8605-247">**Hive Editor**</span></span> |[<span data-ttu-id="c8605-248">vista Hive in Ambari</span><span class="sxs-lookup"><span data-stu-id="c8605-248">Hive View in Ambari</span></span>](hdinsight-hadoop-use-hive-ambari-view.md) |
| <span data-ttu-id="c8605-249">`set hive.execution.engine=tez;` per abilitare Tez</span><span class="sxs-lookup"><span data-stu-id="c8605-249">`set hive.execution.engine=tez;` to enable Tez</span></span> |<span data-ttu-id="c8605-250">Tez è il motore di esecuzione predefinito per i cluster basati su Linux, pertanto l'istruzione set non è più necessaria.</span><span class="sxs-lookup"><span data-stu-id="c8605-250">Tez is the default execution engine for Linux-based clusters, so the set statement is no longer needed.</span></span> |
| <span data-ttu-id="c8605-251">Funzioni definite dall'utente C#</span><span class="sxs-lookup"><span data-stu-id="c8605-251">C# user-defined functions</span></span> | <span data-ttu-id="c8605-252">Per informazioni sulla convalida dei componenti di C# con HDInsight basato su Linux, vedere [Eseguire la migrazione delle soluzioni .NET a HDInsight basato su Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="c8605-252">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="c8605-253">script o file CMD nel server richiamati nell'ambito di un processo Hive</span><span class="sxs-lookup"><span data-stu-id="c8605-253">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="c8605-254">gli script Bash</span><span class="sxs-lookup"><span data-stu-id="c8605-254">use Bash scripts</span></span> |
| <span data-ttu-id="c8605-255">`hive` dal desktop remoto</span><span class="sxs-lookup"><span data-stu-id="c8605-255">`hive` command from remote desktop</span></span> |<span data-ttu-id="c8605-256">Usare [Beeline](hdinsight-hadoop-use-hive-beeline.md) o [Hive da una sessione SSH](hdinsight-hadoop-use-hive-ssh.md)</span><span class="sxs-lookup"><span data-stu-id="c8605-256">Use [Beeline](hdinsight-hadoop-use-hive-beeline.md) or [Hive from an SSH session](hdinsight-hadoop-use-hive-ssh.md)</span></span> |

### <a name="pig"></a><span data-ttu-id="c8605-257">Pig</span><span class="sxs-lookup"><span data-stu-id="c8605-257">Pig</span></span>

| <span data-ttu-id="c8605-258">Nel sistema basato su Windows si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-258">On Windows-based, I use...</span></span> | <span data-ttu-id="c8605-259">Nel sistema basato su Linux si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-259">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="c8605-260">Funzioni definite dall'utente C#</span><span class="sxs-lookup"><span data-stu-id="c8605-260">C# user-defined functions</span></span> | <span data-ttu-id="c8605-261">Per informazioni sulla convalida dei componenti di C# con HDInsight basato su Linux, vedere [Eseguire la migrazione delle soluzioni .NET a HDInsight basato su Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="c8605-261">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="c8605-262">Script o file CMD nel server richiamati nell'ambito di un processo Pig</span><span class="sxs-lookup"><span data-stu-id="c8605-262">CMD files or scripts on the server invoked as part of a Pig job</span></span> |<span data-ttu-id="c8605-263">gli script Bash</span><span class="sxs-lookup"><span data-stu-id="c8605-263">use Bash scripts</span></span> |

### <a name="mapreduce"></a><span data-ttu-id="c8605-264">MapReduce</span><span class="sxs-lookup"><span data-stu-id="c8605-264">MapReduce</span></span>

| <span data-ttu-id="c8605-265">Nel sistema basato su Windows si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-265">On Windows-based, I use...</span></span> | <span data-ttu-id="c8605-266">Nel sistema basato su Linux si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-266">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="c8605-267">Componenti di mapping e riduttore C#</span><span class="sxs-lookup"><span data-stu-id="c8605-267">C# mapper and reducer components</span></span> | <span data-ttu-id="c8605-268">Per informazioni sulla convalida dei componenti di C# con HDInsight basato su Linux, vedere [Eseguire la migrazione delle soluzioni .NET a HDInsight basato su Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="c8605-268">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="c8605-269">script o file CMD nel server richiamati nell'ambito di un processo Hive</span><span class="sxs-lookup"><span data-stu-id="c8605-269">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="c8605-270">gli script Bash</span><span class="sxs-lookup"><span data-stu-id="c8605-270">use Bash scripts</span></span> |

## <a name="oozie"></a><span data-ttu-id="c8605-271">Oozie</span><span class="sxs-lookup"><span data-stu-id="c8605-271">Oozie</span></span>

> [!IMPORTANT]
> <span data-ttu-id="c8605-272">Se si usa un metastore di Oozie esterno, è necessario eseguire il backup del metastore prima di usarlo con HDInsight basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-272">If you use an external Oozie metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="c8605-273">HDInsight basato su Linux è disponibile nelle versioni più recenti di Oozie, che possono presentare problemi di incompatibilità con i metastore creati nelle versioni precedenti.</span><span class="sxs-lookup"><span data-stu-id="c8605-273">Linux-based HDInsight is available with newer versions of Oozie, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="c8605-274">I flussi di lavoro di Oozie consentono le azioni shell.</span><span class="sxs-lookup"><span data-stu-id="c8605-274">Oozie workflows allow shell actions.</span></span> <span data-ttu-id="c8605-275">Le azioni shell usano la shell predefinita per il sistema operativo per poter eseguire i comandi della riga di comando.</span><span class="sxs-lookup"><span data-stu-id="c8605-275">Shell actions use the default shell for the operating system to run command-line commands.</span></span> <span data-ttu-id="c8605-276">Se si dispone di flussi di lavoro di Oozie che si basano su shell di Windows, è necessario riscrivere i flussi di lavoro affinché si basino su un ambiente della shell di Linux (Bash).</span><span class="sxs-lookup"><span data-stu-id="c8605-276">If you have Oozie workflows that rely on the Windows shell, you must rewrite the workflows to rely on the Linux shell environment (Bash).</span></span> <span data-ttu-id="c8605-277">Per ulteriori informazioni sull'uso di azioni shell con Oozie, vedere [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html) (Estensioni dell'azione shell di Oozie).</span><span class="sxs-lookup"><span data-stu-id="c8605-277">For more information on using shell actions with Oozie, see [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span></span>

<span data-ttu-id="c8605-278">Se si dispone di flussi di lavoro di Oozie che si basano su applicazioni C# richiamate tramite azioni shell, è necessario convalidare le applicazioni in un ambiente Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-278">If you have Oozie workflows that rely on C# applications invoked through shell actions, you must validate these applications in a Linux environment.</span></span> <span data-ttu-id="c8605-279">Per ulteriori informazioni, vedere [Eseguire la migrazione per le soluzioni .NET per HDInsight basato su Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-279">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span>

## <a name="storm"></a><span data-ttu-id="c8605-280">Storm</span><span class="sxs-lookup"><span data-stu-id="c8605-280">Storm</span></span>

| <span data-ttu-id="c8605-281">Nel sistema basato su Windows si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-281">On Windows-based, I use...</span></span> | <span data-ttu-id="c8605-282">Nel sistema basato su Linux si usa...</span><span class="sxs-lookup"><span data-stu-id="c8605-282">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="c8605-283">Storm Dashboard</span><span class="sxs-lookup"><span data-stu-id="c8605-283">Storm Dashboard</span></span> |<span data-ttu-id="c8605-284">Storm Dashboard non è disponibile.</span><span class="sxs-lookup"><span data-stu-id="c8605-284">The Storm Dashboard is not available.</span></span> <span data-ttu-id="c8605-285">Vedere [Distribuzione e gestione di topologie Apache Storm in HDInsight basato su Linux](hdinsight-storm-deploy-monitor-topology-linux.md) per le modalità di invio delle topologie</span><span class="sxs-lookup"><span data-stu-id="c8605-285">See [Deploy and Manage Storm topologies on Linux-based HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) for ways to submit topologies</span></span> |
| <span data-ttu-id="c8605-286">Interfaccia utente di Storm</span><span class="sxs-lookup"><span data-stu-id="c8605-286">Storm UI</span></span> |<span data-ttu-id="c8605-287">L'interfaccia utente di Storm è disponibile all'indirizzo https://NOMECLUSTER.azurehdinsight.net/stormui</span><span class="sxs-lookup"><span data-stu-id="c8605-287">The Storm UI is available at https://CLUSTERNAME.azurehdinsight.net/stormui</span></span> |
| <span data-ttu-id="c8605-288">Visual Studio per creare, distribuire e gestire le topologie C# o ibride</span><span class="sxs-lookup"><span data-stu-id="c8605-288">Visual Studio to create, deploy, and manage C# or hybrid topologies</span></span> |<span data-ttu-id="c8605-289">È possibile usare Visual Studio per creare, distribuire e gestire topologie C# (SCP.NET) o ibride in Storm basato su Linux in cluster HDInsight creati dopo il 28/10/2016.</span><span class="sxs-lookup"><span data-stu-id="c8605-289">Visual Studio can be used to create, deploy, and manage C# (SCP.NET) or hybrid topologies on Linux-based Storm on HDInsight clusters created after 10/28/2016.</span></span> |

## <a name="hbase"></a><span data-ttu-id="c8605-290">HBase</span><span class="sxs-lookup"><span data-stu-id="c8605-290">HBase</span></span>

<span data-ttu-id="c8605-291">Nei cluster basati su Linux, l'elemento padre znode per HBase è `/hbase-unsecure`.</span><span class="sxs-lookup"><span data-stu-id="c8605-291">On Linux-based clusters, the znode parent for HBase is `/hbase-unsecure`.</span></span> <span data-ttu-id="c8605-292">Impostare questo valore nella configurazione di qualsiasi applicazione client Java che usi un'API Java HBase nativa.</span><span class="sxs-lookup"><span data-stu-id="c8605-292">Set this value in the configuration for any Java client applications that use native HBase Java API.</span></span>

<span data-ttu-id="c8605-293">Vedere [Compilare un'applicazione HBase basata su Java](hdinsight-hbase-build-java-maven.md) per un client di esempio che imposta questo valore.</span><span class="sxs-lookup"><span data-stu-id="c8605-293">See [Build a Java-based HBase application](hdinsight-hbase-build-java-maven.md) for an example client that sets this value.</span></span>

## <a name="spark"></a><span data-ttu-id="c8605-294">Spark</span><span class="sxs-lookup"><span data-stu-id="c8605-294">Spark</span></span>

<span data-ttu-id="c8605-295">I cluster Spark non erano disponibili nei cluster Windows durante l'anteprima.</span><span class="sxs-lookup"><span data-stu-id="c8605-295">Spark clusters were available on Windows-clusters during preview.</span></span> <span data-ttu-id="c8605-296">GA Spark è disponibile solo con i cluster basati su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-296">Spark GA is only available with Linux-based clusters.</span></span> <span data-ttu-id="c8605-297">Non esiste un percorso di migrazione da un cluster di anteprima Spark basato su Windows a un cluster di rilascio Spark basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-297">There is no migration path from a Windows-based Spark preview cluster to a release Linux-based Spark cluster.</span></span>

## <a name="known-issues"></a><span data-ttu-id="c8605-298">Problemi noti</span><span class="sxs-lookup"><span data-stu-id="c8605-298">Known issues</span></span>

### <a name="azure-data-factory-custom-net-activities"></a><span data-ttu-id="c8605-299">Attività .NET personalizzate in Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="c8605-299">Azure Data Factory custom .NET activities</span></span>

<span data-ttu-id="c8605-300">Le attività .NET personalizzate in Azure Data Factory non sono attualmente supportate nei cluster HDInsight basati su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-300">Azure Data Factory custom .NET activities are not currently supported on Linux-based HDInsight clusters.</span></span> <span data-ttu-id="c8605-301">Conviene invece usare uno dei metodi seguenti per implementare attività personalizzate nell'ambito della pipeline di ADF.</span><span class="sxs-lookup"><span data-stu-id="c8605-301">Instead, you should use one of the following methods to implement custom activities as part of your ADF pipeline.</span></span>

* <span data-ttu-id="c8605-302">Eseguire le attività .NET nel pool di Azure Batch.</span><span class="sxs-lookup"><span data-stu-id="c8605-302">Execute .NET activities on Azure Batch pool.</span></span> <span data-ttu-id="c8605-303">Vedere la sezione relativa all'uso del servizio collegato a Azure Batch dell'articolo su come [usare attività personalizzate in una pipeline di Azure Data Factory](../data-factory/data-factory-use-custom-activities.md)</span><span class="sxs-lookup"><span data-stu-id="c8605-303">See the Use Azure Batch linked service section of [Use custom activities in an Azure Data Factory pipeline](../data-factory/data-factory-use-custom-activities.md)</span></span>
* <span data-ttu-id="c8605-304">Implementare l'attività come attività di MapReduce.</span><span class="sxs-lookup"><span data-stu-id="c8605-304">Implement the activity as a MapReduce activity.</span></span> <span data-ttu-id="c8605-305">Per altre informazioni vedere [Richiamare i programmi MapReduce da Data Factory](../data-factory/data-factory-map-reduce.md).</span><span class="sxs-lookup"><span data-stu-id="c8605-305">For more information, see [Invoke MapReduce Programs from Data Factory](../data-factory/data-factory-map-reduce.md).</span></span>

### <a name="line-endings"></a><span data-ttu-id="c8605-306">Terminazioni riga</span><span class="sxs-lookup"><span data-stu-id="c8605-306">Line endings</span></span>

<span data-ttu-id="c8605-307">In genere le terminazioni riga nei sistemi basati su Windows usano CRLF, mentre nei sistemi basati su Linux usano LF.</span><span class="sxs-lookup"><span data-stu-id="c8605-307">In general, line endings on Windows-based systems use CRLF, while Linux-based systems use LF.</span></span> <span data-ttu-id="c8605-308">Se si producono o si attendono dati con terminazioni riga CRLF, potrebbe essere necessario modificare i producer o i consumer in modo che risultino compatibili con la terminazione riga LF.</span><span class="sxs-lookup"><span data-stu-id="c8605-308">If you produce, or expect, data with CRLF line endings, you may need to modify the producers or consumers to work with the LF line ending.</span></span>

<span data-ttu-id="c8605-309">Ad esempio, se si usa Azure PowerShell per eseguire una query in HDInsight in un cluster basato su Windows, verranno restituiti dati con terminazione riga CRLF.</span><span class="sxs-lookup"><span data-stu-id="c8605-309">For example, using Azure PowerShell to query HDInsight on a Windows-based cluster returns data with CRLF.</span></span> <span data-ttu-id="c8605-310">La stessa query in un cluster basato su Linux restituisce dati con terminazione riga LF.</span><span class="sxs-lookup"><span data-stu-id="c8605-310">The same query with a Linux-based cluster returns LF.</span></span> <span data-ttu-id="c8605-311">Prima di eseguire la migrazione a un cluster basato su Linux, è consigliabile verificare se la fine della riga causa un problema con la soluzione.</span><span class="sxs-lookup"><span data-stu-id="c8605-311">You should test to see if the line ending causes a problem with your solutuion before migrating to a Linux-based cluster.</span></span>

<span data-ttu-id="c8605-312">Se si dispone di script che vengono eseguiti direttamente nei nodi cluster Linux, è necessario usare sempre LF come terminazione di riga.</span><span class="sxs-lookup"><span data-stu-id="c8605-312">If you have scripts that are executed directly on the Linux-cluster nodes, you should always use LF as the line ending.</span></span> <span data-ttu-id="c8605-313">Se si usa CRLF, è possibile riscontrare errori durante l'esecuzione di script in un cluster basato su Linux.</span><span class="sxs-lookup"><span data-stu-id="c8605-313">If you use CRLF, you may see errors when running the scripts on a Linux-based cluster.</span></span>

<span data-ttu-id="c8605-314">Se si è certi che gli script non contengono stringhe con caratteri CR incorporati, è possibile modificare in blocco le terminazioni riga tramite uno dei metodi seguenti:</span><span class="sxs-lookup"><span data-stu-id="c8605-314">If you know that the scripts do not contain strings with embedded CR characters, you can bulk change the line endings using one of the following methods:</span></span>

* <span data-ttu-id="c8605-315">**Prima di caricare sul cluster**: usare le istruzioni di PowerShell seguenti per modificare le terminazioni della riga da CRLF a LF prima di caricare lo script sul cluster.</span><span class="sxs-lookup"><span data-stu-id="c8605-315">**Before uploading to the cluster**: Use the following PowerShell statements to change the line endings from CRLF to LF before uploading the script to the cluster.</span></span>

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* <span data-ttu-id="c8605-316">**Dopo il caricamento sul cluster**: usare il comando seguente da una sessione SSH a un cluster basato su Linux per modificare lo script.</span><span class="sxs-lookup"><span data-stu-id="c8605-316">**After uploading to the cluster**: Use the following command from an SSH session to the Linux-based cluster to modify the script.</span></span>

    ```bash
    hdfs dfs -get wasb:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasb:///path/to/script.py
    ```

## <a name="next-steps"></a><span data-ttu-id="c8605-317">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="c8605-317">Next Steps</span></span>

* [<span data-ttu-id="c8605-318">Informazioni su come creare cluster HDInsight basati su Linux</span><span class="sxs-lookup"><span data-stu-id="c8605-318">Learn how to create Linux-based HDInsight clusters</span></span>](hdinsight-hadoop-provision-linux-clusters.md)
* [<span data-ttu-id="c8605-319">Usare SSHper connettersi a HDInsight</span><span class="sxs-lookup"><span data-stu-id="c8605-319">Use SSH to connect to HDInsight</span></span>](hdinsight-hadoop-linux-use-ssh-unix.md)
* [<span data-ttu-id="c8605-320">Gestire un cluster basato su Linux tramite Ambari</span><span class="sxs-lookup"><span data-stu-id="c8605-320">Manage a Linux-based cluster using Ambari</span></span>](hdinsight-hadoop-manage-ambari.md)
