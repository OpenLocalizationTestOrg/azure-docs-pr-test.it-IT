---
title: Introduzione a Data Factory, un servizio di integrazione dei dati | Documentazione Microsoft
description: "Informazioni su Azure Data Factory: è un servizio di integrazione dei dati cloud che consente di orchestrare e automatizzare lo spostamento e la trasformazione dei dati."
keywords: "integrazione dei dati, integrazione dei dati cloud, che cos'è azure data factory"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="15c0f-104">Introduzione a Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="15c0f-104">Introduction to Azure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="15c0f-105">Che cos'è Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="15c0f-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="15c0f-106">Nel mondo dei Big Data, per sfruttare i dati esistenti a livello aziendale</span><span class="sxs-lookup"><span data-stu-id="15c0f-106">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="15c0f-107">e arricchire i dati generati nel cloud usando dati di riferimento di origini dati locali o di diverso tipo</span><span class="sxs-lookup"><span data-stu-id="15c0f-107">Is it possible to enrich data generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="15c0f-108">Ad esempio, una società di giochi raccoglie numerosi log generati dai giochi nel cloud.</span><span class="sxs-lookup"><span data-stu-id="15c0f-108">For example, a gaming company collects many logs produced by games in the cloud.</span></span> <span data-ttu-id="15c0f-109">La società intende analizzare questi log per ottenere informazioni sui clienti, tra cui preferenze, dati demografici e comportamento di utilizzo, per identificare opportunità di upselling e cross-selling, sviluppare nuove funzionalità interessanti per favorire la crescita aziendale e offrire una migliore esperienza ai clienti.</span><span class="sxs-lookup"><span data-stu-id="15c0f-109">It wants to analyze these logs to gain insights in to customer preferences, demographics, usage behavior etc. to identify up-sell and cross-sell opportunities, develop new compelling features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="15c0f-110">Per analizzare questi log, la società deve usare dati di riferimento presenti in un archivio dati locale, ad esempio informazioni sui clienti, sui giochi e sulle campagne di marketing.</span><span class="sxs-lookup"><span data-stu-id="15c0f-110">To analyze these logs, the company needs to use the reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="15c0f-111">La società intende quindi inserire i dati dei log dall'archivio dati cloud e fare riferimento a questi dati dall'archivio locale.</span><span class="sxs-lookup"><span data-stu-id="15c0f-111">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> <span data-ttu-id="15c0f-112">Vuole quindi elaborare i dati tramite Hadoop nel cloud (Azure HDInsight), quindi pubblicare i risultati in un data warehouse cloud come Azure SQL Data Warehouse o un archivio dati locale, ad esempio SQL Server.</span><span class="sxs-lookup"><span data-stu-id="15c0f-112">Then, process the data by using Hadoop in the cloud (Azure HDInsight) and publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="15c0f-113">Questo flusso di lavoro dovrà essere eseguito una volta a settimana.</span><span class="sxs-lookup"><span data-stu-id="15c0f-113">It wants this workflow to run weekly once.</span></span> 

<span data-ttu-id="15c0f-114">È necessaria una piattaforma che consenta all'azienda di creare un flusso di lavoro che possa inserire i dati sia dall'archivio locale che dall'archivio cloud e quindi trasformare o elaborare i dati usando servizi di calcolo esistenti come Hadoop e successivamente pubblicare i risultati in un archivio dati locale o cloud che verrà usato dalle applicazioni BI.</span><span class="sxs-lookup"><span data-stu-id="15c0f-114">What is needed is a platform that allows the company to create a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Panoramica di Data Factory](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="15c0f-116">Azure Data Factory è la piattaforma per questo tipo di scenari.</span><span class="sxs-lookup"><span data-stu-id="15c0f-116">Azure Data Factory is the platform for this kind of scenarios.</span></span> <span data-ttu-id="15c0f-117">È un **servizio di integrazione di dati basato sul cloud che consente di creare flussi di lavoro basati sui dati nel cloud per orchestrare e automatizzare lo spostamento e la trasformazione dei dati stessi**.</span><span class="sxs-lookup"><span data-stu-id="15c0f-117">It is a **cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="15c0f-118">Usando Azure Data Factory è possibile creare e pianificare flussi di lavoro (denominati pipeline) basati sui dati che possono inserire dati da archivi diversi, elaborarli e trasformarli tramite servizi di calcolo come Hadoop di Azure HDInsight, Spark, Azure Data Lake Analytics e Azure Machine Learning e pubblicare l'output in archivi come Azure SQL Data Warehouse per l'uso da parte di applicazioni di business intelligence (BI).</span><span class="sxs-lookup"><span data-stu-id="15c0f-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="15c0f-119">È più una piattaforma di estrazione e caricamento (Extract-and-Load, EL) e quindi di trasformazione e caricamento (Transform-and-Load, TL) che una piattaforma di estrazione, trasformazione e caricamento (Extract-Transform-and-Load, ETL) tradizionale.</span><span class="sxs-lookup"><span data-stu-id="15c0f-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="15c0f-120">Le trasformazioni che vengono eseguite sono finalizzate alla trasformazione/elaborazione dei dati usando i servizi di calcolo, piuttosto che all'aggiunta di colonne derivate, al conteggio delle righe, all'ordinamento dei dati e così via.</span><span class="sxs-lookup"><span data-stu-id="15c0f-120">The transformations that are performed are to transform/process data by using compute services rather than to perform transformations like the ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="15c0f-121">In Azure Data Factory, i dati attualmente usati e prodotti dai flussi di lavoro sono **dati a suddivisione temporale**, ovvero dati orari, giornalieri, settimanali e così via.</span><span class="sxs-lookup"><span data-stu-id="15c0f-121">Currently, in Azure Data Factory, the data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="15c0f-122">Una pipeline può ad esempio leggere i dati di input, elaborare i dati e generare dati di output una volta al giorno.</span><span class="sxs-lookup"><span data-stu-id="15c0f-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="15c0f-123">È anche possibile eseguire un flusso di lavoro solo una volta.</span><span class="sxs-lookup"><span data-stu-id="15c0f-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="15c0f-124">Come funziona?</span><span class="sxs-lookup"><span data-stu-id="15c0f-124">How does it work?</span></span> 
<span data-ttu-id="15c0f-125">Le pipeline, ovvero i flussi di lavoro basati sui dati, in Azure Data Factory eseguono in genere i tre passaggi seguenti:</span><span class="sxs-lookup"><span data-stu-id="15c0f-125">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![Le tre fasi di Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="15c0f-127">Connettersi e raccogliere</span><span class="sxs-lookup"><span data-stu-id="15c0f-127">Connect and collect</span></span>
<span data-ttu-id="15c0f-128">Le aziende hanno dati di tipi diversi in origini differenti.</span><span class="sxs-lookup"><span data-stu-id="15c0f-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="15c0f-129">Il primo passaggio per creare un sistema di produzione di informazioni consiste nel connettere tutte le origini di dati e di elaborazione necessarie, come servizi SaaS, condivisioni file, FTP e servizi Web, e nello spostare i dati in una posizione centralizzata in base alla necessità per l'elaborazione successiva.</span><span class="sxs-lookup"><span data-stu-id="15c0f-129">The first step in building an information production system is to connect to all the required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="15c0f-130">Senza Data factory le grandi imprese devono creare componenti personalizzati per lo spostamento dei dati oppure scrivere servizi personalizzati per l'integrazione delle origini dati e delle elaborazioni.</span><span class="sxs-lookup"><span data-stu-id="15c0f-130">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="15c0f-131">È un procedimento costoso, i sistemi sono difficili da integrare e gestire e spesso non forniscono il monitoraggio e gli avvisi di livello aziendale, oltre ai controlli che solo un servizio completamente gestito può offrire.</span><span class="sxs-lookup"><span data-stu-id="15c0f-131">It is expensive and hard to integrate and maintain such systems, and it often lacks the enterprise grade monitoring and alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="15c0f-132">Con Data Factory, è possibile usare l'attività di copia in una pipeline di dati per spostare i dati da archivi dati di origine sia in locale che nel cloud a un archivio centralizzato nel cloud per analisi aggiuntive.</span><span class="sxs-lookup"><span data-stu-id="15c0f-132">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="15c0f-133">È ad esempio possibile raccogliere i dati in un'istanza di Azure Data Lake Store e quindi trasformarli usando un servizio di calcolo Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="15c0f-133">For example, you can collect data in an Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="15c0f-134">oppure raccogliere i dati in un archivio BLOB di Azure e quindi trasformarli usando un cluster Hadoop Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="15c0f-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="15c0f-135">Trasformare e arricchire</span><span class="sxs-lookup"><span data-stu-id="15c0f-135">Transform and enrich</span></span>
<span data-ttu-id="15c0f-136">Quando i dati sono presenti in un archivio dati centralizzato nel cloud, elaborare o trasformare i dati raccolti tramite servizi di calcolo come Hadoop HDInsight, Spark, Data Lake Analytics e Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="15c0f-136">Once data is present in a centralized data store in the cloud, you want the collected data to be processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="15c0f-137">L'obiettivo è generare in modo affidabile dati trasformati in una pianificazione gestibile e controllata in modo da alimentare gli ambienti di produzione con dati attendibili.</span><span class="sxs-lookup"><span data-stu-id="15c0f-137">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="15c0f-138">Pubblica</span><span class="sxs-lookup"><span data-stu-id="15c0f-138">Publish</span></span> 
<span data-ttu-id="15c0f-139">Inviare i dati trasformati dal cloud alle origini locali, ad esempio SQL Server, oppure mantenere i dati nelle origini di archiviazione cloud per l'uso da parte di strumenti di business intelligence (BI) e di analisi e di altre applicazioni.</span><span class="sxs-lookup"><span data-stu-id="15c0f-139">Deliver transformed data from the cloud to on-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="15c0f-140">Componenti chiave</span><span class="sxs-lookup"><span data-stu-id="15c0f-140">Key components</span></span>
<span data-ttu-id="15c0f-141">Una sottoscrizione di Azure può includere una o più istanze di Azure Data Factory (o data factory).</span><span class="sxs-lookup"><span data-stu-id="15c0f-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="15c0f-142">Azure Data Factory è costituito da quattro componenti chiave che insieme forniscono la piattaforma nella quale è possibile comporre flussi di lavoro basati sui dati con passaggi per lo spostamento e la trasformazione dei dati stessi.</span><span class="sxs-lookup"><span data-stu-id="15c0f-142">Azure Data Factory is composed of four key components that work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="15c0f-143">Pipeline</span><span class="sxs-lookup"><span data-stu-id="15c0f-143">Pipeline</span></span>
<span data-ttu-id="15c0f-144">Una data factory può comprendere una o più pipeline.</span><span class="sxs-lookup"><span data-stu-id="15c0f-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="15c0f-145">Una pipeline è un gruppo di attività,</span><span class="sxs-lookup"><span data-stu-id="15c0f-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="15c0f-146">che insieme eseguono un'operazione.</span><span class="sxs-lookup"><span data-stu-id="15c0f-146">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="15c0f-147">Una pipeline, ad esempio, può contenere un gruppo di attività che inserisce dati da un BLOB di Azure e quindi esegue una query Hive in un cluster HDInsight per partizionare i dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="15c0f-148">La pipeline offre il vantaggio di poter gestire le attività come un set anziché singolarmente.</span><span class="sxs-lookup"><span data-stu-id="15c0f-148">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="15c0f-149">È ad esempio possibile distribuire e pianificare la pipeline anziché distribuire e pianificare le attività separatamente.</span><span class="sxs-lookup"><span data-stu-id="15c0f-149">For example, you can deploy and schedule the pipeline, instead of the activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="15c0f-150">Attività</span><span class="sxs-lookup"><span data-stu-id="15c0f-150">Activity</span></span>
<span data-ttu-id="15c0f-151">Una pipeline può comprendere una o più attività.</span><span class="sxs-lookup"><span data-stu-id="15c0f-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="15c0f-152">Le attività definiscono le azioni da eseguire sui dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-152">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="15c0f-153">Ad esempio, è possibile usare un'attività Copia per copiare i dati da un archivio dati all'altro.</span><span class="sxs-lookup"><span data-stu-id="15c0f-153">For example, you may use a Copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="15c0f-154">Allo stesso modo, è possibile usare un'attività Hive che esegue una query Hive su un cluster Azure HDInsight per trasformare o analizzare i dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="15c0f-155">Data Factory supporta due tipi di attività: attività di spostamento dei dati e attività di trasformazione dei dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="15c0f-156">Attività di spostamento dei dati</span><span class="sxs-lookup"><span data-stu-id="15c0f-156">Data movement activities</span></span>
<span data-ttu-id="15c0f-157">L'attività di copia in Data Factory esegue la copia dei dati da un archivio dati di origine a un archivio dati sink.</span><span class="sxs-lookup"><span data-stu-id="15c0f-157">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="15c0f-158">Data Factory supporta gli archivi dati seguenti.</span><span class="sxs-lookup"><span data-stu-id="15c0f-158">Data Factory supports the following data stores.</span></span> <span data-ttu-id="15c0f-159">I dati da qualsiasi origine possono essere scritti in qualsiasi sink.</span><span class="sxs-lookup"><span data-stu-id="15c0f-159">Data from any source can be written to any sink.</span></span> <span data-ttu-id="15c0f-160">Fare clic su un archivio dati per informazioni su come copiare dati da e verso tale archivio.</span><span class="sxs-lookup"><span data-stu-id="15c0f-160">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="15c0f-161">Per altre informazioni, vedere l'articolo [Attività di spostamento dei dati](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="15c0f-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="15c0f-162">Attività di trasformazione dei dati</span><span class="sxs-lookup"><span data-stu-id="15c0f-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="15c0f-163">Per altre informazioni, vedere l'articolo [Attività di trasformazione dei dati](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="15c0f-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="15c0f-164">Attività .NET personalizzate</span><span class="sxs-lookup"><span data-stu-id="15c0f-164">Custom .NET activities</span></span>
<span data-ttu-id="15c0f-165">Per spostare dati da e verso un archivio dati che non è supportato dall'attività di copia o per trasformare i dati usando la propria logica, creare un' **attività .NET personalizzata**.</span><span class="sxs-lookup"><span data-stu-id="15c0f-165">If you need to move data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="15c0f-166">Per i dettagli sulla creazione e l'uso di un'attività personalizzata, vedere l'articolo [Usare attività personalizzate in una pipeline di Azure Data Factory](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="15c0f-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="15c0f-167">Set di dati</span><span class="sxs-lookup"><span data-stu-id="15c0f-167">Datasets</span></span>
<span data-ttu-id="15c0f-168">Un'attività accetta zero o più set di dati come input e uno o più set di dati come output.</span><span class="sxs-lookup"><span data-stu-id="15c0f-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="15c0f-169">I set di dati rappresentano strutture dei dati all'interno degli archivi dati e fanno semplicemente riferimento ai dati da usare nelle attività come input o output.</span><span class="sxs-lookup"><span data-stu-id="15c0f-169">Datasets represent data structures within the data stores, which simply point or reference the data you want to use in your activities as inputs or outputs.</span></span> <span data-ttu-id="15c0f-170">Un set di dati BLOB di Azure, ad esempio, specifica il contenitore BLOB e la cartella nell'archiviazione BLOB di Azure da cui la pipeline dovrà leggere i dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-170">For example, an Azure Blob dataset specifies the blob container and folder in the Azure Blob Storage from which the pipeline should read the data.</span></span> <span data-ttu-id="15c0f-171">Il set di dati della tabella SQL di Azure specifica invece la tabella in cui l'attività scriverà i dati di output.</span><span class="sxs-lookup"><span data-stu-id="15c0f-171">Or, an Azure SQL Table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="15c0f-172">Servizi collegati</span><span class="sxs-lookup"><span data-stu-id="15c0f-172">Linked services</span></span>
<span data-ttu-id="15c0f-173">I servizi collegati sono molto simili a stringhe di connessione e definiscono le informazioni necessarie per la connessione di Data Factory a risorse esterne.</span><span class="sxs-lookup"><span data-stu-id="15c0f-173">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="15c0f-174">In sintesi, un servizio collegato definisce la connessione all'origine dati, mentre un set di dati rappresenta la struttura dei dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-174">Think of it this way - a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> <span data-ttu-id="15c0f-175">Ad esempio, un servizio collegato di Archiviazione di Azure specifica la stringa per la connessione all'account di archiviazione di Azure.</span><span class="sxs-lookup"><span data-stu-id="15c0f-175">For example, an Azure Storage linked service specifies connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="15c0f-176">Un set di dati BLOB di Azure specifica il contenitore e la cartella BLOB che contengono i dati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-176">And, an Azure Blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="15c0f-177">In Data factory i servizi collegati vengono usati per i due scopi seguenti:</span><span class="sxs-lookup"><span data-stu-id="15c0f-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="15c0f-178">Per rappresentare un **archivio dati** , inclusi, a titolo esemplificativo, un'istanza di SQL Server locale, un database Oracle, una condivisione file o un account di archiviazione BLOB di Azure.</span><span class="sxs-lookup"><span data-stu-id="15c0f-178">To represent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="15c0f-179">Vedere la sezione [Attività di spostamento dei dati](#data-movement-activities) per un elenco di archivi dati supportati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-179">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="15c0f-180">Per rappresentare una **risorsa di calcolo** che può ospitare l'esecuzione di un'attività.</span><span class="sxs-lookup"><span data-stu-id="15c0f-180">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="15c0f-181">Ad esempio, l'attività HDInsightHive viene eseguita in un cluster HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="15c0f-181">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="15c0f-182">Vedere la sezione [Attività di spostamento dei dati](#data-transformation-activities) per un elenco di ambienti di calcolo supportati.</span><span class="sxs-lookup"><span data-stu-id="15c0f-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="15c0f-183">Relazioni tra le entità di Data Factory</span><span class="sxs-lookup"><span data-stu-id="15c0f-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="15c0f-184">![Diagramma: Data Factory, servizio di integrazione dei dati cloud - Concetti chiave](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figura 2.**</span><span class="sxs-lookup"><span data-stu-id="15c0f-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="15c0f-185">Relazioni tra set di dati, attività, pipeline e servizio collegato</span><span class="sxs-lookup"><span data-stu-id="15c0f-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="15c0f-186">Aree supportate</span><span class="sxs-lookup"><span data-stu-id="15c0f-186">Supported regions</span></span>
<span data-ttu-id="15c0f-187">È attualmente possibile creare data factory nelle aree **Stati Uniti occidentali**, **Stati Uniti orientali** ed **Europa settentrionale**.</span><span class="sxs-lookup"><span data-stu-id="15c0f-187">Currently, you can create data factories in the **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="15c0f-188">Una data factory può accedere ad archivi dati e servizi di calcolo in altre aree di Azure per spostare i dati tra archivi dati o elaborare i dati usando i servizi di calcolo.</span><span class="sxs-lookup"><span data-stu-id="15c0f-188">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="15c0f-189">Azure Data Factory stesso non archivia alcun dato.</span><span class="sxs-lookup"><span data-stu-id="15c0f-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="15c0f-190">Consente di creare flussi di lavoro basati sui dati per orchestrare lo spostamento di dati tra [archivi dati supportati](#data-movement-activities) e l'elaborazione di dati usando i [servizi di calcolo](#data-transformation-activities) in altre aree o in un ambiente locale.</span><span class="sxs-lookup"><span data-stu-id="15c0f-190">It lets you create data-driven workflows to orchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="15c0f-191">Consente anche di [monitorare e gestire i flussi di lavoro](data-factory-monitor-manage-pipelines.md) usando meccanismi a livello di codice e di interfaccia utente.</span><span class="sxs-lookup"><span data-stu-id="15c0f-191">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="15c0f-192">Anche se Data Factory è disponibile solo nelle aree **Stati Uniti occidentali**, **Stati Uniti orientali** ed **Europa settentrionale**, il servizio che consente lo spostamento dei dati in Data Factory è disponibile [a livello globale](data-factory-data-movement-activities.md#global) in alcune aree.</span><span class="sxs-lookup"><span data-stu-id="15c0f-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, the service powering the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="15c0f-193">Se archivio dati è protetto da firewall, i dati verranno spostati da un [gateway di gestione dati](data-factory-move-data-between-onprem-and-cloud.md) installato nell'ambiente locale.</span><span class="sxs-lookup"><span data-stu-id="15c0f-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="15c0f-194">Si supponga ad esempio che gli ambienti di calcolo, come un cluster Azure HDInsight e Azure Machine Learning, siano in esecuzione nell'area Europa occidentale.</span><span class="sxs-lookup"><span data-stu-id="15c0f-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="15c0f-195">È possibile creare e usare un'istanza di Azure Data Factory in Europa settentrionale e usarla per pianificare processi negli ambienti di calcolo in Europa occidentale.</span><span class="sxs-lookup"><span data-stu-id="15c0f-195">You can create and use an Azure Data Factory instance in North Europe and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="15c0f-196">Data Factory necessita di pochi secondi per attivare il processo nell'ambiente di calcolo, ma il tempo per l'esecuzione del processo nell'ambiente di calcolo non cambia.</span><span class="sxs-lookup"><span data-stu-id="15c0f-196">It takes a few milliseconds for Data Factory to trigger the job on your compute environment but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="15c0f-197">Introduzione alla creazione di una pipeline</span><span class="sxs-lookup"><span data-stu-id="15c0f-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="15c0f-198">È possibile usare uno di questi strumenti o le API per creare pipeline in Azure Data Factory:</span><span class="sxs-lookup"><span data-stu-id="15c0f-198">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="15c0f-199">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="15c0f-199">Azure portal</span></span>
- <span data-ttu-id="15c0f-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="15c0f-200">Visual Studio</span></span>
- <span data-ttu-id="15c0f-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="15c0f-201">PowerShell</span></span>
- <span data-ttu-id="15c0f-202">API .NET</span><span class="sxs-lookup"><span data-stu-id="15c0f-202">.NET API</span></span>
- <span data-ttu-id="15c0f-203">API REST</span><span class="sxs-lookup"><span data-stu-id="15c0f-203">REST API</span></span>
- <span data-ttu-id="15c0f-204">Modello di Azure Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="15c0f-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="15c0f-205">Per informazioni su come creare data factory con pipeline di dati, attenersi alle istruzioni dettagliate disponibili nelle esercitazioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="15c0f-205">To learn how to build data factories with data pipelines, follow step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="15c0f-206">Esercitazione</span><span class="sxs-lookup"><span data-stu-id="15c0f-206">Tutorial</span></span> | <span data-ttu-id="15c0f-207">Descrizione</span><span class="sxs-lookup"><span data-stu-id="15c0f-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="15c0f-208">Spostare dati tra due archivi dati cloud</span><span class="sxs-lookup"><span data-stu-id="15c0f-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="15c0f-209">In questa esercitazione viene creata una data factory con una pipeline per **spostare i dati** dall'archivio BLOB al database SQL.</span><span class="sxs-lookup"><span data-stu-id="15c0f-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage to SQL database.</span></span> |
| [<span data-ttu-id="15c0f-210">Trasformare i dati usando cluster Hadoop</span><span class="sxs-lookup"><span data-stu-id="15c0f-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="15c0f-211">Questa esercitazione mostra come compilare la prima istanza di Azure Data Factory con una pipeline di dati che **elabora i dati** eseguendo uno script Hive in un cluster Azure HDInsight (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="15c0f-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="15c0f-212">Spostare dati tra un archivio dati locale e un archivio dati cloud usando il gateway di gestione dati</span><span class="sxs-lookup"><span data-stu-id="15c0f-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="15c0f-213">In questa esercitazione viene creata una data factory con una pipeline che **sposta i dati** da un database di SQL Server **locale** a un BLOB di Azure.</span><span class="sxs-lookup"><span data-stu-id="15c0f-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database to an Azure blob.</span></span> <span data-ttu-id="15c0f-214">Come parte della procedura dettagliata, viene installato e configurato il gateway di gestione dati nel computer.</span><span class="sxs-lookup"><span data-stu-id="15c0f-214">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
