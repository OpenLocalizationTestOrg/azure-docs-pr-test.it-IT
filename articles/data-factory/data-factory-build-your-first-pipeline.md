---
title: 'Esercitazione su Data Factory: prima pipeline di dati | Documentazione Microsoft'
description: In questa esercitazione di Data Factory di Azure viene illustrato come toocreate e la pianificazione di una data factory che elabora i dati utilizzando Hive eseguito uno script in un cluster Hadoop.
services: data-factory
keywords: esercitazione di azure data factory, cluster hadoop, hive di hadoop
documentationcenter: 
author: spelluru
manager: jhubbard
editor: 
ms.assetid: 81f36c76-6e78-4d93-a3f2-0317b413f1d0
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: ed9c0ade4500d4ac1f7c2c2312c1fa675e0b1f02
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="tutorial-build-your-first-pipeline-tootransform-data-using-hadoop-cluster"></a><span data-ttu-id="d6dec-104">Esercitazione: Creare i primi dati tootransform pipeline utilizzando cluster Hadoop</span><span class="sxs-lookup"><span data-stu-id="d6dec-104">Tutorial: Build your first pipeline tootransform data using Hadoop cluster</span></span>
> [!div class="op_single_selector"]
> * [<span data-ttu-id="d6dec-105">Panoramica e prerequisiti</span><span class="sxs-lookup"><span data-stu-id="d6dec-105">Overview and prerequisites</span></span>](data-factory-build-your-first-pipeline.md)
> * [<span data-ttu-id="d6dec-106">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="d6dec-106">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
> * [<span data-ttu-id="d6dec-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="d6dec-107">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
> * [<span data-ttu-id="d6dec-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="d6dec-108">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
> * [<span data-ttu-id="d6dec-109">Modello di Resource Manager</span><span class="sxs-lookup"><span data-stu-id="d6dec-109">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
> * [<span data-ttu-id="d6dec-110">API REST</span><span class="sxs-lookup"><span data-stu-id="d6dec-110">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="d6dec-111">In questa esercitazione si compila la prima data factory di Azure con una pipeline di dati.</span><span class="sxs-lookup"><span data-stu-id="d6dec-111">In this tutorial, you build your first Azure data factory with a data pipeline.</span></span> <span data-ttu-id="d6dec-112">Hello pipeline Trasforma i dati di input tramite l'esecuzione di script Hive in un cluster di Azure HDInsight (Hadoop) tooproduce output dati.</span><span class="sxs-lookup"><span data-stu-id="d6dec-112">hello pipeline transforms input data by running Hive script on an Azure HDInsight (Hadoop) cluster tooproduce output data.</span></span>  

<span data-ttu-id="d6dec-113">Questo articolo fornisce una panoramica e prerequisiti per l'esercitazione hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-113">This article provides overview and prerequisites for hello tutorial.</span></span> <span data-ttu-id="d6dec-114">Dopo aver completato i prerequisiti di hello, è possibile eseguire esercitazione hello utilizzando uno dei seguenti SDK di strumenti/hello: portale di Azure, Visual Studio, PowerShell, Gestione risorse modello API REST.</span><span class="sxs-lookup"><span data-stu-id="d6dec-114">After you complete hello prerequisites, you can do hello tutorial using one of hello following tools/SDKs: Azure portal, Visual Studio, PowerShell, Resource Manager template, REST API.</span></span> <span data-ttu-id="d6dec-115">Selezionare una delle opzioni di hello nell'elenco a discesa hello hello inizio (o) i collegamenti alla fine di hello di questa esercitazione di hello toodo articolo utilizzando una di queste opzioni.</span><span class="sxs-lookup"><span data-stu-id="d6dec-115">Select one of hello options in hello drop-down list at hello beginning (or) links at hello end of this article toodo hello tutorial using one of these options.</span></span>    

## <a name="tutorial-overview"></a><span data-ttu-id="d6dec-116">Panoramica dell'esercitazione</span><span class="sxs-lookup"><span data-stu-id="d6dec-116">Tutorial overview</span></span>
<span data-ttu-id="d6dec-117">In questa esercitazione è eseguire hello alla procedura seguente:</span><span class="sxs-lookup"><span data-stu-id="d6dec-117">In this tutorial, you perform hello following steps:</span></span>

1. <span data-ttu-id="d6dec-118">Creare una **data factory**.</span><span class="sxs-lookup"><span data-stu-id="d6dec-118">Create a **data factory**.</span></span> <span data-ttu-id="d6dec-119">Una data factory può contenere una o più pipeline di dati che spostano e trasformano i dati.</span><span class="sxs-lookup"><span data-stu-id="d6dec-119">A data factory can contain one or more data pipelines that move and transform data.</span></span> 

    <span data-ttu-id="d6dec-120">In questa esercitazione è creare una pipeline in data factory di hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-120">In this tutorial, you create one pipeline in hello data factory.</span></span> 
2. <span data-ttu-id="d6dec-121">Creare una **pipeline**.</span><span class="sxs-lookup"><span data-stu-id="d6dec-121">Create a **pipeline**.</span></span> <span data-ttu-id="d6dec-122">Una pipeline può comprendere una o più attività (esempi: attività di copia, attività Hive HDInsight).</span><span class="sxs-lookup"><span data-stu-id="d6dec-122">A pipeline can have one or more activities (Examples: Copy Activity, HDInsight Hive Activity).</span></span> <span data-ttu-id="d6dec-123">Questo esempio utilizza hello attività Hive di HDInsight che esegue uno script Hive in un cluster HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="d6dec-123">This sample uses hello HDInsight Hive activity that runs a Hive script on a HDInsight Hadoop cluster.</span></span> <span data-ttu-id="d6dec-124">script di Hello crea innanzitutto una tabella in cui i riferimenti hello dati di log web non elaborato archiviati nell'archiviazione blob di Azure e quindi partizioni hello dati non elaborati per anno e mese.</span><span class="sxs-lookup"><span data-stu-id="d6dec-124">hello script first creates a table that references hello raw web log data stored in Azure blob storage and then partitions hello raw data by year and month.</span></span>

    <span data-ttu-id="d6dec-125">In questa esercitazione, pipeline di hello utilizza dati tootransform attività Hive di hello eseguendo una query Hive in un cluster Azure HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="d6dec-125">In this tutorial, hello pipeline uses hello Hive Activity tootransform data by running a Hive query on an Azure HDInsight Hadoop cluster.</span></span> 
3. <span data-ttu-id="d6dec-126">Creare **servizi collegati**.</span><span class="sxs-lookup"><span data-stu-id="d6dec-126">Create **linked services**.</span></span> <span data-ttu-id="d6dec-127">Per creare un servizio collegato di toolink un archivio dati o una data factory toohello servizio di calcolo.</span><span class="sxs-lookup"><span data-stu-id="d6dec-127">You create a linked service toolink a data store or a compute service toohello data factory.</span></span> <span data-ttu-id="d6dec-128">Un archivio dati, ad esempio l'archiviazione di Azure contiene i dati di input/output delle attività nella pipeline hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-128">A data store such as Azure Storage holds input/output data of activities in hello pipeline.</span></span> <span data-ttu-id="d6dec-129">Un servizio di calcolo come un cluster Hadoop di HDInsight elabora/trasforma i dati.</span><span class="sxs-lookup"><span data-stu-id="d6dec-129">A compute service such as HDInsight Hadoop cluster processes/transforms data.</span></span>

    <span data-ttu-id="d6dec-130">In questa esercitazione guidata si creano due servizi collegati : **Archiviazione di Azure** e **Azure HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="d6dec-130">In this tutorial, you create two linked services: **Azure Storage** and **Azure HDInsight**.</span></span> <span data-ttu-id="d6dec-131">Archiviazione di Azure Hello collegato collegamenti al servizio un Account di archiviazione di Azure che contiene una data factory toohello dati di input/output di hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-131">hello Azure Storage linked service links an Azure Storage Account that holds hello input/output data toohello data factory.</span></span> <span data-ttu-id="d6dec-132">Azure HDInsight collegato collegamenti al servizio di un cluster HDInsight di Azure che è usato tootransform dati toohello data factory.</span><span class="sxs-lookup"><span data-stu-id="d6dec-132">Azure HDInsight linked service links an Azure HDInsight cluster that is used tootransform data toohello data factory.</span></span> 
3. <span data-ttu-id="d6dec-133">Creare **set di dati**di input e di output.</span><span class="sxs-lookup"><span data-stu-id="d6dec-133">Create input and output **datasets**.</span></span> <span data-ttu-id="d6dec-134">Un set di dati di input rappresenta hello l'input per un'attività nella pipeline hello e un set di dati di output rappresenta l'output di hello per attività hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-134">An input dataset represents hello input for an activity in hello pipeline and an output dataset represents hello output for hello activity.</span></span>

    <span data-ttu-id="d6dec-135">In questa esercitazione, hello di input e output del set di dati specificare i percorsi di input e output di dati in hello archiviazione Blob di Azure.</span><span class="sxs-lookup"><span data-stu-id="d6dec-135">In this tutorial, hello input and output datasets specify locations of input and output data in hello Azure Blob Storage.</span></span> <span data-ttu-id="d6dec-136">servizio collegato di archiviazione Azure Hello specifica quale Account di archiviazione Azure usato.</span><span class="sxs-lookup"><span data-stu-id="d6dec-136">hello Azure Storage linked service specifies what Azure Storage Account is used.</span></span> <span data-ttu-id="d6dec-137">Consente di specificare un set di dati di input in cui si trovano i file di input hello e specifica di un set di dati di output in cui vengono collocati i file di output di hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-137">An input dataset specifies where hello input files are located and an output dataset specifies where hello output files are placed.</span></span> 


<span data-ttu-id="d6dec-138">Vedere [tooAzure introduzione Data Factory](data-factory-introduction.md) articolo per una panoramica dettagliata della Data Factory di Azure.</span><span class="sxs-lookup"><span data-stu-id="d6dec-138">See [Introduction tooAzure Data Factory](data-factory-introduction.md) article for a detailed overview of Azure Data Factory.</span></span>
  
<span data-ttu-id="d6dec-139">Ecco hello **vista diagramma** della factory di dati di esempio hello è compilare in questa esercitazione.</span><span class="sxs-lookup"><span data-stu-id="d6dec-139">Here is hello **diagram view** of hello sample data factory you build in this tutorial.</span></span> <span data-ttu-id="d6dec-140">**MyFirstPipeline** ha un'attività di tipo Hive che usa i set di dati **AzureBlobInput** come input e produce set di dati **AzureBlobOutput** come output.</span><span class="sxs-lookup"><span data-stu-id="d6dec-140">**MyFirstPipeline** has one activity of type Hive that consumes **AzureBlobInput** dataset as an input and produces **AzureBlobOutput** dataset as an output.</span></span> 

![Vista diagramma nell'esercitazione su Data Factory](media/data-factory-build-your-first-pipeline/data-factory-tutorial-diagram-view.png)


<span data-ttu-id="d6dec-142">In questa esercitazione, **inputdata** cartella di hello **adfgetstarted** contenitore blob di Azure contiene un file denominato input.log.</span><span class="sxs-lookup"><span data-stu-id="d6dec-142">In this tutorial, **inputdata** folder of hello **adfgetstarted** Azure blob container contains one file named input.log.</span></span> <span data-ttu-id="d6dec-143">Questo file di log contiene voci relative ai tre mesi di gennaio, febbraio e marzo 2016.</span><span class="sxs-lookup"><span data-stu-id="d6dec-143">This log file has entries from three months: January, February, and March of 2016.</span></span> <span data-ttu-id="d6dec-144">Di seguito sono le righe di esempio hello per ogni mese nel file di input hello.</span><span class="sxs-lookup"><span data-stu-id="d6dec-144">Here are hello sample rows for each month in hello input file.</span></span> 

```
2016-01-01,02:01:09,SAMPLEWEBSITE,GET,/blogposts/mvc4/step2.png,X-ARR-LOG-ID=2ec4b8ad-3cf0-4442-93ab-837317ece6a1,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,53175,871 
2016-02-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
2016-03-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
```

<span data-ttu-id="d6dec-145">Quando il file hello venga elaborato dalla pipeline di hello con attività Hive di HDInsight, attività hello esegue uno script Hive nel cluster HDInsight hello che partizioni di dati di input per anno e mese.</span><span class="sxs-lookup"><span data-stu-id="d6dec-145">When hello file is processed by hello pipeline with HDInsight Hive Activity, hello activity runs a Hive script on hello HDInsight cluster that partitions input data by year and month.</span></span> <span data-ttu-id="d6dec-146">script di Hello crea tre cartelle di output che contengono un file con le voci di ogni mese.</span><span class="sxs-lookup"><span data-stu-id="d6dec-146">hello script creates three output folders that contain a file with entries from each month.</span></span>  

```
adfgetstarted/partitioneddata/year=2016/month=1/000000_0
adfgetstarted/partitioneddata/year=2016/month=2/000000_0
adfgetstarted/partitioneddata/year=2016/month=3/000000_0
```

<span data-ttu-id="d6dec-147">Dalle righe di esempio hello illustrate in precedenza, hello innanzitutto una (con 2016-01-01) viene scritto toohello 000000_0 file mese hello = 1 cartella.</span><span class="sxs-lookup"><span data-stu-id="d6dec-147">From hello sample lines shown above, hello first one (with 2016-01-01) is written toohello 000000_0 file in hello month=1 folder.</span></span> <span data-ttu-id="d6dec-148">Allo stesso modo, hello secondo viene scritto il file toohello nel mese di hello = 2 cartella e hello terzo uno viene scritto il file toohello nel mese di hello = 3 cartella.</span><span class="sxs-lookup"><span data-stu-id="d6dec-148">Similarly, hello second one is written toohello file in hello month=2 folder and hello third one is written toohello file in hello month=3 folder.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="d6dec-149">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="d6dec-149">Prerequisites</span></span>
<span data-ttu-id="d6dec-150">Prima di iniziare questa esercitazione, è necessario disporre di hello seguenti prerequisiti:</span><span class="sxs-lookup"><span data-stu-id="d6dec-150">Before you begin this tutorial, you must have hello following prerequisites:</span></span>

1. <span data-ttu-id="d6dec-151">**Sottoscrizione di Azure** : se non è disponibile una sottoscrizione di Azure, è possibile creare un account di valutazione gratuito in pochi minuti.</span><span class="sxs-lookup"><span data-stu-id="d6dec-151">**Azure subscription** - If you don't have an Azure subscription, you can create a free trial account in just a couple of minutes.</span></span> <span data-ttu-id="d6dec-152">Vedere hello [versione di valutazione gratuita](https://azure.microsoft.com/pricing/free-trial/) articolo su come ottenere un account di prova.</span><span class="sxs-lookup"><span data-stu-id="d6dec-152">See hello [Free Trial](https://azure.microsoft.com/pricing/free-trial/) article on how you can obtain a free trial account.</span></span>
2. <span data-ttu-id="d6dec-153">**Archiviazione di Azure** : si utilizza un account di archiviazione di Azure standard generica per l'archiviazione dei dati hello in questa esercitazione.</span><span class="sxs-lookup"><span data-stu-id="d6dec-153">**Azure Storage** – You use a general-purpose standard Azure storage account for storing hello data in this tutorial.</span></span> <span data-ttu-id="d6dec-154">Se non si dispone di un account di archiviazione di Azure standard generici, vedere hello [creare un account di archiviazione](../storage/common/storage-create-storage-account.md#create-a-storage-account) articolo.</span><span class="sxs-lookup"><span data-stu-id="d6dec-154">If you don't have a general-purpose standard Azure storage account, see hello [Create a storage account](../storage/common/storage-create-storage-account.md#create-a-storage-account) article.</span></span> <span data-ttu-id="d6dec-155">Dopo aver creato l'account di archiviazione hello, prendere nota delle hello **nome account** e **tasto**.</span><span class="sxs-lookup"><span data-stu-id="d6dec-155">After you have created hello storage account, note down hello **account name** and **access key**.</span></span> <span data-ttu-id="d6dec-156">Vedere [Visualizzare, copiare e rigenerare le chiavi di accesso alle risorse di archiviazione](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span><span class="sxs-lookup"><span data-stu-id="d6dec-156">See [View, copy and regenerate storage access keys](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span></span>
3. <span data-ttu-id="d6dec-157">Scaricare ed esaminare i file di query Hive hello (**HQL**) disponibile all'indirizzo: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span><span class="sxs-lookup"><span data-stu-id="d6dec-157">Download and review hello Hive query file (**HQL**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span></span> <span data-ttu-id="d6dec-158">Questa query Trasforma i dati di output tooproduce di dati di input.</span><span class="sxs-lookup"><span data-stu-id="d6dec-158">This query transforms input data tooproduce output data.</span></span> 
4. <span data-ttu-id="d6dec-159">Scaricare ed esaminare i file di input di esempio hello (**input.log**) disponibile all'indirizzo: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span><span class="sxs-lookup"><span data-stu-id="d6dec-159">Download and review hello sample input file (**input.log**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span></span>
5. <span data-ttu-id="d6dec-160">Creare un contenitore BLOB denominato **adfgetstarted** nell'Archiviazione BLOB di Azure.</span><span class="sxs-lookup"><span data-stu-id="d6dec-160">Create a blob container named **adfgetstarted** in your Azure Blob Storage.</span></span> 
6. <span data-ttu-id="d6dec-161">Caricare **partitionweblogs.hql** file toohello **script** cartella hello **adfgetstarted** contenitore.</span><span class="sxs-lookup"><span data-stu-id="d6dec-161">Upload **partitionweblogs.hql** file toohello **script** folder in hello **adfgetstarted** container.</span></span> <span data-ttu-id="d6dec-162">Usare strumenti come [Esplora archivi di Microsoft Azure](http://storageexplorer.com/).</span><span class="sxs-lookup"><span data-stu-id="d6dec-162">Use tools such as [Microsoft Azure Storage Explorer](http://storageexplorer.com/).</span></span> 
7. <span data-ttu-id="d6dec-163">Caricare **input.log** file toohello **inputdata** cartella hello **adfgetstarted** contenitore.</span><span class="sxs-lookup"><span data-stu-id="d6dec-163">Upload **input.log** file toohello **inputdata** folder in hello **adfgetstarted** container.</span></span> 

<span data-ttu-id="d6dec-164">Dopo aver completato i prerequisiti di hello, selezionare uno dei hello segue/SDK di strumenti toodo hello esercitazione:</span><span class="sxs-lookup"><span data-stu-id="d6dec-164">After you complete hello prerequisites, select one of hello following tools/SDKs toodo hello tutorial:</span></span> 

- [<span data-ttu-id="d6dec-165">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="d6dec-165">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
- [<span data-ttu-id="d6dec-166">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="d6dec-166">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
- [<span data-ttu-id="d6dec-167">PowerShell</span><span class="sxs-lookup"><span data-stu-id="d6dec-167">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
- [<span data-ttu-id="d6dec-168">Modello di Resource Manager</span><span class="sxs-lookup"><span data-stu-id="d6dec-168">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
- [<span data-ttu-id="d6dec-169">API REST</span><span class="sxs-lookup"><span data-stu-id="d6dec-169">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="d6dec-170">Il portale di Azure e Visual Studio forniscono l'interfaccia utente grafica per la creazione di data factory.</span><span class="sxs-lookup"><span data-stu-id="d6dec-170">Azure portal and Visual Studio provide GUI way of building your data factories.</span></span> <span data-ttu-id="d6dec-171">Le opzioni PowerShell, il modello di Resource Manager e l'API REST forniscono una modalità di programmazione/script per la creazione di data factory.</span><span class="sxs-lookup"><span data-stu-id="d6dec-171">Whereas, PowerShell, Resource Manager Template, and REST API options provides scripting/programming way of building your data factories.</span></span>

> [!NOTE]
> <span data-ttu-id="d6dec-172">pipeline di dati Hello in questa esercitazione Trasforma i dati di output tooproduce di dati di input.</span><span class="sxs-lookup"><span data-stu-id="d6dec-172">hello data pipeline in this tutorial transforms input data tooproduce output data.</span></span> <span data-ttu-id="d6dec-173">Non copia dati da un archivio dati di origine dati archivio tooa destinazione.</span><span class="sxs-lookup"><span data-stu-id="d6dec-173">It does not copy data from a source data store tooa destination data store.</span></span> <span data-ttu-id="d6dec-174">Per un'esercitazione su come dati di toocopy tramite Data Factory di Azure, vedere [esercitazione: copiare i dati da archiviazione Blob tooSQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="d6dec-174">For a tutorial on how toocopy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage tooSQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
> 
> <span data-ttu-id="d6dec-175">È possibile concatenare le due attività (eseguire un'attività dopo l'altro) mediante l'impostazione di set di dati di hello output di un'attività come hello input set di dati di hello altre attività.</span><span class="sxs-lookup"><span data-stu-id="d6dec-175">You can chain two activities (run one activity after another) by setting hello output dataset of one activity as hello input dataset of hello other activity.</span></span> <span data-ttu-id="d6dec-176">Per informazioni dettagliate, vedere [Pianificazione ed esecuzione con Data Factory](data-factory-scheduling-and-execution.md).</span><span class="sxs-lookup"><span data-stu-id="d6dec-176">See [Scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md) for detailed information.</span></span> 





  
