---
title: gli scenari di aaaData che l'archivio Data Lake | Documenti Microsoft
description: Comprendere hello diversi scenari e strumenti con i dati possono caricamento, elaborata, scaricato e visualizzato in un archivio Data Lake
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: caaa3979b8a2532089778c3e3db3c711714d3c42
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="7ffd4-103">Uso di Archivio Data Lake di Azure per requisiti Big Data</span><span class="sxs-lookup"><span data-stu-id="7ffd4-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="7ffd4-104">L'elaborazione di Big Data prevede quattro fasi principali:</span><span class="sxs-lookup"><span data-stu-id="7ffd4-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="7ffd4-105">Inserimento di grandi quantità di dati in un archivio dati, in tempo reale o in batch</span><span class="sxs-lookup"><span data-stu-id="7ffd4-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="7ffd4-106">L'elaborazione dei dati hello</span><span class="sxs-lookup"><span data-stu-id="7ffd4-106">Processing hello data</span></span>
* <span data-ttu-id="7ffd4-107">Download dei dati di hello</span><span class="sxs-lookup"><span data-stu-id="7ffd4-107">Downloading hello data</span></span>
* <span data-ttu-id="7ffd4-108">Visualizzazione dei dati hello</span><span class="sxs-lookup"><span data-stu-id="7ffd4-108">Visualizing hello data</span></span>

<span data-ttu-id="7ffd4-109">In questo articolo verranno esaminate queste fasi con riguardo tooAzure archivio Data Lake toounderstand hello opzioni e gli strumenti disponibili toomeet le esigenze di dati.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-109">In this article, we look at these stages with respect tooAzure Data Lake Store toounderstand hello options and tools available toomeet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="7ffd4-110">Inserire i dati in Archivio Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="7ffd4-111">In questa sezione evidenzia hello diverse origini dati e hello diversi modi in cui è possano caricamento dati in un account archivio Data Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-111">This section highlights hello different sources of data and hello different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="7ffd4-112">![Inserire i dati in Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Inserire i dati in Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="7ffd4-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="7ffd4-113">Dati ad hoc</span><span class="sxs-lookup"><span data-stu-id="7ffd4-113">Ad hoc data</span></span>
<span data-ttu-id="7ffd4-114">Si tratta di set di dati di piccole dimensioni usati per la creazione del prototipo di un'applicazione Big Data.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="7ffd4-115">Esistono diversi metodi per l'inserimento di dati ad hoc a seconda origine hello hello dati.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-115">There are different ways of ingesting ad hoc data depending on hello source of hello data.</span></span>

| <span data-ttu-id="7ffd4-116">origine dati</span><span class="sxs-lookup"><span data-stu-id="7ffd4-116">Data Source</span></span> | <span data-ttu-id="7ffd4-117">Inserire usando</span><span class="sxs-lookup"><span data-stu-id="7ffd4-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="7ffd4-118">Computer locale</span><span class="sxs-lookup"><span data-stu-id="7ffd4-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="7ffd4-119">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="7ffd4-120">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="7ffd4-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="7ffd4-121">Interfaccia della riga di comando multipiattaforma di Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="7ffd4-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="7ffd4-122">Usare Strumenti di Data Lake per Visual Studio</span><span class="sxs-lookup"><span data-stu-id="7ffd4-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="7ffd4-123">BLOB di Archiviazione di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="7ffd4-124">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="7ffd4-125">strumento AdlCopy</span><span class="sxs-lookup"><span data-stu-id="7ffd4-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="7ffd4-126">DistCp in esecuzione nel cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="7ffd4-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="7ffd4-127">Dati di streaming</span><span class="sxs-lookup"><span data-stu-id="7ffd4-127">Streamed data</span></span>
<span data-ttu-id="7ffd4-128">Si tratta dei dati che possono essere generati da origini diverse, ad esempio applicazioni, dispositivi, sensori, ecc. Questi dati possono essere inseriti in un Archivio Data Lake tramite strumenti diversi.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="7ffd4-129">Questi strumenti vengano in genere acquisire ed elaborare dati hello un singolo evento per evento in tempo reale e quindi scrivere gli eventi di hello in batch in archivio Data Lake in modo che possono essere elaborati ulteriormente.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-129">These tools will usually capture and process hello data on an event-by-event basis in real-time, and then write hello events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="7ffd4-130">Di seguito sono elencati gli strumenti che è possibile usare:</span><span class="sxs-lookup"><span data-stu-id="7ffd4-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="7ffd4-131">[Azure Analitica flusso](../stream-analytics/stream-analytics-data-lake-output.md) -eventi di caricamento hub di eventi possono essere scritte tooAzure Data Lake con un archivio Azure Data Lake di output.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written tooAzure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="7ffd4-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) -è possibile scrivere i dati direttamente tooData Lake archivio da hello cluster Storm.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly tooData Lake Store from hello Storm cluster.</span></span>
* <span data-ttu-id="7ffd4-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) : È possibile ricevere eventi dall'hub eventi e scriverli tooData Lake archivio utilizzando hello [Data Lake archivio .NET SDK](data-lake-store-get-started-net-sdk.md).</span><span class="sxs-lookup"><span data-stu-id="7ffd4-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it tooData Lake Store using hello [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="7ffd4-134">Dati relazionali</span><span class="sxs-lookup"><span data-stu-id="7ffd4-134">Relational data</span></span>
<span data-ttu-id="7ffd4-135">È inoltre possibile recuperare i dati dai database relazionali.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-135">You can also source data from relational databases.</span></span> <span data-ttu-id="7ffd4-136">I database relazionali raccolgono nel tempo elevate quantità di dati che possono fornire informazioni significative se elaborate tramite una pipeline Big Data.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="7ffd4-137">È possibile utilizzare tali dati hello seguenti strumenti toomove in archivio Data Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-137">You can use hello following tools toomove such data into Data Lake Store.</span></span>

* [<span data-ttu-id="7ffd4-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="7ffd4-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="7ffd4-139">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="7ffd4-140">Dati di log del server Web (caricamento tramite applicazioni personalizzate)</span><span class="sxs-lookup"><span data-stu-id="7ffd4-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="7ffd4-141">Questo tipo di set di dati è indicato in modo specifico perché l'analisi dei dati di log del server web è un caso di utilizzo comune per le applicazioni di dati e richiede grandi volumi di log file toobe caricato archivio toohello Data Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files toobe uploaded toohello Data Lake Store.</span></span> <span data-ttu-id="7ffd4-142">È possibile utilizzare uno qualsiasi dei seguenti strumenti toowrite hello tooupload proprie applicazioni o script tali dati.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-142">You can use any of hello following tools toowrite your own scripts or applications tooupload such data.</span></span>

* [<span data-ttu-id="7ffd4-143">Interfaccia della riga di comando multipiattaforma di Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="7ffd4-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="7ffd4-144">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="7ffd4-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="7ffd4-145">.NET SDK di Archivio Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="7ffd4-146">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="7ffd4-147">Per il caricamento dei dati di log del server web e per il caricamento di altri tipi di dati (ad esempio, i rispettivi social), è un buon approccio toowrite script/applicazioni personalizzate poiché consente di hello flessibilità tooinclude componente come parte di caricamento dati dell'applicazione di dati più grande.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach toowrite your own custom scripts/applications because it gives you hello flexibility tooinclude your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="7ffd4-148">In alcuni casi, questo codice potrebbe richiedere modulo hello di uno script o utilità della riga di comando semplice.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-148">In some cases this code may take hello form of a script or simple command line utility.</span></span> <span data-ttu-id="7ffd4-149">In altri casi, il codice di hello può essere utilizzato toointegrate elaborazione di big data in un'applicazione di business o una soluzione.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-149">In other cases, hello code may be used toointegrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="7ffd4-150">Dati associati ai cluster Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="7ffd4-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="7ffd4-151">La maggior parte dei tipi di cluster HDInsight (Hadoop, HBase, Storm) supportano Archivio Data Lake come repository di archiviazione dei dati.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="7ffd4-152">I cluster HDInsight accedono ai dati dai BLOB di archiviazione di Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="7ffd4-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="7ffd4-153">Per ottenere prestazioni migliori, è possibile copiare dati hello da WASB in un account archivio Data Lake associato hello cluster.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-153">For better performance, you can copy hello data from WASB into a Data Lake Store account associated with hello cluster.</span></span> <span data-ttu-id="7ffd4-154">È possibile utilizzare hello strumenti toocopy hello dati seguenti.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-154">You can use hello following tools toocopy hello data.</span></span>

* [<span data-ttu-id="7ffd4-155">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="7ffd4-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="7ffd4-156">Servizio AdlCopy</span><span class="sxs-lookup"><span data-stu-id="7ffd4-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="7ffd4-157">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="7ffd4-158">Dati archiviati in locale o in cluster IaaS Hadoop</span><span class="sxs-lookup"><span data-stu-id="7ffd4-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="7ffd4-159">Grandi quantità di dati possono essere archiviati in cluster Hadoop esistenti, localmente, nei computer che usano HDFS.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="7ffd4-160">cluster Hadoop Hello potrebbero trovarsi in una distribuzione locale o può essere all'interno di un cluster IaaS in Azure.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-160">hello Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="7ffd4-161">Può avere requisiti toocopy tooAzure tali dati archivio Data Lake per un approccio One-Off o in modo ricorrente.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-161">There could be requirements toocopy such data tooAzure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="7ffd4-162">Sono disponibili varie opzioni che è possibile utilizzare tooachieve questo.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-162">There are various options that you can use tooachieve this.</span></span> <span data-ttu-id="7ffd4-163">Di seguito è riportato un elenco di alternative e hello associati vantaggi e svantaggi.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-163">Below is a list of alternatives and hello associated trade-offs.</span></span>

| <span data-ttu-id="7ffd4-164">Approccio</span><span class="sxs-lookup"><span data-stu-id="7ffd4-164">Approach</span></span> | <span data-ttu-id="7ffd4-165">Dettagli</span><span class="sxs-lookup"><span data-stu-id="7ffd4-165">Details</span></span> | <span data-ttu-id="7ffd4-166">Vantaggi</span><span class="sxs-lookup"><span data-stu-id="7ffd4-166">Advantages</span></span> | <span data-ttu-id="7ffd4-167">Considerazioni</span><span class="sxs-lookup"><span data-stu-id="7ffd4-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="7ffd4-168">Utilizzare i dati di Azure Data Factory (ADF) toocopy direttamente dall'archivio di Hadoop cluster tooAzure Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-168">Use Azure Data Factory (ADF) toocopy data directly from Hadoop clusters tooAzure Data Lake Store</span></span> |[<span data-ttu-id="7ffd4-169">ADF supporta HDFS come origine dati</span><span class="sxs-lookup"><span data-stu-id="7ffd4-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="7ffd4-170">ADF fornisce il supporto nativo per HDFS e il monitoraggio e gestione end-to-end di prima classe</span><span class="sxs-lookup"><span data-stu-id="7ffd4-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="7ffd4-171">Richiede toobe Gateway di gestione dati distribuiti in locale o in cluster IaaS hello</span><span class="sxs-lookup"><span data-stu-id="7ffd4-171">Requires Data Management Gateway toobe deployed on-premises or in hello IaaS cluster</span></span> |
| <span data-ttu-id="7ffd4-172">Esportare dati da Hadoop come file.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="7ffd4-173">Quindi copia hello file tooAzure archivio Data Lake tramite il meccanismo appropriato.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-173">Then copy hello files tooAzure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="7ffd4-174">È possibile copiare i file tooAzure archivio Data Lake mediante:</span><span class="sxs-lookup"><span data-stu-id="7ffd4-174">You can copy files tooAzure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="7ffd4-175">Azure PowerShell per sistema operativo Windows</span><span class="sxs-lookup"><span data-stu-id="7ffd4-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="7ffd4-176">Interfaccia della riga di comando multipiattaforma di Azure 2.0 per sistemi operativi non Windows</span><span class="sxs-lookup"><span data-stu-id="7ffd4-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="7ffd4-177">Applicazione personalizzata che usa qualsiasi SDK di Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="7ffd4-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="7ffd4-178">Avvio rapido tooget.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-178">Quick tooget started.</span></span> <span data-ttu-id="7ffd4-179">È possibile eseguire caricamenti personalizzati</span><span class="sxs-lookup"><span data-stu-id="7ffd4-179">Can do customized uploads</span></span> |<span data-ttu-id="7ffd4-180">Processo in più passaggi che prevede più tecnologie.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="7ffd4-181">Gestione e monitoraggio aumenterà toobe una richiesta di verifica tramite strumenti hello natura hello personalizzato ora specificate</span><span class="sxs-lookup"><span data-stu-id="7ffd4-181">Management and monitoring will grow toobe a challenge over time given hello customized nature of hello tools</span></span> |
| <span data-ttu-id="7ffd4-182">Utilizzare dati toocopy Distcp Hadoop tooAzure archiviazione.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-182">Use Distcp toocopy data from Hadoop tooAzure Storage.</span></span> <span data-ttu-id="7ffd4-183">Copiare quindi i dati dall'archivio Lake tooData archiviazione di Azure utilizzando il meccanismo appropriato.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-183">Then copy data from Azure Storage tooData Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="7ffd4-184">È possibile copiare dati da un archivio Azure Storage tooData Lake tramite:</span><span class="sxs-lookup"><span data-stu-id="7ffd4-184">You can copy data from Azure Storage tooData Lake Store using:</span></span> <ul><li>[<span data-ttu-id="7ffd4-185">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="7ffd4-186">strumento AdlCopy</span><span class="sxs-lookup"><span data-stu-id="7ffd4-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="7ffd4-187">DistCp Apache in esecuzione nei cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="7ffd4-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="7ffd4-188">È possibile usare strumenti open source.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-188">You can use open-source tools.</span></span> |<span data-ttu-id="7ffd4-189">Processo in più passaggi che prevede più tecnologie</span><span class="sxs-lookup"><span data-stu-id="7ffd4-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="7ffd4-190">Set di dati di grandi dimensioni</span><span class="sxs-lookup"><span data-stu-id="7ffd4-190">Really large datasets</span></span>
<span data-ttu-id="7ffd4-191">Per il caricamento dei set di dati in un intervallo più terabyte, usando metodi hello descritti in precedenza può talvolta essere lenta e dispendiosa.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-191">For uploading datasets that range in several terabytes, using hello methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="7ffd4-192">In questi casi, è possibile utilizzare le opzioni di hello riportate di seguito.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-192">In such cases, you can use hello options below.</span></span>

* <span data-ttu-id="7ffd4-193">**Uso di Azure ExpressRoute**.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="7ffd4-194">Azure ExpressRoute consente di creare connessioni private tra i data center di Azure e l'infrastruttura locale.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="7ffd4-195">Ciò offre un'opzione affidabile per il trasferimento di grandi quantità di dati.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="7ffd4-196">Per altre informazioni, vedere la [Documentazione su ExpressRoute](../expressroute/expressroute-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="7ffd4-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="7ffd4-197">**Caricamento "offline" dei dati**.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="7ffd4-198">Se l'uso di Azure ExpressRoute non è fattibile per qualsiasi motivo, è possibile utilizzare [servizio di importazione/esportazione di Azure](../storage/common/storage-import-export-service.md) tooship unità disco con i dati tooan data center di Azure.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) tooship hard disk drives with your data tooan Azure data center.</span></span> <span data-ttu-id="7ffd4-199">I dati vengono prima caricato tooAzure archiviazione BLOB.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-199">Your data is first uploaded tooAzure Storage Blobs.</span></span> <span data-ttu-id="7ffd4-200">È quindi possibile utilizzare [Data Factory di Azure](../data-factory/data-factory-azure-datalake-connector.md) o [AdlCopy strumento](data-lake-store-copy-data-azure-storage-blob.md) toocopy dati da un archivio Azure archiviazione BLOB tooData Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) toocopy data from Azure Storage Blobs tooData Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="7ffd4-201">Mentre tramite hello servizio importazione/esportazione, delle dimensioni del file hello in hello dischi che si effettua la spedizione tooAzure data center non devono essere maggiore di 195 GB.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-201">While using hello Import/Export service, hello file sizes on hello disks that you ship tooAzure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="7ffd4-202">Elaborare i dati archiviati in Archivio Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="7ffd4-203">Una volta hello dati sono disponibili in archivio Data Lake è possibile eseguire analisi che i dati utilizzando hello supportati applicazioni big data.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-203">Once hello data is available in Data Lake Store you can run analysis on that data using hello supported big data applications.</span></span> <span data-ttu-id="7ffd4-204">Attualmente, è possibile utilizzare i processi di analisi dati toorun HDInsight di Azure e Azure Data Lake Analitica dati hello archiviati in archivio Data Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics toorun data analysis jobs on hello data stored in Data Lake Store.</span></span>

<span data-ttu-id="7ffd4-205">![Analizzare i dati in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analizzare i dati in Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="7ffd4-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="7ffd4-206">È possibile esaminare hello seguono esempi.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-206">You can look at hello following examples.</span></span>

* [<span data-ttu-id="7ffd4-207">Creare un cluster HDInsight con Archivio Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="7ffd4-208">Usare Azure Data Lake Analytics con Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="7ffd4-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="7ffd4-209">Scaricare i dati da Archivio Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="7ffd4-210">È anche possibile desidera toodownload o spostare i dati dall'archivio Azure Data Lake per gli scenari, ad esempio:</span><span class="sxs-lookup"><span data-stu-id="7ffd4-210">You might also want toodownload or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="7ffd4-211">Spostare dati tooother repository toointerface con le pipeline di elaborazione dei dati esistente.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-211">Move data tooother repositories toointerface with your existing data processing pipelines.</span></span> <span data-ttu-id="7ffd4-212">Ad esempio, si potrebbe essere necessario toomove dati dall'archivio Data Lake tooAzure Database SQL o SQL Server locale.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-212">For example, you might want toomove data from Data Lake Store tooAzure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="7ffd4-213">Scaricare computer locale tooyour di dati per l'elaborazione in ambienti IDE durante la creazione di prototipi di applicazioni.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-213">Download data tooyour local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="7ffd4-214">![Estrarre i dati da Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Estrarre i dati da Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="7ffd4-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="7ffd4-215">In questi casi, è possibile utilizzare uno qualsiasi dei hello le opzioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="7ffd4-215">In such cases, you can use any of hello following options:</span></span>

* [<span data-ttu-id="7ffd4-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="7ffd4-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="7ffd4-217">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="7ffd4-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="7ffd4-218">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="7ffd4-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="7ffd4-219">Consente inoltre hello seguenti metodi toowrite dati toodownload/applicazione di script da un archivio Data Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-219">You can also use hello following methods toowrite your own script/application toodownload data from Data Lake Store.</span></span>

* [<span data-ttu-id="7ffd4-220">Interfaccia della riga di comando multipiattaforma di Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="7ffd4-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="7ffd4-221">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="7ffd4-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="7ffd4-222">.NET SDK di Archivio Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="7ffd4-223">Visualizzare i dati in Archivio Data Lake</span><span class="sxs-lookup"><span data-stu-id="7ffd4-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="7ffd4-224">È possibile utilizzare una combinazione di rappresentazioni visive toocreate di servizi di dati archiviati nell'archivio Data Lake.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-224">You can use a mix of services toocreate visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="7ffd4-225">![Visualizzare i dati in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualizzare i dati in Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="7ffd4-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="7ffd4-226">È possibile avviare utilizzando [dati toomove Data Factory di Azure dall'archivio Data Lake tooAzure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span><span class="sxs-lookup"><span data-stu-id="7ffd4-226">You can start by using [Azure Data Factory toomove data from Data Lake Store tooAzure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="7ffd4-227">Successivamente, è possibile [Power BI viene integrato con Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) toocreate rappresentazione visiva dei dati di hello.</span><span class="sxs-lookup"><span data-stu-id="7ffd4-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) toocreate visual representation of hello data.</span></span>
