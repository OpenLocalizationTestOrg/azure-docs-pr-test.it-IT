---
title: "Selezione delle funzionalità nel Processo di analisi scientifica dei dati per i team | Documentazione Microsoft"
description: "Illustra le finalità della selezione delle funzioni e fornisce esempi del relativo ruolo nel processo di miglioramento dei dati di Machine Learning."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: ab97ee8278be567ff46d9b0f762d3c5c6cafa412
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 07/11/2017
---
# <a name="feature-selection-in-the-team-data-science-process-tdsp"></a><span data-ttu-id="cd20b-103">Selezione delle funzionalità nel Processo di analisi scientifica dei dati per i team (TDSP)</span><span class="sxs-lookup"><span data-stu-id="cd20b-103">Feature selection in the Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="cd20b-104">Questo articolo illustra la selezione della funzione e fornisce esempi del relativo ruolo nel processo di miglioramento dei dati di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="cd20b-104">This article explains the purposes of feature selection and provides examples of its role in the data enhancement process of machine learning.</span></span> <span data-ttu-id="cd20b-105">Questi esempi sono tratti da Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="cd20b-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="cd20b-106">La progettazione e la selezione delle funzionalità costituiscono una parte del processo TDSP descritto nel documento di [informazioni sul processo di analisi scientifica dei dati per i team](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="cd20b-106">The engineering and selection of features is one part of the Team Data Science Process (TDSP) outlined in [What is the Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="cd20b-107">La progettazione e la selezione delle funzionalità sono parti del passaggio **Sviluppare funzionalità** del processo TDSP.</span><span class="sxs-lookup"><span data-stu-id="cd20b-107">Feature engineering and selection are parts of the **Develop features** step of the TDSP.</span></span>

* <span data-ttu-id="cd20b-108">**Progettazione di funzionalità**: questo processo tenta di creare altre funzioni rilevanti dalle funzioni non elaborate esistenti nei dati e di aumentare le potenzialità predittive dell'algoritmo di apprendimento.</span><span class="sxs-lookup"><span data-stu-id="cd20b-108">**feature engineering**: This process attempts to create additional relevant features from the existing raw features in the data, and to increase predictive power to the learning algorithm.</span></span>
* <span data-ttu-id="cd20b-109">**Selezione di funzionalità**: questo processo seleziona il subset principale delle funzionalità dei dati originali nel tentativo di ridurre la dimensionalità del problema di training.</span><span class="sxs-lookup"><span data-stu-id="cd20b-109">**feature selection**: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</span></span>

<span data-ttu-id="cd20b-110">In genere, la **progettazione di funzionalità** viene applicata prima di tutto per generare altre funzionalità e quindi viene eseguito il passaggio di **selezione delle funzionalità** per eliminare quelle irrilevanti, ridondanti o altamente correlate.</span><span class="sxs-lookup"><span data-stu-id="cd20b-110">Normally **feature engineering** is applied first to generate additional features, and then the **feature selection** step is performed to eliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="cd20b-111">Filtro delle funzioni dai dati: selezione di funzioni</span><span class="sxs-lookup"><span data-stu-id="cd20b-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="cd20b-112">La selezione delle funzioni è un processo applicato comunemente per la costruzione di set di dati di training per le attività di modellazione predittive, come la classificazione o la regressione.</span><span class="sxs-lookup"><span data-stu-id="cd20b-112">Feature selection is a process that is commonly applied for the construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="cd20b-113">L'obiettivo consiste nel selezionare un subset di funzioni dal set di dati originale, che riducono le dimensioni usando un set minimo di funzioni per rappresentare la quantità massima di varianza nei dati.</span><span class="sxs-lookup"><span data-stu-id="cd20b-113">The goal is to select a subset of the features from the original dataset that reduce its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</span></span> <span data-ttu-id="cd20b-114">Questo subset di funzioni rappresenta quindi le sole funzioni da includere per il training del modello.</span><span class="sxs-lookup"><span data-stu-id="cd20b-114">This subset of features are, then, the only features to be included to train the model.</span></span> <span data-ttu-id="cd20b-115">La selezione delle funzioni ha due scopi principali.</span><span class="sxs-lookup"><span data-stu-id="cd20b-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="cd20b-116">La selezione di funzioni migliora spesso la  precisione della classificazione eliminando le funzioni irrilevanti, ridondanti o altamente correlate.</span><span class="sxs-lookup"><span data-stu-id="cd20b-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="cd20b-117">In secondo luogo, riduce il numero di funzioni rendendo più efficiente il processo di training del modello.</span><span class="sxs-lookup"><span data-stu-id="cd20b-117">Second, it decreases the number of features which makes model training process more efficient.</span></span> <span data-ttu-id="cd20b-118">Questo aspetto è particolarmente importante per gli strumenti di apprendimento, come le macchine a vettori di supporto, il cui training risulta costoso.</span><span class="sxs-lookup"><span data-stu-id="cd20b-118">This is particularly important for learners that are expensive to train such as support vector machines.</span></span>

<span data-ttu-id="cd20b-119">Anche se la selezione delle funzioni cerca di ridurre il numero di funzioni nel set di dati usato per il training del modello, non viene in genere definita con il termine "riduzione della dimensionalità".</span><span class="sxs-lookup"><span data-stu-id="cd20b-119">Although feature selection does seek to reduce the number of features in the dataset used to train the model, it is not usually referred to by the term "dimensionality reduction".</span></span> <span data-ttu-id="cd20b-120">I metodi di selezione delle funzioni estraggono un subset delle funzioni originali presenti nei dati senza apportarvi modifiche.</span><span class="sxs-lookup"><span data-stu-id="cd20b-120">Feature selection methods extract a subset of original features in the data without changing them.</span></span>  <span data-ttu-id="cd20b-121">I metodi di riduzione della dimensionalità usano funzioni progettate che possono trasformare le funzioni originali e quindi modificarle.</span><span class="sxs-lookup"><span data-stu-id="cd20b-121">Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</span></span> <span data-ttu-id="cd20b-122">Analisi in componenti principali, analisi di correlazione canonica e scomposizione di valori singolari sono esempi di metodi di riduzione della dimensionalità.</span><span class="sxs-lookup"><span data-stu-id="cd20b-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="cd20b-123">Tra le altre, una categoria di funzioni ampiamente applicata in un contesto supervisionato è detta "Selezione delle funzioni basata su filtro".</span><span class="sxs-lookup"><span data-stu-id="cd20b-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="cd20b-124">Tramite la valutazione della correlazione tra ogni funzione e l'attributo di destinazione, questi metodi applicano una misura statistica per assegnare un punteggio a ogni funzione.</span><span class="sxs-lookup"><span data-stu-id="cd20b-124">By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</span></span> <span data-ttu-id="cd20b-125">Queste funzioni vengono quindi classificate in base al punteggio, che può essere usato per facilitare l'impostazione della soglia per mantenere o eliminare una funzione specifica.</span><span class="sxs-lookup"><span data-stu-id="cd20b-125">The features are then ranked by the score, which may be used to help set the threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="cd20b-126">Correlazione di Pearson, informazione mutua e test del chi quadrato sono esempi di misure statistiche usate in questi metodi.</span><span class="sxs-lookup"><span data-stu-id="cd20b-126">Examples of the statistical measures used in these methods include Person correlation, mutual information, and the Chi squared test.</span></span>

<span data-ttu-id="cd20b-127">In Azure Machine Learning Studio sono disponibili moduli per la selezione delle funzioni.</span><span class="sxs-lookup"><span data-stu-id="cd20b-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="cd20b-128">Come illustrato nella figura seguente, questi moduli includono [Filter-Based Feature Selection][filter-based-feature-selection] (Selezione di funzionalità in base al filtro) e [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis] (Analisi discriminante lineare di Fisher).</span><span class="sxs-lookup"><span data-stu-id="cd20b-128">As shown in the following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="cd20b-130">Si consideri ad esempio l'uso del modulo [Filter-Based Feature Selection][filter-based-feature-selection] (Selezione di funzionalità in base al filtro).</span><span class="sxs-lookup"><span data-stu-id="cd20b-130">Consider, for example, the use of the [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="cd20b-131">Per praticità, si continuerà a usare l'esempio di data mining del testo illustrato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="cd20b-131">For the purpose of convenience, we continue to use the text mining example outlined above.</span></span> <span data-ttu-id="cd20b-132">Si supponga di voler compilare un modello di regressione in base a un set di 256 funzionalità create con il modulo [Feature Hashing][feature-hashing] (Hash delle funzionalità) e che la variabile di risposta sia "Col1" e rappresenti le classificazioni delle recensioni di un libro in un intervallo da 1 a 5.</span><span class="sxs-lookup"><span data-stu-id="cd20b-132">Assume that we want to build a regression model after a set of 256 features are created through the [Feature Hashing][feature-hashing] module, and that the response variable is the "Col1" and represents a book review ratings ranging from 1 to 5.</span></span> <span data-ttu-id="cd20b-133">Impostando "Feature scoring method" su "Pearson Correlation", "Target column" su "Col1" e "Number of desired features" su 50,</span><span class="sxs-lookup"><span data-stu-id="cd20b-133">By setting "Feature scoring method" to be "Pearson Correlation", the "Target column" to be "Col1", and the "Number of desired features" to 50.</span></span> <span data-ttu-id="cd20b-134">il modulo [Filter-Based Feature Selection][filter-based-feature-selection] (Selezione di funzionalità in base al filtro) produrrà un set di dati contenente 50 funzionalità insieme all'attributo di destinazione "Col1".</span><span class="sxs-lookup"><span data-stu-id="cd20b-134">Then the module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with the target attribute "Col1".</span></span> <span data-ttu-id="cd20b-135">La figura seguente mostra il flusso dell'esperimenti e i parametri di input appena descritti.</span><span class="sxs-lookup"><span data-stu-id="cd20b-135">The following figure shows the flow of this experiment and the input parameters we just described.</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="cd20b-137">La figura seguente mostra i set di dati risultanti.</span><span class="sxs-lookup"><span data-stu-id="cd20b-137">The following figure shows the resulting datasets.</span></span> <span data-ttu-id="cd20b-138">Il punteggio di ogni funzione viene calcolato in base alla correlazione di Pearson tra la funzione stessa e l'attributo di destinazione "Col1".</span><span class="sxs-lookup"><span data-stu-id="cd20b-138">Each feature is scored based on the Pearson Correlation between itself and the target attribute "Col1".</span></span> <span data-ttu-id="cd20b-139">Vengono mantenute le funzioni con i punteggi più alti.</span><span class="sxs-lookup"><span data-stu-id="cd20b-139">The features with top scores are kept.</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="cd20b-141">I corrispondenti punteggi delle funzioni selezionate sono illustrati nella figura seguente.</span><span class="sxs-lookup"><span data-stu-id="cd20b-141">The corresponding scores of the selected features are shown in the following figure.</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="cd20b-143">Applicando questo modulo [Filter-Based Feature Selection][filter-based-feature-selection] (Selezione di funzionalità in base al filtro) vengono selezionate 50 delle 256 funzionalità perché presentano le funzioni maggiormente correlate con la variabile di destinazione "Col1", sulla base del metodo di assegnazione dei punteggi denominato "correlazione di Pearson".</span><span class="sxs-lookup"><span data-stu-id="cd20b-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have the most correlated features with the target variable "Col1", based on the scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="cd20b-144">Conclusione</span><span class="sxs-lookup"><span data-stu-id="cd20b-144">Conclusion</span></span>
<span data-ttu-id="cd20b-145">La progettazione delle funzionalità e la selezione delle funzionalità sono due funzionalità progettate e selezionate che migliorano l'efficienza del processo di training che tenta di estrarre le informazioni essenziali contenute nei dati.</span><span class="sxs-lookup"><span data-stu-id="cd20b-145">Feature engineering and feature selection are two commonly Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</span></span> <span data-ttu-id="cd20b-146">Migliorano anche le potenzialità di questi modelli per la classificazione accurata dei dati di input e per la stima più affidabile dei risultati di interesse.</span><span class="sxs-lookup"><span data-stu-id="cd20b-146">They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</span></span> <span data-ttu-id="cd20b-147">Progettazione e selezione delle funzioni possono anche combinarsi per rendere l'apprendimento più computazionalmente trattabile.</span><span class="sxs-lookup"><span data-stu-id="cd20b-147">Feature engineering and selection can also combine to make the learning more computationally tractable.</span></span> <span data-ttu-id="cd20b-148">Questa operazione viene eseguita tramite il miglioramento e la successiva riduzione del numero di funzioni richieste per calibrare o eseguire il training di un modello.</span><span class="sxs-lookup"><span data-stu-id="cd20b-148">It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</span></span> <span data-ttu-id="cd20b-149">Da un punto di vista matematico, le funzioni selezionate per eseguire il training di un modello sono costituite da un set minimo di variabili indipendenti che spiegano i modelli nei dati e quindi stimano correttamente i risultati.</span><span class="sxs-lookup"><span data-stu-id="cd20b-149">Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</span></span>

<span data-ttu-id="cd20b-150">Si noti che non sempre è necessario eseguire la progettazione o la selezione delle funzioni.</span><span class="sxs-lookup"><span data-stu-id="cd20b-150">Note that it is not always necessarily to perform feature engineering or feature selection.</span></span> <span data-ttu-id="cd20b-151">La necessità o meno di questi passaggi dipende dai dati da raccogliere, dagli algoritmi scelti e dall'obiettivo dell'esperimento.</span><span class="sxs-lookup"><span data-stu-id="cd20b-151">Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/

