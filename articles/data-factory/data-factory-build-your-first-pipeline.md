---
title: 'Esercitazione su Data Factory: prima pipeline di dati | Documentazione Microsoft'
description: Questa esercitazione di Azure Data Factory illustra come creare e pianificare una data factory che elabora i dati usando uno script Hive in un cluster Hadoop.
services: data-factory
keywords: esercitazione di azure data factory, cluster hadoop, hive di hadoop
documentationcenter: 
author: spelluru
manager: jhubbard
editor: 
ms.assetid: 81f36c76-6e78-4d93-a3f2-0317b413f1d0
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 08e2988d455cca21726162d9fb128e91fd51f463
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/29/2017
---
# <a name="tutorial-build-your-first-pipeline-to-transform-data-using-hadoop-cluster"></a><span data-ttu-id="90877-104">Esercitazione: Creare la prima pipeline per trasformare i dati usando il cluster Hadoop</span><span class="sxs-lookup"><span data-stu-id="90877-104">Tutorial: Build your first pipeline to transform data using Hadoop cluster</span></span>
> [!div class="op_single_selector"]
> * [<span data-ttu-id="90877-105">Panoramica e prerequisiti</span><span class="sxs-lookup"><span data-stu-id="90877-105">Overview and prerequisites</span></span>](data-factory-build-your-first-pipeline.md)
> * [<span data-ttu-id="90877-106">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="90877-106">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
> * [<span data-ttu-id="90877-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="90877-107">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
> * [<span data-ttu-id="90877-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="90877-108">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
> * [<span data-ttu-id="90877-109">Modello di Resource Manager</span><span class="sxs-lookup"><span data-stu-id="90877-109">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
> * [<span data-ttu-id="90877-110">API REST</span><span class="sxs-lookup"><span data-stu-id="90877-110">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="90877-111">In questa esercitazione si compila la prima data factory di Azure con una pipeline di dati.</span><span class="sxs-lookup"><span data-stu-id="90877-111">In this tutorial, you build your first Azure data factory with a data pipeline.</span></span> <span data-ttu-id="90877-112">La pipeline trasforma i dati di input tramite l'esecuzione di script Hive su un cluster Azure HDInsight (Hadoop) per generare i dati di output.</span><span class="sxs-lookup"><span data-stu-id="90877-112">The pipeline transforms input data by running Hive script on an Azure HDInsight (Hadoop) cluster to produce output data.</span></span>  

<span data-ttu-id="90877-113">Questo articolo fornisce una panoramica e i prerequisiti per l'esercitazione.</span><span class="sxs-lookup"><span data-stu-id="90877-113">This article provides overview and prerequisites for the tutorial.</span></span> <span data-ttu-id="90877-114">Dopo avere completato i prerequisiti, è possibile eseguire l'esercitazione usando uno degli strumenti/SDK seguenti: Portale di Azure, Visual Studio, PowerShell, modello di Resource Manager, API REST.</span><span class="sxs-lookup"><span data-stu-id="90877-114">After you complete the prerequisites, you can do the tutorial using one of the following tools/SDKs: Azure portal, Visual Studio, PowerShell, Resource Manager template, REST API.</span></span> <span data-ttu-id="90877-115">Selezionare una delle opzioni nell'elenco a discesa all'inizio o i collegamenti alla fine di questo articolo per eseguire l'esercitazione sull'uso di una di queste opzioni.</span><span class="sxs-lookup"><span data-stu-id="90877-115">Select one of the options in the drop-down list at the beginning (or) links at the end of this article to do the tutorial using one of these options.</span></span>    

## <a name="tutorial-overview"></a><span data-ttu-id="90877-116">Panoramica dell'esercitazione</span><span class="sxs-lookup"><span data-stu-id="90877-116">Tutorial overview</span></span>
<span data-ttu-id="90877-117">In questa esercitazione si segue questa procedura:</span><span class="sxs-lookup"><span data-stu-id="90877-117">In this tutorial, you perform the following steps:</span></span>

1. <span data-ttu-id="90877-118">Creare una **data factory**.</span><span class="sxs-lookup"><span data-stu-id="90877-118">Create a **data factory**.</span></span> <span data-ttu-id="90877-119">Una data factory può contenere una o più pipeline di dati che spostano e trasformano i dati.</span><span class="sxs-lookup"><span data-stu-id="90877-119">A data factory can contain one or more data pipelines that move and transform data.</span></span> 

    <span data-ttu-id="90877-120">In questa esercitazione si creerà una pipeline nella data factory.</span><span class="sxs-lookup"><span data-stu-id="90877-120">In this tutorial, you create one pipeline in the data factory.</span></span> 
2. <span data-ttu-id="90877-121">Creare una **pipeline**.</span><span class="sxs-lookup"><span data-stu-id="90877-121">Create a **pipeline**.</span></span> <span data-ttu-id="90877-122">Una pipeline può comprendere una o più attività (esempi: attività di copia, attività Hive HDInsight).</span><span class="sxs-lookup"><span data-stu-id="90877-122">A pipeline can have one or more activities (Examples: Copy Activity, HDInsight Hive Activity).</span></span> <span data-ttu-id="90877-123">In questo esempio viene usata un'attività Hive di HDInsight che esegue uno script Hive in un cluster Hadoop di HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90877-123">This sample uses the HDInsight Hive activity that runs a Hive script on a HDInsight Hadoop cluster.</span></span> <span data-ttu-id="90877-124">Lo script crea prima di tutto una tabella che fa riferimento ai dati di blog non elaborati contenuti nell'archivio BLOB di Azure e quindi esegue il partizionamento dei dati non elaborati per anno e per mese.</span><span class="sxs-lookup"><span data-stu-id="90877-124">The script first creates a table that references the raw web log data stored in Azure blob storage and then partitions the raw data by year and month.</span></span>

    <span data-ttu-id="90877-125">In questa esercitazione, la pipeline usa l'attività Hive per trasformare i dati eseguendo una query Hive in un cluster Hadoop di HDInsight di Azure.</span><span class="sxs-lookup"><span data-stu-id="90877-125">In this tutorial, the pipeline uses the Hive Activity to transform data by running a Hive query on an Azure HDInsight Hadoop cluster.</span></span> 
3. <span data-ttu-id="90877-126">Creare **servizi collegati**.</span><span class="sxs-lookup"><span data-stu-id="90877-126">Create **linked services**.</span></span> <span data-ttu-id="90877-127">Creare un servizio collegato per collegare un archivio dati o un servizio di calcolo alla data factory.</span><span class="sxs-lookup"><span data-stu-id="90877-127">You create a linked service to link a data store or a compute service to the data factory.</span></span> <span data-ttu-id="90877-128">Un archivio dati come Archiviazione di Azure contiene i dati di input/output delle attività nella pipeline.</span><span class="sxs-lookup"><span data-stu-id="90877-128">A data store such as Azure Storage holds input/output data of activities in the pipeline.</span></span> <span data-ttu-id="90877-129">Un servizio di calcolo come un cluster Hadoop di HDInsight elabora/trasforma i dati.</span><span class="sxs-lookup"><span data-stu-id="90877-129">A compute service such as HDInsight Hadoop cluster processes/transforms data.</span></span>

    <span data-ttu-id="90877-130">In questa esercitazione guidata si creano due servizi collegati : **Archiviazione di Azure** e **Azure HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="90877-130">In this tutorial, you create two linked services: **Azure Storage** and **Azure HDInsight**.</span></span> <span data-ttu-id="90877-131">Il servizio collegato Archiviazione di Azure collega un account di archiviazione di Azure contenente i dati di input/output alla data factory.</span><span class="sxs-lookup"><span data-stu-id="90877-131">The Azure Storage linked service links an Azure Storage Account that holds the input/output data to the data factory.</span></span> <span data-ttu-id="90877-132">Il servizio collegato Azure HDInsight collega un cluster HDInsight di Azure usato per trasformare i dati alla data factory.</span><span class="sxs-lookup"><span data-stu-id="90877-132">Azure HDInsight linked service links an Azure HDInsight cluster that is used to transform data to the data factory.</span></span> 
3. <span data-ttu-id="90877-133">Creare **set di dati**di input e di output.</span><span class="sxs-lookup"><span data-stu-id="90877-133">Create input and output **datasets**.</span></span> <span data-ttu-id="90877-134">Un set di dati di input rappresenta l'input per un'attività nella pipeline, un set di dati di output rappresenta l'output dell'attività.</span><span class="sxs-lookup"><span data-stu-id="90877-134">An input dataset represents the input for an activity in the pipeline and an output dataset represents the output for the activity.</span></span>

    <span data-ttu-id="90877-135">In questa esercitazione i set di dati di input e output specificano i percorsi dei dati di input e output nell'Archiviazione BLOB di Azure.</span><span class="sxs-lookup"><span data-stu-id="90877-135">In this tutorial, the input and output datasets specify locations of input and output data in the Azure Blob Storage.</span></span> <span data-ttu-id="90877-136">Il servizio collegato Archiviazione di Azure specifica l'account di archiviazione di Azure che viene usato.</span><span class="sxs-lookup"><span data-stu-id="90877-136">The Azure Storage linked service specifies what Azure Storage Account is used.</span></span> <span data-ttu-id="90877-137">Un set di dati di input specifica la posizione in cui si trovano i file di input e un set di dati di output specifica la posizione in cui verranno inseriti i file di output.</span><span class="sxs-lookup"><span data-stu-id="90877-137">An input dataset specifies where the input files are located and an output dataset specifies where the output files are placed.</span></span> 


<span data-ttu-id="90877-138">Per una panoramica dettagliata di Azure Data Factory, vedere l'articolo [Introduzione al servizio Azure Data Factory](data-factory-introduction.md) .</span><span class="sxs-lookup"><span data-stu-id="90877-138">See [Introduction to Azure Data Factory](data-factory-introduction.md) article for a detailed overview of Azure Data Factory.</span></span>
  
<span data-ttu-id="90877-139">Di seguito è riportata la **vista diagramma** della data factory di esempio creata in questa esercitazione.</span><span class="sxs-lookup"><span data-stu-id="90877-139">Here is the **diagram view** of the sample data factory you build in this tutorial.</span></span> <span data-ttu-id="90877-140">**MyFirstPipeline** ha un'attività di tipo Hive che usa i set di dati **AzureBlobInput** come input e produce set di dati **AzureBlobOutput** come output.</span><span class="sxs-lookup"><span data-stu-id="90877-140">**MyFirstPipeline** has one activity of type Hive that consumes **AzureBlobInput** dataset as an input and produces **AzureBlobOutput** dataset as an output.</span></span> 

![Vista diagramma nell'esercitazione su Data Factory](media/data-factory-build-your-first-pipeline/data-factory-tutorial-diagram-view.png)


<span data-ttu-id="90877-142">In questa esercitazione la cartella **inputdata** del contenitore BLOB di Azure **adfgetstarted** contiene un file denominato input.log.</span><span class="sxs-lookup"><span data-stu-id="90877-142">In this tutorial, **inputdata** folder of the **adfgetstarted** Azure blob container contains one file named input.log.</span></span> <span data-ttu-id="90877-143">Questo file di log contiene voci relative ai tre mesi di gennaio, febbraio e marzo 2016.</span><span class="sxs-lookup"><span data-stu-id="90877-143">This log file has entries from three months: January, February, and March of 2016.</span></span> <span data-ttu-id="90877-144">Ecco le righe di esempio per ogni mese nel file di input.</span><span class="sxs-lookup"><span data-stu-id="90877-144">Here are the sample rows for each month in the input file.</span></span> 

```
2016-01-01,02:01:09,SAMPLEWEBSITE,GET,/blogposts/mvc4/step2.png,X-ARR-LOG-ID=2ec4b8ad-3cf0-4442-93ab-837317ece6a1,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,53175,871 
2016-02-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
2016-03-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
```

<span data-ttu-id="90877-145">Quando il file viene elaborato dalla pipeline con attività Hive di HDInsight, l'attività esegue uno script Hive nel cluster HDInsight che esegue il partizionamento dei dati di input per anno e per mese.</span><span class="sxs-lookup"><span data-stu-id="90877-145">When the file is processed by the pipeline with HDInsight Hive Activity, the activity runs a Hive script on the HDInsight cluster that partitions input data by year and month.</span></span> <span data-ttu-id="90877-146">Lo script crea tre cartelle di output che contengono un file con le voci di ogni mese.</span><span class="sxs-lookup"><span data-stu-id="90877-146">The script creates three output folders that contain a file with entries from each month.</span></span>  

```
adfgetstarted/partitioneddata/year=2016/month=1/000000_0
adfgetstarted/partitioneddata/year=2016/month=2/000000_0
adfgetstarted/partitioneddata/year=2016/month=3/000000_0
```

<span data-ttu-id="90877-147">Delle righe di esempio riportate sopra, la prima (con 2016-01-01) viene scritta nel file 000000_0 nella cartella month=1.</span><span class="sxs-lookup"><span data-stu-id="90877-147">From the sample lines shown above, the first one (with 2016-01-01) is written to the 000000_0 file in the month=1 folder.</span></span> <span data-ttu-id="90877-148">Allo stesso modo, la seconda viene scritta nel file nella cartella month=2 e la terza viene scritta nel file nella cartella month=3.</span><span class="sxs-lookup"><span data-stu-id="90877-148">Similarly, the second one is written to the file in the month=2 folder and the third one is written to the file in the month=3 folder.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="90877-149">Prerequisiti</span><span class="sxs-lookup"><span data-stu-id="90877-149">Prerequisites</span></span>
<span data-ttu-id="90877-150">Prima di iniziare questa esercitazione, sono necessari i prerequisiti seguenti:</span><span class="sxs-lookup"><span data-stu-id="90877-150">Before you begin this tutorial, you must have the following prerequisites:</span></span>

1. <span data-ttu-id="90877-151">**Sottoscrizione di Azure** : se non è disponibile una sottoscrizione di Azure, è possibile creare un account di valutazione gratuito in pochi minuti.</span><span class="sxs-lookup"><span data-stu-id="90877-151">**Azure subscription** - If you don't have an Azure subscription, you can create a free trial account in just a couple of minutes.</span></span> <span data-ttu-id="90877-152">Vedere l'articolo [Versione di valutazione gratuita](https://azure.microsoft.com/pricing/free-trial/) per informazioni su come ottenere un account di valutazione gratuito.</span><span class="sxs-lookup"><span data-stu-id="90877-152">See the [Free Trial](https://azure.microsoft.com/pricing/free-trial/) article on how you can obtain a free trial account.</span></span>
2. <span data-ttu-id="90877-153">**Archiviazione di Azure**: in questa esercitazione si usa un account di archiviazione di Azure per utilizzo generico per archiviare i dati.</span><span class="sxs-lookup"><span data-stu-id="90877-153">**Azure Storage** – You use a general-purpose standard Azure storage account for storing the data in this tutorial.</span></span> <span data-ttu-id="90877-154">Se non si ha un account di archiviazione di Azure per utilizzo generico, vedere l'articolo [Creare un account di archiviazione di Azure](../storage/common/storage-create-storage-account.md#create-a-storage-account).</span><span class="sxs-lookup"><span data-stu-id="90877-154">If you don't have a general-purpose standard Azure storage account, see the [Create a storage account](../storage/common/storage-create-storage-account.md#create-a-storage-account) article.</span></span> <span data-ttu-id="90877-155">Dopo aver creato l'account di archiviazione, annotare il **nome dell'account** e la **chiave di accesso**.</span><span class="sxs-lookup"><span data-stu-id="90877-155">After you have created the storage account, note down the **account name** and **access key**.</span></span> <span data-ttu-id="90877-156">Vedere [Visualizzare, copiare e rigenerare le chiavi di accesso alle risorse di archiviazione](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span><span class="sxs-lookup"><span data-stu-id="90877-156">See [View, copy and regenerate storage access keys](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span></span>
3. <span data-ttu-id="90877-157">Scaricare e leggere il file di query Hive (**HQL**) disponibile all'indirizzo: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span><span class="sxs-lookup"><span data-stu-id="90877-157">Download and review the Hive query file (**HQL**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span></span> <span data-ttu-id="90877-158">Questa query trasforma i dati di input per generare i dati di output.</span><span class="sxs-lookup"><span data-stu-id="90877-158">This query transforms input data to produce output data.</span></span> 
4. <span data-ttu-id="90877-159">Scaricare e leggere il file di input di esempio (**input.log**) disponibile all'indirizzo: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span><span class="sxs-lookup"><span data-stu-id="90877-159">Download and review the sample input file (**input.log**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span></span>
5. <span data-ttu-id="90877-160">Creare un contenitore BLOB denominato **adfgetstarted** nell'Archiviazione BLOB di Azure.</span><span class="sxs-lookup"><span data-stu-id="90877-160">Create a blob container named **adfgetstarted** in your Azure Blob Storage.</span></span> 
6. <span data-ttu-id="90877-161">Caricare il file **partitionweblogs.hql** nella cartella **script** nel contenitore **adfgetstarted**.</span><span class="sxs-lookup"><span data-stu-id="90877-161">Upload **partitionweblogs.hql** file to the **script** folder in the **adfgetstarted** container.</span></span> <span data-ttu-id="90877-162">Usare strumenti come [Esplora archivi di Microsoft Azure](http://storageexplorer.com/).</span><span class="sxs-lookup"><span data-stu-id="90877-162">Use tools such as [Microsoft Azure Storage Explorer](http://storageexplorer.com/).</span></span> 
7. <span data-ttu-id="90877-163">Caricare il file**input.log** nella cartella **inputdata** nel contenitore **adfgetstarted**.</span><span class="sxs-lookup"><span data-stu-id="90877-163">Upload **input.log** file to the **inputdata** folder in the **adfgetstarted** container.</span></span> 

<span data-ttu-id="90877-164">Dopo avere completato i prerequisiti, selezionare uno dei seguenti strumenti/SDK per eseguire l'esercitazione:</span><span class="sxs-lookup"><span data-stu-id="90877-164">After you complete the prerequisites, select one of the following tools/SDKs to do the tutorial:</span></span> 

- [<span data-ttu-id="90877-165">Portale di Azure</span><span class="sxs-lookup"><span data-stu-id="90877-165">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
- [<span data-ttu-id="90877-166">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="90877-166">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
- [<span data-ttu-id="90877-167">PowerShell</span><span class="sxs-lookup"><span data-stu-id="90877-167">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
- [<span data-ttu-id="90877-168">Modello di Resource Manager</span><span class="sxs-lookup"><span data-stu-id="90877-168">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
- [<span data-ttu-id="90877-169">API REST</span><span class="sxs-lookup"><span data-stu-id="90877-169">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="90877-170">Il portale di Azure e Visual Studio forniscono l'interfaccia utente grafica per la creazione di data factory.</span><span class="sxs-lookup"><span data-stu-id="90877-170">Azure portal and Visual Studio provide GUI way of building your data factories.</span></span> <span data-ttu-id="90877-171">Le opzioni PowerShell, il modello di Resource Manager e l'API REST forniscono una modalità di programmazione/script per la creazione di data factory.</span><span class="sxs-lookup"><span data-stu-id="90877-171">Whereas, PowerShell, Resource Manager Template, and REST API options provides scripting/programming way of building your data factories.</span></span>

> [!NOTE]
> <span data-ttu-id="90877-172">La pipeline di dati in questa esercitazione trasforma i dati di input per produrre dati di output.</span><span class="sxs-lookup"><span data-stu-id="90877-172">The data pipeline in this tutorial transforms input data to produce output data.</span></span> <span data-ttu-id="90877-173">Non copia dati da un archivio dati di origine a un archivio dati di destinazione.</span><span class="sxs-lookup"><span data-stu-id="90877-173">It does not copy data from a source data store to a destination data store.</span></span> <span data-ttu-id="90877-174">Per un'esercitazione su come copiare dati usando Azure Data Factory, vedere [Copiare dati da un archivio BLOB al database SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="90877-174">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
> 
> <span data-ttu-id="90877-175">È possibile concatenare due attività, ovvero eseguire un'attività dopo l'altra, impostando il set di dati di output di un'attività come set di dati di input di altre attività.</span><span class="sxs-lookup"><span data-stu-id="90877-175">You can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="90877-176">Per informazioni dettagliate, vedere [Pianificazione ed esecuzione con Data Factory](data-factory-scheduling-and-execution.md).</span><span class="sxs-lookup"><span data-stu-id="90877-176">See [Scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md) for detailed information.</span></span> 





  
