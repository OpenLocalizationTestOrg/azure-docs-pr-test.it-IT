---
title: Linee guida per l'ottimizzazione delle prestazioni di Azure Data Lake Store | Microsoft Docs
description: Linee guida per l'ottimizzazione delle prestazioni di Azure Data Lake Store
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: e7ea83465328bd4c7479dec4093cd94700463854
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 07/11/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="6e4d3-103">Ottimizzazione delle prestazioni di Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="6e4d3-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="6e4d3-104">Data Lake Store supporta la velocità effettiva elevata per l'analisi con uso intensivo dell'I/O e lo spostamento dei dati.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="6e4d3-105">In Azure Data Lake Store è importante poter usare tutta la velocità effettiva disponibile, ovvero la quantità di dati che possono essere letti o scritti al secondo, per ottenere prestazioni ottimali.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-105">In Azure Data Lake Store, using all available throughput – the amount of data that can be read or written per second – is important to get the best performance.</span></span>  <span data-ttu-id="6e4d3-106">Questo risultato viene ottenuto eseguendo il numero massimo possibile di operazioni di lettura e scrittura in parallelo.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Prestazioni di Data Lake Store](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="6e4d3-108">Azure Data Lake Store può essere ridimensionato in modo da fornire la velocità effettiva necessaria per qualsiasi scenario di analisi.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-108">Azure Data Lake Store can scale to provide the necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="6e4d3-109">Per impostazione predefinita, un account di Azure Data Lake Store fornisce automaticamente la velocità effettiva sufficiente per soddisfare le esigenze di un'ampia categoria di casi d'uso.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-109">By default, an Azure Data Lake Store account provides automatically enough throughput to meet the needs of a broad category of use cases.</span></span> <span data-ttu-id="6e4d3-110">Per i casi in cui i clienti raggiungono il limite predefinito, è possibile contattare il supporto tecnico Microsoft per configurare l'account ADLS in modo da ottenere maggiore velocità effettiva.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-110">For the cases where customers run into the default limit, the ADLS account can be configured to provide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="6e4d3-111">Inserimento di dati</span><span class="sxs-lookup"><span data-stu-id="6e4d3-111">Data ingestion</span></span>

<span data-ttu-id="6e4d3-112">Durante l'inserimento di dati da un sistema di origine ad ADLS, è importante tenere presente che l'hardware di origine, l'hardware di rete di origine e la connettività di rete ad ADLS può costituire il collo di bottiglia.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-112">When ingesting data from a source system to ADLS, it is important to consider that the source hardware, source network hardware, and network connectivity to ADLS can be the bottleneck.</span></span>  

![Prestazioni di Data Lake Store](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="6e4d3-114">È importante verificare che questi fattori non influiscano sullo spostamento dei dati.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-114">It is important to ensure that the data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="6e4d3-115">Hardware di origine</span><span class="sxs-lookup"><span data-stu-id="6e4d3-115">Source Hardware</span></span>

<span data-ttu-id="6e4d3-116">Indipendentemente dall'uso di computer locali o macchine virtuali in Azure, è necessario scegliere con attenzione l'hardware appropriato.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select the appropriate hardware.</span></span> <span data-ttu-id="6e4d3-117">Per l'hardware del disco di origine, preferire le unità SSD alle HDD e scegliere hardware con spindle più veloci.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-117">For Source Disk Hardware, prefer SSDs to HDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="6e4d3-118">Per l'hardware di rete di origine, usare le schede di interfaccia di rete più veloci possibili.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-118">For Source Network Hardware, use the fastest NICs possible.</span></span>  <span data-ttu-id="6e4d3-119">In Azure è consigliabile usare macchine virtuali Azure D14 che sono dotate di hardware di rete e del disco sufficientemente potente.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-119">On Azure, we recommend Azure D14 VMs which have the appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-to-azure-data-lake-store"></a><span data-ttu-id="6e4d3-120">Connettività di rete ad Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="6e4d3-120">Network Connectivity to Azure Data Lake Store</span></span>

<span data-ttu-id="6e4d3-121">La connettività di rete tra i dati di origine e Azure Data Lake Store può talvolta costituire il collo di bottiglia.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-121">The network connectivity between your source data and Azure Data Lake store can sometimes be the bottleneck.</span></span> <span data-ttu-id="6e4d3-122">Quando i dati di origine sono in locale, valutare l'opportunità di usare un collegamento dedicato con [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span><span class="sxs-lookup"><span data-stu-id="6e4d3-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="6e4d3-123">Se i dati di origine sono in Azure, si ottengono prestazioni ottimali quando i dati si trovano nella stessa area di Azure usata da Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-123">If your source data is in Azure, the performance will be best when the data is in the same Azure region as the Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="6e4d3-124">Configurare gli strumenti di inserimento di dati per la massima parallelizzazione</span><span class="sxs-lookup"><span data-stu-id="6e4d3-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="6e4d3-125">Dopo aver risolto i colli di bottiglia provocati dall'hardware di origine e dalla connettività di rete, si è pronti per configurare gli strumenti di inserimento.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-125">Once you have addressed the source hardware and network connectivity bottlenecks above, you are ready to configure your ingestion tools.</span></span> <span data-ttu-id="6e4d3-126">La tabella seguente presenta un riepilogo delle impostazioni delle chiavi per diversi strumenti di inserimento comuni e include collegamenti ad articoli di approfondimento sull'ottimizzazione delle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-126">The following table summarizes the key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="6e4d3-127">Per altre informazioni sullo strumento da usare per uno scenario specifico, vedere questo [articolo](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span><span class="sxs-lookup"><span data-stu-id="6e4d3-127">To learn more about which tool to use for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="6e4d3-128">Strumento</span><span class="sxs-lookup"><span data-stu-id="6e4d3-128">Tool</span></span>               | <span data-ttu-id="6e4d3-129">Impostazioni</span><span class="sxs-lookup"><span data-stu-id="6e4d3-129">Settings</span></span>     | <span data-ttu-id="6e4d3-130">Altre informazioni</span><span class="sxs-lookup"><span data-stu-id="6e4d3-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="6e4d3-131">PowerShell</span><span class="sxs-lookup"><span data-stu-id="6e4d3-131">Powershell</span></span>       | <span data-ttu-id="6e4d3-132">PerFileThreadCount, ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="6e4d3-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="6e4d3-133">Collegamento</span><span class="sxs-lookup"><span data-stu-id="6e4d3-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="6e4d3-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="6e4d3-134">AdlCopy</span></span>    | <span data-ttu-id="6e4d3-135">Unità Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="6e4d3-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="6e4d3-136">Collegamento</span><span class="sxs-lookup"><span data-stu-id="6e4d3-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="6e4d3-137">DistCp</span><span class="sxs-lookup"><span data-stu-id="6e4d3-137">DistCp</span></span>            | <span data-ttu-id="6e4d3-138">-m (mapper)</span><span class="sxs-lookup"><span data-stu-id="6e4d3-138">-m (mapper)</span></span>   | [<span data-ttu-id="6e4d3-139">Collegamento</span><span class="sxs-lookup"><span data-stu-id="6e4d3-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="6e4d3-140">Data factory di Azure</span><span class="sxs-lookup"><span data-stu-id="6e4d3-140">Azure Data Factory</span></span>| <span data-ttu-id="6e4d3-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="6e4d3-141">parallelCopies</span></span>    | [<span data-ttu-id="6e4d3-142">Collegamento</span><span class="sxs-lookup"><span data-stu-id="6e4d3-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="6e4d3-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="6e4d3-143">Sqoop</span></span>           | <span data-ttu-id="6e4d3-144">fs.azure.block.size, -m (mapper)</span><span class="sxs-lookup"><span data-stu-id="6e4d3-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="6e4d3-145">Collegamento</span><span class="sxs-lookup"><span data-stu-id="6e4d3-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="6e4d3-146">Strutturare il set di dati</span><span class="sxs-lookup"><span data-stu-id="6e4d3-146">Structure your data set</span></span>

<span data-ttu-id="6e4d3-147">Quando i dati vengono archiviati in Data Lake Store, le dimensioni dei file, il numero di file e la struttura di cartelle influiscono sulle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-147">When data is stored in Data Lake Store, the file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="6e4d3-148">La sezione seguente descrive le procedure consigliate in queste aree.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-148">The following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="6e4d3-149">Dimensioni complete</span><span class="sxs-lookup"><span data-stu-id="6e4d3-149">File size</span></span>

<span data-ttu-id="6e4d3-150">I motori di analisi come HDInsight e Azure Data Lake Analytics in genere gestiscono il sovraccarico a livello di singolo file.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="6e4d3-151">Se quindi si archiviano i dati in molti file di piccole dimensioni, questo può influire negativamente sulle prestazioni.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="6e4d3-152">Per ottenere prestazioni migliori, è in genere opportuno organizzare i dati in file di dimensioni più grandi.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="6e4d3-153">Come regola generale, organizzare i set di dati in file di 256 MB o di dimensione maggiore.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="6e4d3-154">In alcuni casi, ad esempio per le immagini e i dati binari, non è possibile eseguire l'elaborazione in parallelo</span><span class="sxs-lookup"><span data-stu-id="6e4d3-154">In some cases such as images and binary data, it is not possible to process them in parallel.</span></span>  <span data-ttu-id="6e4d3-155">ed è quindi consigliabile mantenere la dimensione dei singoli file al di sotto di 2 GB.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-155">In these cases, it is recommended to keep individual files under 2GB.</span></span>

<span data-ttu-id="6e4d3-156">Le pipeline di dati hanno talvolta un controllo limitato sui dati non elaborati costituiti da molti file di piccole dimensioni.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-156">Sometimes, data pipelines have limited control over the raw data which has lots of small files.</span></span>  <span data-ttu-id="6e4d3-157">È pertanto consigliabile prevedere l'esecuzione di un processo che genera file di maggiori dimensioni destinati all'uso da parte delle applicazioni downstream.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-157">It is recommended to have a “cooking” process that generates larger files to use for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="6e4d3-158">Organizzazione dei dati di serie temporali in cartelle</span><span class="sxs-lookup"><span data-stu-id="6e4d3-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="6e4d3-159">Per i carichi di lavoro Hive e ADLA, l'eliminazione delle partizioni dei dati di serie temporali consente ad alcune query di limitare la lettura a un subset di dati, migliorando così le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of the data which improves performance.</span></span>    

<span data-ttu-id="6e4d3-160">Queste pipeline che inseriscono dati di serie temporali, posizionano spesso i file usando un sistema di denominazione molto strutturato per file e cartelle.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="6e4d3-161">Di seguito è riportato un esempio molto comune in cui i dati sono strutturati per data:</span><span class="sxs-lookup"><span data-stu-id="6e4d3-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="6e4d3-162">Si noti che le informazioni di data/ora vengono visualizzate sia come cartelle sia nel nome del file.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-162">Notice that the datetime information appears both as folders and in the filename.</span></span>

<span data-ttu-id="6e4d3-163">Per la data e l'ora, di seguito è riportato un modello comune</span><span class="sxs-lookup"><span data-stu-id="6e4d3-163">For date and time, the following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="6e4d3-164">Anche in questo caso, la scelta relativa all'organizzazione di file e cartelle deve prevedere una gestione ottimizzata dei file di maggiori dimensioni e l'inclusione di un numero ragionevole di file in ogni cartella.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-164">Again, the choice you make with the folder and file organization should optimize for the larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="6e4d3-165">Ottimizzazione dei processi con uso intensivo dell'I/O nei carichi di lavoro Hadoop e Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="6e4d3-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="6e4d3-166">I processi sono classificabili in una delle tre categorie seguenti:</span><span class="sxs-lookup"><span data-stu-id="6e4d3-166">Jobs fall into one of the following three categories:</span></span>

* <span data-ttu-id="6e4d3-167">**Uso intensivo della CPU.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-167">**CPU intensive.**</span></span>  <span data-ttu-id="6e4d3-168">Questi processi hanno tempi di elaborazione lunghi e tempi di I/O minimi,</span><span class="sxs-lookup"><span data-stu-id="6e4d3-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="6e4d3-169">come i processi di machine learning e quelli di elaborazione del linguaggio naturale.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="6e4d3-170">**Uso intensivo della memoria.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-170">**Memory intensive.**</span></span>  <span data-ttu-id="6e4d3-171">Questi processi usano grandi quantità di memoria,</span><span class="sxs-lookup"><span data-stu-id="6e4d3-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="6e4d3-172">come i processi di PageRank e quelli di analisi in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="6e4d3-173">**Uso intensivo dell'I/O.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-173">**I/O intensive.**</span></span>  <span data-ttu-id="6e4d3-174">Questi processi impiegano la maggior parte del tempo a eseguire operazioni di I/O.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="6e4d3-175">Un esempio comune è rappresentato da un processo di copia che esegue solo operazioni di lettura e scrittura.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="6e4d3-176">Altri esempi includono i processi di preparazione dei dati che leggono una grande quantità di dati, eseguono alcune trasformazioni e quindi scrivono nuovamente i dati nell'archivio.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes the data back to the store.</span></span>  

<span data-ttu-id="6e4d3-177">Le linee guida seguenti sono applicabili solo ai processi con uso intensivo dell'I/O.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-177">The following guidance is only applicable to I/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="6e4d3-178">Considerazioni generali per un cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="6e4d3-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="6e4d3-179">**Versioni di HDInsight.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-179">**HDInsight versions.**</span></span> <span data-ttu-id="6e4d3-180">Per prestazioni ottimali, usare la versione più recente di HDInsight.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-180">For best performance, use the latest release of HDInsight.</span></span>
* <span data-ttu-id="6e4d3-181">**Aree.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-181">**Regions.**</span></span> <span data-ttu-id="6e4d3-182">Posizionare l'istanza di Data Lake Store nella stessa area del cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-182">Place the Data Lake Store in the same region as the HDInsight cluster.</span></span>  

<span data-ttu-id="6e4d3-183">Un cluster HDInsight è composto da due nodi head e da alcuni nodi di ruolo di lavoro.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="6e4d3-184">Ogni nodo di ruolo di lavoro fornisce un numero specifico di core e memoria, in base al tipo di macchina virtuale.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-184">Each worker node provides a specific number of cores and memory, which is determined by the VM-type.</span></span>  <span data-ttu-id="6e4d3-185">Quando si esegue un processo, YARN è il negoziatore di risorse che alloca la memoria e i core disponibili per creare contenitori.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-185">When running a job, YARN is the resource negotiator that allocates the available memory and cores to create containers.</span></span>  <span data-ttu-id="6e4d3-186">Ogni contenitore esegue le attività necessarie per completare il processo.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-186">Each container runs the tasks needed to complete the job.</span></span>  <span data-ttu-id="6e4d3-187">I contenitori vengono eseguiti in parallelo per l'elaborazione rapida delle attività.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-187">Containers run in parallel to process tasks quickly.</span></span> <span data-ttu-id="6e4d3-188">È quindi possibile ottenere un miglioramento delle prestazioni eseguendo la quantità massima possibile di contenitori paralleli.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="6e4d3-189">All'interno di un cluster HDInsight sono presenti tre livelli che possono essere ottimizzati per aumentare il numero di contenitori e sfruttare tutta la velocità effettiva disponibile.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-189">There are three layers within an HDInsight cluster that can be tuned to increase the number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="6e4d3-190">**Livello fisico**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-190">**Physical layer**</span></span>
* <span data-ttu-id="6e4d3-191">**Livello YARN**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-191">**YARN layer**</span></span>
* <span data-ttu-id="6e4d3-192">**Livello del carico di lavoro**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="6e4d3-193">Livello fisico</span><span class="sxs-lookup"><span data-stu-id="6e4d3-193">Physical Layer</span></span>

<span data-ttu-id="6e4d3-194">**Eseguire il cluster con più nodi e/o macchine virtuali di dimensioni maggiori.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="6e4d3-195">Un cluster di dimensioni maggiori consentirà di eseguire più contenitori YARN, come illustrato nell'immagine seguente.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-195">A larger cluster will enable you to run more YARN containers as shown in the picture below.</span></span>

![Prestazioni di Data Lake Store](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="6e4d3-197">**Usare macchine virtuali con maggiore larghezza di banda di rete.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="6e4d3-198">La larghezza di banda di rete può costituire un collo di bottiglia se la larghezza di banda di rete disponibile è inferiore alla velocità effettiva di Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-198">The amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="6e4d3-199">Macchine virtuali differenti avranno dimensioni variabili della larghezza di banda di rete.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="6e4d3-200">Scegliere un tipo di macchina virtuale con la massima larghezza di banda di rete possibile.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-200">Choose a VM-type that has the largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="6e4d3-201">Livello YARN</span><span class="sxs-lookup"><span data-stu-id="6e4d3-201">YARN Layer</span></span>

<span data-ttu-id="6e4d3-202">**Usare contenitori YARN di dimensioni inferiori.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="6e4d3-203">Ridurre le dimensioni di ogni contenitore YARN per creare altri contenitori con la stessa quantità di risorse.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-203">Reduce the size of each YARN container to create more containers with the same amount of resources.</span></span>

![Prestazioni di Data Lake Store](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="6e4d3-205">A seconda del carico di lavoro, sarà sempre necessaria una dimensione minima per i contenitori YARN.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="6e4d3-206">Se si sceglie un contenitore troppo piccolo, si verificheranno problemi di memoria insufficiente per i processi.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="6e4d3-207">In genere, la dimensione dei contenitori YARN non deve essere inferiore a 1 GB.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="6e4d3-208">I contenitori YARN hanno spesso una dimensione di 3 GB.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-208">It’s common to see 3GB YARN containers.</span></span> <span data-ttu-id="6e4d3-209">Per alcuni carichi di lavoro, possono essere necessari contenitori YARN più grandi.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="6e4d3-210">**Aumentare il numero di core per contenitore YARN.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="6e4d3-211">Aumentare il numero di core allocati a ogni contenitore per aumentare il numero di attività parallele eseguite in ogni contenitore.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-211">Increase the number of cores allocated to each container to increase the number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="6e4d3-212">Questa soluzione è valida per le applicazioni, come Spark, che eseguono più attività per contenitore.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="6e4d3-213">Per le applicazioni, come Hive, che eseguono un singolo thread in ogni contenitore, è preferibile avere più contenitori anziché più core per contenitore.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-213">For applications like Hive which run a single thread in each container, it is better to have more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="6e4d3-214">Livello del carico di lavoro</span><span class="sxs-lookup"><span data-stu-id="6e4d3-214">Workload Layer</span></span>

<span data-ttu-id="6e4d3-215">**Usare tutti i contenitori disponibili.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-215">**Use all available containers.**</span></span>  <span data-ttu-id="6e4d3-216">Impostare un numero di attività uguale o maggiore del numero di contenitori disponibili, in modo da usare tutte le risorse.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-216">Set the number of tasks to be equal or larger than the number of available containers so that all resources are utilized.</span></span>

![Prestazioni di Data Lake Store](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="6e4d3-218">**Le attività che non vengono eseguite correttamente sono dispendiose.**</span><span class="sxs-lookup"><span data-stu-id="6e4d3-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="6e4d3-219">Se ogni attività deve elaborare una grande quantità di dati, l'esito negativo di un'attività ha come risultato l'esecuzione di un nuovo tentativo impegnativo in termini di risorse.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-219">If each task has a large amount of data to process, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="6e4d3-220">È quindi preferibile creare un numero maggiore di attività, ognuna delle quali elabora una piccola quantità di dati.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-220">Therefore, it is better to create more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="6e4d3-221">Oltre alle linee guida generali sopra illustrate, ogni applicazione dispone di diversi parametri che è possibile ottimizzare.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-221">In addition to the general guidelines above, each application has different parameters available to tune for that specific application.</span></span> <span data-ttu-id="6e4d3-222">La tabella seguente elenca alcuni parametri e collegamenti per ottimizzare con facilità le prestazioni di ogni applicazione.</span><span class="sxs-lookup"><span data-stu-id="6e4d3-222">The table below lists some of the parameters and links to get started with performance tuning for each application.</span></span>

| <span data-ttu-id="6e4d3-223">Carico di lavoro</span><span class="sxs-lookup"><span data-stu-id="6e4d3-223">Workload</span></span>               | <span data-ttu-id="6e4d3-224">Parametro per impostare le attività</span><span class="sxs-lookup"><span data-stu-id="6e4d3-224">Parameter to set tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="6e4d3-225">Spark in HDInisight</span><span class="sxs-lookup"><span data-stu-id="6e4d3-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="6e4d3-226">Num-executors</span><span class="sxs-lookup"><span data-stu-id="6e4d3-226">Num-executors</span></span></li><li><span data-ttu-id="6e4d3-227">Executor-memory</span><span class="sxs-lookup"><span data-stu-id="6e4d3-227">Executor-memory</span></span></li><li><span data-ttu-id="6e4d3-228">Executor-cores</span><span class="sxs-lookup"><span data-stu-id="6e4d3-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="6e4d3-229">Hive in HDInsight</span><span class="sxs-lookup"><span data-stu-id="6e4d3-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="6e4d3-230">hive.tez.container.size</span><span class="sxs-lookup"><span data-stu-id="6e4d3-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="6e4d3-231">MapReduce in HDInsight</span><span class="sxs-lookup"><span data-stu-id="6e4d3-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="6e4d3-232">Mapreduce.map.memory</span><span class="sxs-lookup"><span data-stu-id="6e4d3-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="6e4d3-233">Mapreduce.job.maps</span><span class="sxs-lookup"><span data-stu-id="6e4d3-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="6e4d3-234">Mapreduce.reduce.memory</span><span class="sxs-lookup"><span data-stu-id="6e4d3-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="6e4d3-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="6e4d3-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="6e4d3-236">Storm in HDInsight</span><span class="sxs-lookup"><span data-stu-id="6e4d3-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="6e4d3-237">Numero di processi del ruolo di lavoro</span><span class="sxs-lookup"><span data-stu-id="6e4d3-237">Number of worker processes</span></span></li><li><span data-ttu-id="6e4d3-238">Numero di istanze di spout executor</span><span class="sxs-lookup"><span data-stu-id="6e4d3-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="6e4d3-239">Numero di istanze di bolt executor</span><span class="sxs-lookup"><span data-stu-id="6e4d3-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="6e4d3-240">Numero di attività spout</span><span class="sxs-lookup"><span data-stu-id="6e4d3-240">Number of spout tasks</span></span></li><li><span data-ttu-id="6e4d3-241">Numero di attività bolt</span><span class="sxs-lookup"><span data-stu-id="6e4d3-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="6e4d3-242">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="6e4d3-242">See also</span></span>
* [<span data-ttu-id="6e4d3-243">Panoramica dell’Archivio Data Lake di Azure</span><span class="sxs-lookup"><span data-stu-id="6e4d3-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="6e4d3-244">Introduzione all’analisi dei dati di Data Lake di Azure</span><span class="sxs-lookup"><span data-stu-id="6e4d3-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
