---
title: tooSpark aaaIntroduction in Azure HDInsight | Documenti Microsoft
description: "Questo articolo fornisce un'introduzione tooSpark su HDInsight e hello diversi scenari in cui è possibile utilizzare cluster Spark in HDInsight."
keywords: "che cos'è spark apache, cluster spark, introduzione toospark, spark in hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: 41996e733618b8534469fa239b980ac50161a535
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-toospark-on-hdinsight"></a><span data-ttu-id="15dba-104">Introduzione tooSpark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-104">Introduction tooSpark on HDInsight</span></span>

<span data-ttu-id="15dba-105">In questo articolo fornisce un'introduzione tooSpark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="15dba-105">This article provides you with an introduction tooSpark on HDInsight.</span></span> <span data-ttu-id="15dba-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> è un framework di elaborazione parallela open source che supporta in memoria prestazioni di elaborazione tooboost hello delle applicazioni analitiche big data.</span><span class="sxs-lookup"><span data-stu-id="15dba-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="15dba-107">Il cluster Spark in HDInsight è compatibile con Archiviazione di Azure (WASB) e con Azure Data Lake Store. È quindi possibile elaborare con facilità tramite un cluster Spark i dati esistenti archiviati in Azure.</span><span class="sxs-lookup"><span data-stu-id="15dba-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="15dba-108">Quando si crea un cluster Spark in HDInsight, si creano risorse di calcolo di Azure con Spark installato e configurato.</span><span class="sxs-lookup"><span data-stu-id="15dba-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="15dba-109">È sufficiente cluster toocreate un Spark in HDInsight circa dieci minuti.</span><span class="sxs-lookup"><span data-stu-id="15dba-109">It only takes about ten minutes toocreate a Spark cluster in HDInsight.</span></span> <span data-ttu-id="15dba-110">Hello toobe di dati elaborati verrà archiviati in archiviazione di Azure o archivio Azure Data Lake.</span><span class="sxs-lookup"><span data-stu-id="15dba-110">hello data toobe processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="15dba-111">Vedere [Usare l'Archiviazione di Azure con HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="15dba-112">**cluster toocreate un Spark in HDInsight**, vedere [Guida introduttiva: creare un cluster Spark in HDInsight ed eseguire query interattivo utilizzando Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-112">**toocreate a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="15dba-113">Informazioni su Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="15dba-114">I cluster Spark in HDInsight offrono un servizio Spark completamente gestito.</span><span class="sxs-lookup"><span data-stu-id="15dba-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="15dba-115">I vantaggi della creazione di un cluster Spark in HDInsight sono elencati qui.</span><span class="sxs-lookup"><span data-stu-id="15dba-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="15dba-116">Funzionalità</span><span class="sxs-lookup"><span data-stu-id="15dba-116">Feature</span></span> | <span data-ttu-id="15dba-117">Descrizione</span><span class="sxs-lookup"><span data-stu-id="15dba-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="15dba-118">Facilità di creazione dei cluster Spark</span><span class="sxs-lookup"><span data-stu-id="15dba-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="15dba-119">È possibile creare un nuovo cluster Spark in HDInsight in minuti con hello portale di Azure, Azure PowerShell o hello HDInsight .NET SDK.</span><span class="sxs-lookup"><span data-stu-id="15dba-119">You can create a new Spark cluster on HDInsight in minutes using hello Azure Portal, Azure PowerShell, or hello HDInsight .NET SDK.</span></span> <span data-ttu-id="15dba-120">Vedere [Introduzione ai cluster Spark in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="15dba-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="15dba-121">Semplicità d'uso</span><span class="sxs-lookup"><span data-stu-id="15dba-121">Ease of use</span></span> |<span data-ttu-id="15dba-122">Il cluster Spark in HDInsight include notebook di Jupyter e Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="15dba-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="15dba-123">È possibile usarli per la visualizzazione e l'elaborazione interattiva di dati.</span><span class="sxs-lookup"><span data-stu-id="15dba-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="15dba-124">API REST</span><span class="sxs-lookup"><span data-stu-id="15dba-124">REST APIs</span></span> |<span data-ttu-id="15dba-125">I cluster Spark in HDInsight sono [inserire il](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), un Spark basate su API REST di processi server tooremotely invio e monitoraggio processi.</span><span class="sxs-lookup"><span data-stu-id="15dba-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server tooremotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="15dba-126">Supporto per Archivio Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="15dba-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="15dba-127">Il cluster Spark in HDInsight può essere configurato toouse archivio Azure Data Lake come un'ulteriore spazio di archiviazione, nonché l'archiviazione primaria (solo con i cluster HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="15dba-127">Spark cluster on HDInsight can be configured toouse Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="15dba-128">Per altre informazioni su Archivio Data Lake, vedere [Panoramica di Archivio Azure Data Lake](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="15dba-129">Integrazione con servizi di Azure</span><span class="sxs-lookup"><span data-stu-id="15dba-129">Integration with Azure services</span></span> |<span data-ttu-id="15dba-130">Il cluster Spark in HDInsight viene fornito con un tooAzure connettore hub eventi.</span><span class="sxs-lookup"><span data-stu-id="15dba-130">Spark cluster on HDInsight comes with a connector tooAzure Event Hubs.</span></span> <span data-ttu-id="15dba-131">Gli utenti possono creare lo streaming di applicazioni con gli hub di eventi di hello inoltre troppo[Kafka](http://kafka.apache.org/), che è già disponibile come parte di Spark.</span><span class="sxs-lookup"><span data-stu-id="15dba-131">Customers can build streaming applications using hello Event Hubs, in addition too[Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="15dba-132">Supporto per R Server</span><span class="sxs-lookup"><span data-stu-id="15dba-132">Support for R Server</span></span> | <span data-ttu-id="15dba-133">È possibile impostare un Server di R in HDInsight Spark cluster toorun distribuita calcoli R con velocità hello promessa con un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="15dba-133">You can set up a R Server on HDInsight Spark cluster toorun distributed R computations with hello speeds promised with a Spark cluster.</span></span> <span data-ttu-id="15dba-134">Per altre informazioni, vedere [Introduzione all'uso di R Server in HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="15dba-135">Integrazione con IDE di terze parti</span><span class="sxs-lookup"><span data-stu-id="15dba-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="15dba-136">HDInsight fornisce i plug-in per IDE come IntelliJ IDEA ed Eclipse, che è possibile utilizzare toocreate e inviare tooan applicazioni cluster HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="15dba-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use toocreate and submit applications tooan HDInsight Spark cluster.</span></span> <span data-ttu-id="15dba-137">Per altre informazioni, vedere [Usare Azure Toolkit per IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) e [Usare Azure Toolkit per Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="15dba-138">Query simultanee</span><span class="sxs-lookup"><span data-stu-id="15dba-138">Concurrent Queries</span></span> |<span data-ttu-id="15dba-139">I cluster Spark in HDInsight supportano le query simultanee.</span><span class="sxs-lookup"><span data-stu-id="15dba-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="15dba-140">In questo modo più query da un utente o di più query da diversi utenti e applicazioni tooshare hello stesse risorse di cluster.</span><span class="sxs-lookup"><span data-stu-id="15dba-140">This enables multiple queries from one user or multiple queries from various users and applications tooshare hello same cluster resources.</span></span> |
| <span data-ttu-id="15dba-141">La memorizzazione nella cache nelle unità SSD</span><span class="sxs-lookup"><span data-stu-id="15dba-141">Caching on SSDs</span></span> |<span data-ttu-id="15dba-142">È possibile scegliere toocache dati in memoria o in unità SSD allegato toohello i nodi del cluster.</span><span class="sxs-lookup"><span data-stu-id="15dba-142">You can choose toocache data either in memory or in SSDs attached toohello cluster nodes.</span></span> <span data-ttu-id="15dba-143">La memorizzazione nella cache in memoria offre migliori prestazioni di query hello ma può essere costoso; memorizzazione nella cache in unità SSD fornisce un'opzione utilissima per migliorare le prestazioni di query senza necessità di hello toocreate un cluster di dimensioni che sono necessario toofit hello intero set di dati in memoria.</span><span class="sxs-lookup"><span data-stu-id="15dba-143">Caching in memory provides hello best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without hello need toocreate a cluster of a size that is required toofit hello entire dataset in memory.</span></span> |
| <span data-ttu-id="15dba-144">Integrazione con strumenti di Business Intelligence</span><span class="sxs-lookup"><span data-stu-id="15dba-144">Integration with BI Tools</span></span> |<span data-ttu-id="15dba-145">I cluster Spark in HDInsight offrono connettori per strumenti di Business Intelligence, come [Power BI](http://www.powerbi.com/) e [Tableau](http://www.tableau.com/products/desktop), per l'analisi dei dati.</span><span class="sxs-lookup"><span data-stu-id="15dba-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="15dba-146">Librerie Anaconda precaricate</span><span class="sxs-lookup"><span data-stu-id="15dba-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="15dba-147">I cluster Spark in HDInsight sono dotati di librerie Anaconda preinstallate</span><span class="sxs-lookup"><span data-stu-id="15dba-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="15dba-148">[Anaconda](http://docs.continuum.io/anaconda/) fornisce librerie too200 chiusura per l'apprendimento, analisi dei dati, visualizzazione e così via.</span><span class="sxs-lookup"><span data-stu-id="15dba-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close too200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="15dba-149">Scalabilità</span><span class="sxs-lookup"><span data-stu-id="15dba-149">Scalability</span></span> |<span data-ttu-id="15dba-150">Sebbene sia possibile specificare il numero di hello di nodi del cluster durante la creazione, si desidera toogrow oppure ridurre il carico di lavoro di hello cluster toomatch.</span><span class="sxs-lookup"><span data-stu-id="15dba-150">Although you can specify hello number of nodes in your cluster during creation, you may want toogrow or shrink hello cluster toomatch workload.</span></span> <span data-ttu-id="15dba-151">Tutti i cluster HDInsight consentono numero hello toochange di nodi nel cluster hello.</span><span class="sxs-lookup"><span data-stu-id="15dba-151">All HDInsight clusters allow you toochange hello number of nodes in hello cluster.</span></span> <span data-ttu-id="15dba-152">Inoltre, i cluster Spark possono essere eliminati senza perdita di dati poiché tutti i dati di hello viene archiviata in archiviazione di Azure o archivio Data Lake.</span><span class="sxs-lookup"><span data-stu-id="15dba-152">Also, Spark clusters can be dropped with no loss of data since all hello data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="15dba-153">Supporto 24/7</span><span class="sxs-lookup"><span data-stu-id="15dba-153">24/7 Support</span></span> |<span data-ttu-id="15dba-154">I cluster Spark in HDInsight includono il supporto continuo a livello aziendale e un Contratto di servizio che garantisce tempi di attività pari al 99,9%.</span><span class="sxs-lookup"><span data-stu-id="15dba-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-hello-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="15dba-155">Quali sono i casi di utilizzo hello per Spark in HDInsight?</span><span class="sxs-lookup"><span data-stu-id="15dba-155">What are hello use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="15dba-156">Il cluster Spark in HDInsight Abilita hello seguendo gli scenari principali.</span><span class="sxs-lookup"><span data-stu-id="15dba-156">Spark clusters in HDInsight enable hello following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="15dba-157">Analisi dei dati interattivi e Business Intelligence</span><span class="sxs-lookup"><span data-stu-id="15dba-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="15dba-158">Esaminare un'esercitazione</span><span class="sxs-lookup"><span data-stu-id="15dba-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="15dba-159">Apache Spark in HDInsight archivia i dati nell'Archiviazione di Azure o in Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="15dba-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="15dba-160">Esperti aziendali e responsabili delle decisioni chiave possono analizzare e generare rapporti su dati e report interattivi di Microsoft Power BI toobuild dai dati hello analizzato.</span><span class="sxs-lookup"><span data-stu-id="15dba-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI toobuild interactive reports from hello analyzed data.</span></span> <span data-ttu-id="15dba-161">Gli analisti possono avviare dai dati non strutturati/semi strutturati nell'archiviazione cluster, definire uno schema per i dati di hello utilizzando blocchi appunti e quindi compilare modelli di dati con Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="15dba-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for hello data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="15dba-162">I cluster Spark in HDInsight supportano anche alcuni strumenti di BI di terze parti, ad esempio Tableau, e sono quindi una piattaforma ottimale per gli analisti di dati, gli esperti aziendali e i decision maker principali.</span><span class="sxs-lookup"><span data-stu-id="15dba-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="15dba-163">Machine Learning in Spark</span><span class="sxs-lookup"><span data-stu-id="15dba-163">Spark Machine Learning</span></span>
[<span data-ttu-id="15dba-164">Esaminare un'esercitazione: stima delle temperature di compilazione mediante i dati HVAC</span><span class="sxs-lookup"><span data-stu-id="15dba-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="15dba-165">Esaminare un'esercitazione: stima dei risultati di ispezione del cibo</span><span class="sxs-lookup"><span data-stu-id="15dba-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="15dba-166">Apache Spark include [MLlib](http://spark.apache.org/mllib/), una libreria di Machine Learning basata su Spark, che è possibile usare da un cluster Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="15dba-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="15dba-167">Il cluster Spark in HDInsight include inoltre Anaconda, una distribuzione di Python con un'ampia gamma di pacchetti per l'apprendimento automatico.</span><span class="sxs-lookup"><span data-stu-id="15dba-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="15dba-168">Aggiungendo il supporto incorporato per notebook Jupyter e Zeppelin si otterrà un ambiente di qualità elevata per la creazione di applicazioni di Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="15dba-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="15dba-169">Analisi dei dati in tempo reale e streaming in Spark</span><span class="sxs-lookup"><span data-stu-id="15dba-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="15dba-170">Esaminare un'esercitazione</span><span class="sxs-lookup"><span data-stu-id="15dba-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="15dba-171">I cluster Spark in HDInsight offrono un supporto completo per la creazione di soluzioni di analisi in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="15dba-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="15dba-172">Mentre Spark ha già i dati dei connettori tooingest da molte origini, ad esempio di socket Kafka, Flume, Twitter, ZeroMQ o TCP, Spark in HDInsight aggiunge il supporto di prima classe per l'inserimento di dati di hub di eventi di Azure.</span><span class="sxs-lookup"><span data-stu-id="15dba-172">While Spark already has connectors tooingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="15dba-173">Gli hub eventi sono hello più diffuse servizio di Accodamento messaggi in Azure.</span><span class="sxs-lookup"><span data-stu-id="15dba-173">Event Hubs are hello most widely used queuing service on Azure.</span></span> <span data-ttu-id="15dba-174">La disponibilità di un supporto per Hub eventi rende i cluster Spark in HDInsight la piattaforma ideale per la compilazione della pipeline di analisi in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="15dba-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="15dba-175"><a name="next-steps"></a>Quali componenti sono inclusi come parte di un cluster di Spark?</span><span class="sxs-lookup"><span data-stu-id="15dba-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="15dba-176">Il cluster Spark in HDInsight include hello seguenti componenti che sono disponibili nei cluster hello per impostazione predefinita.</span><span class="sxs-lookup"><span data-stu-id="15dba-176">Spark clusters in HDInsight include hello following components that are available on hello clusters by default.</span></span>

* <span data-ttu-id="15dba-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="15dba-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="15dba-178">Viene fornito con Spark Core, Spark SQL, streaming API Spark, GraphX e MLlib Spark.</span><span class="sxs-lookup"><span data-stu-id="15dba-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="15dba-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="15dba-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="15dba-180">Livy</span><span class="sxs-lookup"><span data-stu-id="15dba-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="15dba-181">Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="15dba-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="15dba-182">Notebook Zeppelin</span><span class="sxs-lookup"><span data-stu-id="15dba-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="15dba-183">I cluster Spark in HDInsight includono inoltre un [driver ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) per connettività tooSpark cluster HDInsight da strumenti di Business Intelligence, ad esempio Microsoft Power BI e Tableau.</span><span class="sxs-lookup"><span data-stu-id="15dba-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity tooSpark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="15dba-184">Dove iniziare?</span><span class="sxs-lookup"><span data-stu-id="15dba-184">Where do I start?</span></span>
<span data-ttu-id="15dba-185">Iniziare con la creazione di un cluster Spark in HDInsight.</span><span class="sxs-lookup"><span data-stu-id="15dba-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="15dba-186">Vedere [Guida introduttiva: creare un cluster di Spark in HDInsight ed eseguire query interattive usando Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="15dba-187">Passaggi successivi</span><span class="sxs-lookup"><span data-stu-id="15dba-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="15dba-188">Scenari</span><span class="sxs-lookup"><span data-stu-id="15dba-188">Scenarios</span></span>
* [<span data-ttu-id="15dba-189">Spark con Business Intelligence: eseguire l'analisi interattiva dei dati con strumenti di Business Intelligence mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="15dba-190">Spark con Machine Learning: utilizzare Spark in HDInsight per l'analisi della temperatura di compilazione utilizzando dati HVAC</span><span class="sxs-lookup"><span data-stu-id="15dba-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="15dba-191">Spark con Machine Learning: usare Spark in HDInsight risultati dell'ispezione alimentare toopredict</span><span class="sxs-lookup"><span data-stu-id="15dba-191">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="15dba-192">Streaming Spark: usare Spark in HDInsight per la creazione di applicazioni di streaming in tempo reale</span><span class="sxs-lookup"><span data-stu-id="15dba-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="15dba-193">Analisi dei log del sito Web mediante Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="15dba-194">Creare ed eseguire applicazioni</span><span class="sxs-lookup"><span data-stu-id="15dba-194">Create and run applications</span></span>
* [<span data-ttu-id="15dba-195">Creare un'applicazione autonoma con Scala</span><span class="sxs-lookup"><span data-stu-id="15dba-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="15dba-196">Eseguire processi in modalità remota in un cluster Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="15dba-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="15dba-197">Strumenti ed estensioni</span><span class="sxs-lookup"><span data-stu-id="15dba-197">Tools and extensions</span></span>
* [<span data-ttu-id="15dba-198">Utilizzare i plug-in strumenti di HDInsight per toocreate IntelliJ IDEA e inviare applicazioni Spark Scala</span><span class="sxs-lookup"><span data-stu-id="15dba-198">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="15dba-199">Utilizzare i plug-in strumenti di HDInsight per le applicazioni di Spark toodebug IntelliJ IDEA in modalità remota</span><span class="sxs-lookup"><span data-stu-id="15dba-199">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="15dba-200">Usare i notebook di Zeppelin con un cluster Spark in HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="15dba-201">Kernel disponibili per notebook di Jupyter nel cluster Spark per HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="15dba-202">Usare pacchetti esterni con i notebook Jupyter</span><span class="sxs-lookup"><span data-stu-id="15dba-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="15dba-203">Installare Jupyter nel computer e connettere il cluster HDInsight Spark tooan</span><span class="sxs-lookup"><span data-stu-id="15dba-203">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="15dba-204">Gestire risorse</span><span class="sxs-lookup"><span data-stu-id="15dba-204">Manage resources</span></span>
* [<span data-ttu-id="15dba-205">Gestire le risorse di cluster di hello Apache Spark in HDInsight di Azure</span><span class="sxs-lookup"><span data-stu-id="15dba-205">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="15dba-206">Tenere traccia ed eseguire il debug di processi in esecuzione nel cluster Apache Spark in Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="15dba-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="15dba-207">[Problemi noti di Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="15dba-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
