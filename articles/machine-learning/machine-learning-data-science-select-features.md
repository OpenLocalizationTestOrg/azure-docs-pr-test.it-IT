---
title: selezione aaaFeature nel processo di analisi scientifica dei dati di Team hello | Documenti Microsoft
description: "Viene spiegato hello scopo della funzionalità di selezione e vengono forniti esempi del proprio ruolo nel processo di miglioramento dei dati hello di machine learning."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: 54af93c83e4cc6a3670b3ad62490e0f74082b4ee
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/06/2017
---
# <a name="feature-selection-in-hello-team-data-science-process-tdsp"></a><span data-ttu-id="2256d-103">Selezione di funzionalità in hello Team Data Science processo (TDSP)</span><span class="sxs-lookup"><span data-stu-id="2256d-103">Feature selection in hello Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="2256d-104">In questo articolo illustra a scopo di hello di selezione delle funzionalità e fornisce esempi del relativo ruolo nel processo di miglioramento dei dati hello di machine learning.</span><span class="sxs-lookup"><span data-stu-id="2256d-104">This article explains hello purposes of feature selection and provides examples of its role in hello data enhancement process of machine learning.</span></span> <span data-ttu-id="2256d-105">Questi esempi sono tratti da Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="2256d-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="2256d-106">Hello engineering e selezione di funzionalità fa parte di hello indicati in Team dati scienza processo (TDSP) [novità hello processo di analisi scientifica dei dati del Team?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="2256d-106">hello engineering and selection of features is one part of hello Team Data Science Process (TDSP) outlined in [What is hello Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="2256d-107">Progettazione di funzionalità e di selezione sono parti di hello **sviluppare funzionalità** passaggio di hello TDSP.</span><span class="sxs-lookup"><span data-stu-id="2256d-107">Feature engineering and selection are parts of hello **Develop features** step of hello TDSP.</span></span>

* <span data-ttu-id="2256d-108">**funzionalità di progettazione**: il processo tenta toocreate funzionalità rilevanti aggiuntive dalle funzionalità non elaborato esistente di hello hello di dati e l'algoritmo di apprendimento toohello tooincrease capacità predittiva.</span><span class="sxs-lookup"><span data-stu-id="2256d-108">**feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data, and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="2256d-109">**selezione delle caratteristiche**: questo processo consente di selezionare sottoinsieme di chiave hello delle funzionalità di dati originale della dimensionalità di hello tooreduce tentativo di problema training hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-109">**feature selection**: This process selects hello key subset of original data features in an attempt tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="2256d-110">In genere **funzionalità engineering** verrà applicato prima toogenerate le funzionalità aggiuntive, quindi hello **selezione delle caratteristiche** passaggio viene eseguito tooeliminate irrilevanti, ridondanti o altamente correlate funzionalità.</span><span class="sxs-lookup"><span data-stu-id="2256d-110">Normally **feature engineering** is applied first toogenerate additional features, and then hello **feature selection** step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="2256d-111">Filtro delle funzioni dai dati: selezione di funzioni</span><span class="sxs-lookup"><span data-stu-id="2256d-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="2256d-112">Funzionalità di selezione è un processo che viene in genere applicato per la costruzione di hello del set di dati di training per la modellazione predittiva di attività, ad esempio attività di classificazione o regressione.</span><span class="sxs-lookup"><span data-stu-id="2256d-112">Feature selection is a process that is commonly applied for hello construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="2256d-113">obiettivo di Hello è un subset delle funzionalità di hello dal set di dati originale hello che consentono di ridurre le dimensioni utilizzando un set minimo di funzionalità toorepresent hello massimo della varianza nei dati hello tooselect.</span><span class="sxs-lookup"><span data-stu-id="2256d-113">hello goal is tooselect a subset of hello features from hello original dataset that reduce its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="2256d-114">Questo sottoinsieme di funzionalità, quindi, hello solo funzionalità toobe inclusi modello hello tootrain.</span><span class="sxs-lookup"><span data-stu-id="2256d-114">This subset of features are, then, hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="2256d-115">La selezione delle funzioni ha due scopi principali.</span><span class="sxs-lookup"><span data-stu-id="2256d-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="2256d-116">La selezione di funzioni migliora spesso la  precisione della classificazione eliminando le funzioni irrilevanti, ridondanti o altamente correlate.</span><span class="sxs-lookup"><span data-stu-id="2256d-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="2256d-117">In secondo luogo, tale operazione riduce hello numerose funzionalità che rende più efficiente il processo di training del modello.</span><span class="sxs-lookup"><span data-stu-id="2256d-117">Second, it decreases hello number of features which makes model training process more efficient.</span></span> <span data-ttu-id="2256d-118">Ciò è particolarmente importante per strumenti di apprendimento che sono costosi tootrain, ad esempio macchine a vettori di supporto.</span><span class="sxs-lookup"><span data-stu-id="2256d-118">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="2256d-119">Sebbene Selezione funzionalità seek numero hello tooreduce funzionalità hello set di dati utilizzato tootrain hello modello, non è in genere tooby cui hello termine "riduzione della dimensionalità".</span><span class="sxs-lookup"><span data-stu-id="2256d-119">Although feature selection does seek tooreduce hello number of features in hello dataset used tootrain hello model, it is not usually referred tooby hello term "dimensionality reduction".</span></span> <span data-ttu-id="2256d-120">Metodi di selezione delle funzioni di estrarre un subset delle funzionalità originale in dati hello senza modificarli.</span><span class="sxs-lookup"><span data-stu-id="2256d-120">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="2256d-121">Metodi di riduzione della dimensionalità utilizzano ingegneria funzionalità che è possibile trasformare le funzionalità originali di hello e quindi modificarli.</span><span class="sxs-lookup"><span data-stu-id="2256d-121">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="2256d-122">Analisi in componenti principali, analisi di correlazione canonica e scomposizione di valori singolari sono esempi di metodi di riduzione della dimensionalità.</span><span class="sxs-lookup"><span data-stu-id="2256d-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="2256d-123">Tra le altre, una categoria di funzioni ampiamente applicata in un contesto supervisionato è detta "Selezione delle funzioni basata su filtro".</span><span class="sxs-lookup"><span data-stu-id="2256d-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="2256d-124">Per la valutazione di correlazione hello tra ogni attributo di destinazione di funzionalità e hello, questi metodi si applicano tooassign una misura statistica una funzionalità tooeach punteggio.</span><span class="sxs-lookup"><span data-stu-id="2256d-124">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="2256d-125">funzionalità di Hello vengono quindi classificate in base punteggio hello, che può essere utilizzato toohelp set hello soglia per il mantenimento o l'eliminazione di una funzionalità specifica.</span><span class="sxs-lookup"><span data-stu-id="2256d-125">hello features are then ranked by hello score, which may be used toohelp set hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="2256d-126">Esempi di misure statistiche di hello usate in questi metodi includono correlazione persona, basato sull'informazione mutua e test di hello Chi quadrato.</span><span class="sxs-lookup"><span data-stu-id="2256d-126">Examples of hello statistical measures used in these methods include Person correlation, mutual information, and hello Chi squared test.</span></span>

<span data-ttu-id="2256d-127">In Azure Machine Learning Studio sono disponibili moduli per la selezione delle funzioni.</span><span class="sxs-lookup"><span data-stu-id="2256d-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="2256d-128">Come illustrato nella seguente illustrazione hello, questi moduli includono [Filter-Based Feature Selection] [ filter-based-feature-selection] e [Fisher Linear Discriminant Analysis] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="2256d-128">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="2256d-130">Si consideri, ad esempio, usare hello di hello [Filter-Based Feature Selection] [ filter-based-feature-selection] modulo.</span><span class="sxs-lookup"><span data-stu-id="2256d-130">Consider, for example, hello use of hello [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="2256d-131">Ai fini di hello della praticità, continuiamo toouse hello text mining riportato di seguito viene illustrato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="2256d-131">For hello purpose of convenience, we continue toouse hello text mining example outlined above.</span></span> <span data-ttu-id="2256d-132">Si supponga che un modello di regressione dopo un set di 256 funzionalità vengono creati tramite hello toobuild [Feature Hashing] [ feature-hashing] modulo e la variabile di risposta hello hello "Col1" e rappresenta un libro Esaminare le classificazioni comprese tra 1 too5.</span><span class="sxs-lookup"><span data-stu-id="2256d-132">Assume that we want toobuild a regression model after a set of 256 features are created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is hello "Col1" and represents a book review ratings ranging from 1 too5.</span></span> <span data-ttu-id="2256d-133">Tramite l'impostazione "Funzionalità di assegnazione dei punteggi metodo" toobe "Correlazione di Pearson", hello "Colonna di destinazione" toobe "Col1" e too50 "Numero di funzioni desiderate" hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-133">By setting "Feature scoring method" toobe "Pearson Correlation", hello "Target column" toobe "Col1", and hello "Number of desired features" too50.</span></span> <span data-ttu-id="2256d-134">Quindi hello modulo [Filter-Based Feature Selection] [ filter-based-feature-selection] produrrà un set di dati contenente le funzionalità di 50 con attributo di destinazione hello "Col1".</span><span class="sxs-lookup"><span data-stu-id="2256d-134">Then hello module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with hello target attribute "Col1".</span></span> <span data-ttu-id="2256d-135">di seguito Hello figura mostra il flusso di hello di questa sperimentazione e hello parametri di input che appena descritti.</span><span class="sxs-lookup"><span data-stu-id="2256d-135">hello following figure shows hello flow of this experiment and hello input parameters we just described.</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="2256d-137">Hello nella figura seguente mostra i set di dati risultante hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-137">hello following figure shows hello resulting datasets.</span></span> <span data-ttu-id="2256d-138">Ogni funzionalità viene calcolato il punteggio in base su hello correlazione di Pearson tra stesso e attributo di destinazione "Col1" hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-138">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute "Col1".</span></span> <span data-ttu-id="2256d-139">funzionalità di Hello con i punteggi migliori vengono mantenute.</span><span class="sxs-lookup"><span data-stu-id="2256d-139">hello features with top scores are kept.</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="2256d-141">Hello corrispondente moltissimi funzionalità hello selezionato vengono visualizzati nella seguente illustrazione hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-141">hello corresponding scores of hello selected features are shown in hello following figure.</span></span>

![Esempio di selezione delle funzioni](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="2256d-143">Applicando questo [Filter-Based Feature Selection] [ filter-based-feature-selection] modulo, 50 da 256 funzionalità selezionate sono in quanto essi hanno hello più funzioni correlate con la variabile di destinazione hello "Col1", in base a hello punteggio metodo "Correlazione di Pearson".</span><span class="sxs-lookup"><span data-stu-id="2256d-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most correlated features with hello target variable "Col1", based on hello scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="2256d-144">Conclusioni</span><span class="sxs-lookup"><span data-stu-id="2256d-144">Conclusion</span></span>
<span data-ttu-id="2256d-145">Progettazione di funzionalità e funzionalità di selezione sono due comunemente progettata e funzionalità selezionate e aumentare l'efficienza di hello di formazione di processo che tenta di informazioni chiave hello tooextract contenute nei dati hello hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-145">Feature engineering and feature selection are two commonly Engineered and selected features increase hello efficiency of hello training process which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="2256d-146">Sono anche migliorare power hello questi modelli tooclassify hello di dati di input in modo accurato e risultati toopredict di interessano più in modo affidabile.</span><span class="sxs-lookup"><span data-stu-id="2256d-146">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="2256d-147">Progettazione di funzionalità e la selezione anche possibile combinare learning hello toomake gestibile calcoli più complessi.</span><span class="sxs-lookup"><span data-stu-id="2256d-147">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="2256d-148">Ciò avviene tramite ottimizzazione e quindi riducendo il numero di hello delle funzionalità necessarie toocalibrate o un modello di training.</span><span class="sxs-lookup"><span data-stu-id="2256d-148">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="2256d-149">Matematicamente generale, il modello di hello di hello funzionalità tootrain selezionato sono un set minimo di variabili indipendenti che descrivono i modelli di hello nei dati hello e quindi una stima dei risultati correttamente.</span><span class="sxs-lookup"><span data-stu-id="2256d-149">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="2256d-150">Si noti che non è sempre necessariamente tooperform di funzionalità engineering o funzionalità di selezione.</span><span class="sxs-lookup"><span data-stu-id="2256d-150">Note that it is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="2256d-151">Se è necessario o non dipende dai dati hello è o raccogliere, algoritmo hello che viene selezionato, e hello obiettivo dell'esperimento hello.</span><span class="sxs-lookup"><span data-stu-id="2256d-151">Whether it is needed or not depends on hello data we have or collect, hello algorithm we pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/

